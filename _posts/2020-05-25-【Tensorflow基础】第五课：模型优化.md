---
layout:     post
title:      ã€TensorflowåŸºç¡€ã€‘ç¬¬äº”è¯¾ï¼šæ¨¡å‹ä¼˜åŒ–
subtitle:   ä»£ä»·å‡½æ•°ï¼Œç½‘ç»œç»“æ„ï¼Œä¼˜åŒ–å™¨
date:       2020-05-25
author:     x-jeff
header-img: blogimg/20200525.jpg
catalog: true
tags:
    - Tensorflow Series
---
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.å‰è¨€

æˆ‘ä»¬ä»¥[ã€TensorflowåŸºç¡€ã€‘ç¬¬å››è¯¾ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«](http://shichaoxin.com/2020/03/26/TensorflowåŸºç¡€-ç¬¬å››è¯¾-æ‰‹å†™æ•°å­—è¯†åˆ«/)ä¸­æ„å»ºçš„æ‰‹å†™æ•°å­—è¯†åˆ«æ¨¡å‹ä¸ºä¾‹ï¼Œå¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚

# 2.ä¿®æ”¹ä»£ä»·å‡½æ•°

åœ¨ä¹‹å‰çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ç”¨çš„æ˜¯å‡æ–¹è¯¯å·®ä½œä¸ºcost functionã€‚ç°åœ¨æˆ‘ä»¬ä½¿ç”¨æ›´åˆé€‚çš„[äº¤å‰ç†µæŸå¤±å‡½æ•°](http://shichaoxin.com/2019/09/04/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬äºŒè¯¾-softmaxåˆ†ç±»å™¨å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°/)ä½œä¸ºcost functionï¼š

```python
loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))
```

ç»“æœå¯¹æ¯”è§ä¸‹ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/TensorflowSeries/Lesson5/5x1.png)

å¾ˆæ˜æ˜¾ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°æ•ˆæœæ›´å¥½ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚

>åœ¨åštensorä¹‹é—´çš„åŠ å‡ä¹˜é™¤ç­‰åŸºæœ¬è¿ç®—æ—¶ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨`+-*\`ç­‰ç¬¦å·ï¼Œè¿™äº›ç¬¦å·ä¼šè¢«tensorflowè‡ªåŠ¨é‡è½½ä¸ºå¯¹åº”çš„æ¥å£å‡½æ•°ï¼Œä¾‹å¦‚`+`è¢«é‡è½½ä¸º`tf.add()`ã€‚

# 3.ä¿®æ”¹ç½‘ç»œ

åœ¨ç¬¬2éƒ¨åˆ†çš„åŸºç¡€ä¸Šï¼Œå¯¹ç½‘ç»œçš„ç»“æ„å’Œå‚æ•°è¿›è¡Œäº†å¦‚ä¸‹ä¿®æ”¹ï¼š

1. æ·»åŠ éšè—å±‚ã€‚
2. éšæœºåˆå§‹åŒ–æƒé‡ã€‚
3. dropouté˜²æ­¢è¿‡æ‹Ÿåˆã€‚

>ä¸ºä»€ä¹ˆè¦éšæœºåˆå§‹åŒ–æƒé‡ï¼Ÿè¯·æˆ³ğŸ‘‰[ã€æ·±åº¦å­¦ä¹ åŸºç¡€ã€‘ç¬¬åä¸‰è¯¾ï¼šæ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸](http://shichaoxin.com/2020/02/07/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸‰è¯¾-æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸/)ã€‚
>
>å…³äºdropoutçš„è¯¦ç»†ä»‹ç»ï¼Œè¯·æˆ³ğŸ‘‰[ã€æ·±åº¦å­¦ä¹ åŸºç¡€ã€‘ç¬¬åä¸€è¯¾ï¼šæ­£åˆ™åŒ–](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/)ã€‚

ä»£ç å¦‚ä¸‹ï¼š

```python
#ç¬¬ä¸€å±‚
W1=tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))
b1=tf.Variable(tf.zeros([2000])+0.1)
A1=tf.nn.tanh(tf.matmul(x,W1)+b1)
A1_drop=tf.nn.dropout(A1,keep_prob)
#ç¬¬äºŒå±‚
W2=tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))
b2=tf.Variable(tf.zeros([2000])+0.1)
A2=tf.nn.tanh(tf.matmul(A1_drop,W2)+b2)
A2_drop=tf.nn.dropout(A2,keep_prob)
#ç¬¬ä¸‰å±‚
W3=tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))
b3=tf.Variable(tf.zeros([1000])+0.1)
A3=tf.nn.tanh(tf.matmul(A2_drop,W3)+b3)
A3_drop=tf.nn.dropout(A3,keep_prob)
#è¾“å‡ºå±‚
W4=tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))
b4=tf.Variable(tf.zeros([10])+0.1)
prediction=tf.nn.softmax(tf.matmul(A3_drop,W4)+b4)
```

å‡½æ•°`tf.truncated_normal`ï¼š

```python
truncated_normal(
	shape,#è¾“å‡ºå¼ é‡å›´åº¦
	mean=0.0,#å‡å€¼
	stddev=1.0,#æ ‡å‡†å·®
	dtype=dtypes.float32,#è¾“å‡ºç±»å‹
	seed=None,#éšæœºæ•°ç§å­
	name=None#è¿ç®—åç§°
)
```

è¯¥å‡½æ•°å¯äº§ç”Ÿæˆªæ–­æ­£æ€åˆ†å¸ƒéšæœºæ•°ï¼Œå–å€¼èŒƒå›´ä¸º$[mean-2\times stddev,mean+2\times stddev]$ã€‚

`keep_prob`åœ¨è®­ç»ƒæ—¶è®¾ä¸º0.7ï¼Œé¢„æµ‹æ—¶ä¸èƒ½ä½¿ç”¨dropoutï¼Œå› æ­¤é¢„æµ‹æ—¶`keep_drop`è®¾ä¸º1.0ã€‚

ä¿®æ”¹åé¢„æµ‹ç»“æœä¸ºï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/TensorflowSeries/Lesson5/5x2.png)

ç›¸æ¯”ç¬¬2éƒ¨åˆ†ï¼Œç»“æœåˆæœ‰äº†è¿›ä¸€æ­¥çš„æå‡ã€‚

# 4.ä¿®æ”¹ä¼˜åŒ–å™¨

æœ‰å¾ˆå¤šä¼˜åŒ–ç®—æ³•å¯ä¾›é€‰æ‹©ï¼š

1. [Adamä¼˜åŒ–ç®—æ³•](http://shichaoxin.com/2020/03/19/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¹è¯¾-Adamä¼˜åŒ–ç®—æ³•/)ï¼š`tf.train.AdamOptimizer()`ã€‚
2. [RMSPropä¼˜åŒ–ç®—æ³•](http://shichaoxin.com/2020/03/13/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åå…«è¯¾-RMSprop/)ï¼š`tf.train.RMSPropOptimizer()`ã€‚
3. [Momentumä¼˜åŒ–ç®—æ³•](http://shichaoxin.com/2020/03/05/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸ƒè¯¾-Momentumæ¢¯åº¦ä¸‹é™æ³•/)ï¼š`tf.train.MomentumOptimizer()`ã€‚

ä¾‹å¦‚æˆ‘ä»¬é€‰æ‹©Adamä¼˜åŒ–ç®—æ³•ï¼š

```python
train_step=tf.train.AdamOptimizer(1e-2).minimize(loss)
```

![](https://github.com/x-jeff/BlogImage/raw/master/TensorflowSeries/Lesson5/5x3.png)

æ¨¡å‹è¡¨ç°ç›¸æ¯”ç¬¬3éƒ¨åˆ†åˆæœ‰æå‡ã€‚

# 5.ä»£ç åœ°å€

1. [æ¨¡å‹ä¼˜åŒ–](https://github.com/x-jeff/Tensorflow_Code_Demo/tree/master/Demo4)