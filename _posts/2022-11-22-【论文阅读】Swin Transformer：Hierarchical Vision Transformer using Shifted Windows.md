---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘Swin Transformerï¼šHierarchical Vision Transformer using Shifted Windows
subtitle:   Swin Transformer
date:       2022-11-22
author:     x-jeff
header-img: blogimg/20221122.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>githubå®˜æ–¹repoï¼š[https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)ã€‚

è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å»ºæ¨¡ä¸€ç›´è¢«CNNæ‰€ä¸»å¯¼ã€‚ä»[AlexNet](http://shichaoxin.com/2021/02/03/è®ºæ–‡é˜…è¯»-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/)åœ¨ImageNetå›¾åƒåˆ†ç±»æŒ‘æˆ˜ä¸Šçš„ä¼˜å¼‚è¡¨ç°å¼€å§‹ï¼ŒCNNé€šè¿‡æ›´å¤§çš„è§„æ¨¡ã€æ›´å¹¿æ³›çš„è¿æ¥å’Œæ›´å¤æ‚çš„å·ç§¯å½¢å¼å˜å¾—è¶Šæ¥è¶Šå¼ºå¤§ã€‚ä»¥CNNä¸ºbackboneçš„å„ç§æ¡†æ¶ä¸æ–­æå‡ç€å…¶æ€§èƒ½ï¼Œä¿ƒè¿›äº†è§†è§‰é¢†åŸŸçš„è¿›æ­¥ã€‚

å¦ä¸€æ–¹é¢ï¼ŒNLPåˆ™æ˜¯ä¸€æ¡ä¸åŒçš„é“è·¯ï¼Œå½“ä»Šæµè¡Œçš„æ¡†æ¶æ˜¯[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)ã€‚å…¶åœ¨NLPé¢†åŸŸçš„å·¨å¤§æˆåŠŸä¿ƒä½¿äººä»¬å¼€å§‹ç ”ç©¶å…¶åœ¨CVé¢†åŸŸçš„é€‚åº”æ€§ï¼Œæœ€è¿‘åœ¨CVé¢†åŸŸå†…çš„ä¸€äº›ä»»åŠ¡ä¸Šï¼Œç‰¹åˆ«æ˜¯å›¾åƒåˆ†ç±»å’Œjoint vision-language modelingï¼Œå…¶å±•ç¤ºäº†æœ‰å¸Œæœ›çš„ç»“æœã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å°†[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)ä½œä¸ºCVä»»åŠ¡é€šç”¨backboneçš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬è®¤ä¸ºå°†NLPé¢†åŸŸå†…çš„é«˜æ€§èƒ½æ–¹æ³•è¿ç§»åˆ°CVé¢†åŸŸï¼Œæ‰€é¢ä¸´çš„æŒ‘æˆ˜å¯è¢«æ€»ç»“ä¸ºä¸¤ç‚¹ä¸åŒã€‚ç¬¬ä¸€ä¸ªä¸åŒæ˜¯scaleã€‚NLPé¢†åŸŸä¸­ï¼ŒåŸºæœ¬å…ƒç´ é€šå¸¸æ˜¯word tokensï¼Œè€Œåœ¨CVé¢†åŸŸï¼ŒåŸºæœ¬å…ƒç´ çš„scaleå¯ä»¥æœ‰å¾ˆå¤§åŒºåˆ«ï¼Œé€šå¸¸åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ä¼šç¢°åˆ°è¿™æ ·çš„é—®é¢˜ã€‚åœ¨ç›®å‰å·²æœ‰çš„åŸºäº[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)çš„æ¨¡å‹ä¸­ï¼Œtokensçš„scaleéƒ½æ˜¯å›ºå®šçš„ï¼Œè¿™ä¸€ç‰¹æ€§ä¸é€‚åˆCVä»»åŠ¡ã€‚ç¬¬äºŒä¸ªä¸åŒæ˜¯ï¼Œç›¸æ¯”æ–‡æœ¬æ®µè½ä¸­çš„å•è¯æ•°é‡ï¼Œå›¾åƒä¸­çš„åƒç´ åˆ†è¾¨ç‡è¦é«˜å¾—å¤šã€‚æœ‰äº›CVä»»åŠ¡ï¼Œæ¯”å¦‚è¯­ä¹‰åˆ†å‰²ï¼Œéœ€è¦åœ¨åƒç´ çº§åˆ«ä¸Šè¿›è¡Œdense predictionï¼Œè¿™åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šå¯¹äº[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)æ¥è¯´æ˜¯å¾ˆå›°éš¾çš„ï¼Œå…¶è®¡ç®—å¤æ‚åº¦å’Œå›¾åƒå¤§å°æˆå¹³æ–¹å…³ç³»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Swin Transformerï¼Œå…¶æ„å»ºäº†hierarchical feature mapsï¼Œå¹¶ä¸”å…¶è®¡ç®—å¤æ‚åº¦ä¸å›¾åƒå¤§å°å‘ˆçº¿æ€§å…³ç³»ã€‚å¦‚Fig1(a)æ‰€ç¤ºï¼ŒSwin Transformeræ„å»ºäº†hierarchical representationï¼Œä¸€å¼€å§‹æ˜¯å°å°ºå¯¸çš„patchï¼ˆç°è‰²ç½‘æ ¼ï¼‰ï¼Œéšç€Transformer layersçš„åŠ æ·±ï¼Œé€æ¸åˆå¹¶æˆå¤§å°ºå¯¸çš„patchã€‚æœ‰äº†è¿™äº›hierarchical feature mapsï¼ŒSwin Transformeræ¨¡å‹å¯ä»¥æ–¹ä¾¿åœ°åˆ©ç”¨ç°æœ‰å…ˆè¿›çš„æ¡†æ¶ï¼ˆæ¯”å¦‚FPNæˆ–[U-Net](http://shichaoxin.com/2022/03/05/è®ºæ–‡é˜…è¯»-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation/)ï¼‰æ¥è¿›è¡Œdense predictionã€‚çº¿æ€§è®¡ç®—å¤æ‚åº¦ç”±ä¸é‡å çª—å£ï¼ˆçº¢è‰²ç½‘æ ¼ï¼‰å†…çš„å±€éƒ¨è‡ªæ³¨æ„åŠ›è®¡ç®—æ¥å®ç°ã€‚æ¯ä¸ªçª—å£å†…çš„patchæ•°é‡æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥å¤æ‚åº¦å’Œå›¾åƒå¤§å°å‘ˆçº¿æ€§ç›¸å…³ã€‚è¿™äº›ä¼˜ç‚¹ä½¿å¾—Swin Transformerå¯ä»¥ä½œä¸ºä»»ä½•CVä»»åŠ¡çš„é€šç”¨backboneï¼Œè€Œä¹‹å‰åŸºäºTransformerçš„æ¡†æ¶åªèƒ½äº§ç”Ÿå•ä¸€åˆ†è¾¨ç‡çš„feature mapså¹¶ä¸”æ˜¯äºŒæ¬¡æ–¹å¤æ‚åº¦ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/1.png)

Fig1(a)å±•ç¤ºäº†Swin Transformeræ‰€å»ºç«‹çš„hierarchical feature mapsï¼Œå³éšç€å±‚æ•°çš„åŠ æ·±ï¼Œå°patché€æ¸è¢«åˆå¹¶ï¼ˆç°è‰²ç½‘æ ¼ï¼‰ã€‚Fig1(b)å±•ç¤ºäº†[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)æ‰€äº§ç”Ÿçš„å•ä¸€ä½åˆ†è¾¨ç‡çš„feature mapsï¼Œç”±äºå…¨å±€è®¡ç®—è‡ªæ³¨æ„åŠ›çš„ç¼˜æ•…ï¼Œå…¶è®¡ç®—å¤æ‚åº¦å’Œå›¾åƒå¤§å°å‘ˆäºŒæ¬¡æ–¹å…³ç³»ã€‚

Swin Transformerçš„ä¸€ä¸ªå…³é”®è®¾è®¡æ˜¯shifted windowï¼Œå¦‚Fig2æ‰€ç¤ºã€‚shifted windowæä¾›äº†å‰ä¸€å±‚çª—å£ä¹‹é—´çš„è¿æ¥ï¼Œè¿™æ˜¾è‘—å¢å¼ºäº†å»ºæ¨¡èƒ½åŠ›ï¼ˆè§è¡¨4ï¼‰ã€‚è¿™ç§ç­–ç•¥åŒæ ·ä¹Ÿå¾ˆæœ‰æ•ˆç‡ï¼šä¸€ä¸ªçª—å£å†…æ‰€æœ‰patchçš„queryå…±ç”¨åŒä¸€ä¸ªkeyã€‚ç›¸æ¯”æ—©æœŸåŸºäºsliding windowçš„è‡ªæ³¨æ„åŠ›æ–¹æ³•ï¼Œç”±äºä¸åŒçš„queryä½¿ç”¨ä¸åŒçš„keyï¼Œæ‰€ä»¥å…¶æ•ˆç‡ä¸é«˜ï¼ˆå› ä¸ºå…±äº«æƒé‡çš„ç¼˜æ•…ï¼Œsliding windowåœ¨CNNæ¡†æ¶ä¸­å¾ˆæœ‰æ•ˆç‡ï¼Œä½†æ˜¯sliding windowåœ¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­å¾ˆéš¾åšåˆ°è¿™ä¸€ç‚¹ï¼‰ã€‚æˆ‘ä»¬çš„å®éªŒè¯æ˜ï¼Œshifted windowæ¯”sliding windowæœ‰æ›´ä½çš„latencyï¼Œå¹¶ä¸”äºŒè€…å»ºæ¨¡èƒ½åŠ›ç›¸ä¼¼ï¼ˆè§è¡¨5å’Œè¡¨6ï¼‰ã€‚shifted windowå¯¹æ‰€æœ‰MLPï¼ˆMulti-Layer Perceptronï¼‰æ¡†æ¶éƒ½æ˜¯æœ‰ç›Šçš„ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/2.png)

Fig2å±•ç¤ºäº†shifted windowæ–¹æ³•ã€‚åœ¨ç¬¬$l$å±‚ï¼ˆFig2å·¦ï¼‰ï¼Œé‡‡ç”¨äº†è§„åˆ™çš„åˆ’åˆ†æ–¹å¼ï¼Œå¹¶åœ¨æ¯ä¸ªçª—å£å†…è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚åœ¨ç¬¬$l+1$å±‚ï¼ˆFig2å³ï¼‰çª—å£å‘å³ä¸‹ç§»åŠ¨äº†2ä¸ªpatchï¼Œå¯¼è‡´äº†æ–°çš„çª—å£åˆ’åˆ†ã€‚æ–°çª—å£çš„è‡ªæ³¨æ„åŠ›è®¡ç®—è·¨è¶Šäº†ç¬¬$l$å±‚çª—å£çš„è¾¹ç•Œï¼Œæä¾›äº†å®ƒä»¬ä¹‹é—´çš„è¿æ¥ã€‚shifted windowæ›´ç›´è§‚çš„è§£é‡Šï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/3.gif)

Swin Transformeråœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ä¸­éƒ½å–å¾—äº†å¾ˆå¥½çš„æˆç»©ã€‚å…¶è¡¨ç°æ˜¾è‘—ä¼˜äº[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)ã€DeiTä»¥åŠ[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ï¼Œå¹¶ä¸”è¿™äº›æ–¹æ³•çš„latencyæ¥è¿‘ã€‚åœ¨COCO test-dev setä¸Šï¼ŒSwin Transformerå–å¾—äº†58.7çš„box APï¼Œæ¯”ä¹‹å‰SOTAçš„Copy-pasteï¼ˆwithout external dataï¼‰é«˜äº†2.7ä¸ªç‚¹ï¼›å…¶è¿˜å–å¾—äº†51.1çš„mask APï¼Œæ¯”ä¹‹å‰SOTAçš„DetectoRSé«˜äº†2.6ä¸ªç‚¹ã€‚åœ¨ADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šï¼Œåœ¨val setä¸Šï¼ŒSwin Transformerå–å¾—äº†53.5çš„mIoUï¼Œæ¯”ä¹‹å‰SOTAçš„SETRæå‡äº†3.2ã€‚åœ¨ImageNet-1Kå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒSwin Transformerçš„top-1å‡†ç¡®ç‡ä¸º87.3%ã€‚

>DeiTï¼šHugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve Ì Je Ìgou. Training data-efficient image transformers & distillation through attention. arXiv preprint arXiv:2012.12877, 2020.ã€‚
>
>Copy-pasteï¼šGolnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, Ekin D Cubuk, Quoc V Le, and Barret Zoph. Simple copy-paste is a strong data augmentation method for instance segmentation. arXiv preprint arXiv:2012.07177, 2020.ã€‚
>
>DetectoRSï¼šSiyuan Qiao, Liang-Chieh Chen, and Alan Yuille. Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution. arXiv preprint arXiv:2006.02334, 2020.ã€‚
>
>SETRï¼šSixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. arXiv preprint arXiv:2012.15840, 2020.ã€‚

æˆ‘ä»¬ç›¸ä¿¡ä¸€ä¸ªæ¨ªè·¨CVå’ŒNLPé¢†åŸŸçš„å¤§ä¸€ç»Ÿæ¨¡å‹æ¡†æ¶æœ‰åŠ©äºè¿™ä¸¤ä¸ªé¢†åŸŸçš„å…±åŒå‘å±•ï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªé¢†åŸŸçš„å»ºæ¨¡çŸ¥è¯†å¯ä»¥æ›´æ·±å…¥åœ°å…±äº«ã€‚æˆ‘ä»¬å¸Œæœ›Swin Transformerçš„å‡ºç°å¯ä»¥ä¿ƒè¿›è¿™æ–¹é¢çš„ç ”ç©¶ã€‚

# 2.Related Work

ğŸ‘‰**CNN and variants**

CNNé€šå¸¸ä½œä¸ºCVé¢†åŸŸçš„æ ‡å‡†ç½‘ç»œæ¨¡å‹ã€‚è™½ç„¶CNNå·²ç»å­˜åœ¨äº†å‡ åå¹´ï¼Œä½†æ˜¯ç›´åˆ°[AlexNet](http://shichaoxin.com/2021/02/03/è®ºæ–‡é˜…è¯»-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/)çš„å‡ºç°ï¼ŒCNNæ‰å¼€å§‹å‘å±•æˆä¸ºä¸»æµã€‚ä»é‚£æ—¶èµ·ï¼Œäººä»¬æå‡ºäº†æ›´å¤šæ›´æ·±å…¥ä¸”æ›´æœ‰æ•ˆçš„CNNæ¡†æ¶ï¼Œæ¨åŠ¨äº†æ·±åº¦å­¦ä¹ åœ¨CVé¢†åŸŸçš„è¿›æ­¥ï¼Œæ¯”å¦‚ï¼š[VGG](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œ[GoogleNet](http://shichaoxin.com/2021/06/01/è®ºæ–‡é˜…è¯»-Going-deeper-with-convolutions/)ï¼Œ[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ï¼Œ[DenseNet](http://shichaoxin.com/2023/11/12/è®ºæ–‡é˜…è¯»-Densely-Connected-Convolutional-Networks/)ï¼Œ[HRNet](http://shichaoxin.com/2023/05/13/è®ºæ–‡é˜…è¯»-Deep-High-Resolution-Representation-Learning-for-Visual-Recognition/)ä»¥åŠEfficientNetç­‰ã€‚é™¤äº†ç½‘ç»œæ¡†æ¶ä¸Šçš„è¿›æ­¥ï¼Œè¿˜æœ‰è®¸å¤šå…³äºæ”¹è¿›å•ä¸ªå·ç§¯å±‚çš„å·¥ä½œï¼Œæ¯”å¦‚depth-wise convolutionå’Œdeformable convolutionã€‚è™½ç„¶CNNåŠå…¶å˜ä½“ä¾ç„¶æ˜¯CVé¢†åŸŸå†…çš„ä¸»è¦backboneï¼Œä½†æˆ‘ä»¬å±•ç¤ºäº†Transformeræ¡†æ¶åœ¨CVä»¥åŠNLPé¢†åŸŸä¹‹é—´ç»Ÿä¸€å»ºæ¨¡çš„å·¨å¤§æ½œåŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨å‡ ä¸ªåŸºç¡€çš„CVä»»åŠ¡ä¸Šéƒ½å–å¾—äº†éå¸¸å¥½çš„è¡¨ç°ã€‚

>EfficientNetï¼šMingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. In International Conference on Machine Learning, pages 6105â€“6114. PMLR, 2019.ã€‚

ğŸ‘‰**Self-attention based backbone architectures**

å—åˆ°NLPé¢†åŸŸå†…è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥åŠ[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)å¤§è·æˆåŠŸçš„å¯å‘ï¼Œä¸€äº›ç ”ç©¶å°è¯•å°†[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ä¸­çš„éƒ¨åˆ†æˆ–æ‰€æœ‰å·ç§¯å±‚æ›¿æ¢ä¸ºè‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚åœ¨è¿™äº›ç ”ç©¶ä¸­ï¼Œåœ¨æ¯ä¸ªlocal windowå†…ä»¥åƒç´ ä¸ºå•ä½è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œä»¥è¾¾åˆ°å‡†ç¡®ç‡å’ŒFLOPsä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚ç„¶è€Œï¼Œå®ƒä»¬é«˜æ˜‚çš„memory accessæˆæœ¬å¯¼è‡´å®é™…latencyæ˜æ˜¾å¤§äºCNNç½‘ç»œæ¡†æ¶ã€‚å› æ­¤æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨sliding windowsï¼Œè€Œæ˜¯åœ¨è¿ç»­å±‚ä¹‹é—´é‡‡ç”¨shift windowsï¼Œä½¿å…¶åœ¨é€šç”¨ç¡¬ä»¶ä¸­å¯ä»¥æ›´é«˜æ•ˆçš„å®ç°ã€‚

ğŸ‘‰**Self-attention/Transformers to complement CNNs**

å¦ä¸€ç ”ç©¶æ–¹å‘æ˜¯ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æˆ–[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)æ¥åŠ å¼ºæ ‡å‡†çš„CNNæ¡†æ¶ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯è¢«ç”¨äºè¡¥å……backbonesæˆ–head networksã€‚æœ€è¿‘ï¼Œ[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)ä¸­çš„encoder-decoderè®¾è®¡å·²è¢«ç”¨äºç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¯¹ä¸Šè¿°å·¥ä½œè¿›è¡Œäº†è¿›ä¸€æ­¥çš„æ‰©å±•ã€‚

ğŸ‘‰**Transformer based vision backbones**

å’Œæˆ‘ä»¬å·¥ä½œæœ€ç›¸å…³çš„æ˜¯[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)åŠå…¶åç»­çš„è¡ç”Ÿæ¨¡å‹ã€‚[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)å¼€åˆ›æ€§çš„ç›´æ¥å°†[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)æ¡†æ¶åº”ç”¨äºæ— é‡å åŒºåŸŸä¸”ä¸­ç­‰å°ºå¯¸çš„å›¾åƒpatchï¼Œä»è€Œæ‰§è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚ä¸CNNç›¸æ¯”ï¼Œ[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­åšåˆ°äº†é€Ÿåº¦å’Œç²¾åº¦çš„è‰¯å¥½å¹³è¡¡ã€‚è™½ç„¶[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)éœ€è¦å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®é›†ï¼ˆæ¯”å¦‚JFT-300Mï¼‰æ‰èƒ½è¡¨ç°è‰¯å¥½ï¼Œä½†æ˜¯å…¶è¡ç”Ÿæ¨¡å‹DeiTé€šè¿‡å¼•å…¥å¤šç§è®­ç»ƒç­–ç•¥ï¼Œä½¿å¾—[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)ä½¿ç”¨è¾ƒå°çš„ImageNet-1Kæ•°æ®é›†ä¹Ÿå¯ä»¥æœ‰ä¸é”™çš„è¡¨ç°ã€‚[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„ç»“æœä»¤äººé¼“èˆï¼Œä½†æ˜¯ç”±äºå…¶ä½¿ç”¨ä½åˆ†è¾¨ç‡çš„feature mapsä¸”è®¡ç®—å¤æ‚åº¦éšå›¾åƒå¤§å°å‘ˆäºŒæ¬¡æ–¹å¢é•¿ï¼Œæ‰€ä»¥å…¶ç»“æ„ä¸é€‚åˆç”¨ä½œdense vision tasksçš„backbonesï¼ŒåŒæ—¶ä¹Ÿä¸é€‚ç”¨äºè¾“å…¥å›¾åƒåˆ†è¾¨ç‡è¾ƒé«˜çš„æ—¶å€™ã€‚æœ‰ä¸€äº›ç ”ç©¶ç›´æ¥é€šè¿‡ä¸Šé‡‡æ ·æˆ–åå·ç§¯å°†[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)åº”ç”¨äºç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰dense vision tasksï¼Œä½†æ€§èƒ½ç›¸å¯¹è¾ƒä½ã€‚è¿˜æœ‰ä¸€äº›ç ”ç©¶é€šè¿‡ä¿®æ”¹[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)çš„ç»“æ„æ¥æå‡å…¶åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ä¸è¿™äº›æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šï¼ŒSwin Transformerå®ç°äº†æœ€ä½³çš„é€Ÿåº¦ä¸ç²¾åº¦ä¹‹é—´çš„å¹³è¡¡ï¼Œå°½ç®¡æˆ‘ä»¬çš„å·¥ä½œé‡ç‚¹æ˜¯é€šç”¨æ€§èƒ½è€Œä¸æ˜¯å›¾åƒåˆ†ç±»ã€‚è¿˜æœ‰ä¸€äº›ç ”ç©¶ä¹Ÿæ¢ç´¢äº†åœ¨[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)ä¸Šæ„å»ºå¤šåˆ†è¾¨ç‡çš„feature mapsã€‚ä½†æ˜¯è¿™äº›ç ”ç©¶çš„è®¡ç®—å¤æ‚åº¦ä»ç„¶å’Œå›¾åƒå¤§å°å‘ˆäºŒæ¬¡æ–¹å…³ç³»ï¼Œè€Œæˆ‘ä»¬æ–¹æ³•çš„è®¡ç®—å¤æ‚åº¦æ˜¯çº¿æ€§çš„ï¼Œå¹¶ä¸”æ˜¯å±€éƒ¨æ“ä½œã€‚æˆ‘ä»¬çš„æ–¹æ³•å³é«˜æ•ˆåˆæœ‰æ•ˆï¼Œåœ¨COCOç›®æ ‡æ£€æµ‹ä»»åŠ¡å’ŒADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šå‡å–å¾—äº†SOTAçš„æˆç»©ã€‚

# 3.Method

## 3.1.Overall Architecture

Swin Transformerçš„ç»“æ„è§Fig3ï¼Œå±•ç¤ºçš„æ˜¯tiny versionï¼ˆå³Swin-Tï¼‰ã€‚é¦–å…ˆï¼Œå’Œ[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)ç±»ä¼¼ï¼Œå°†RGBå›¾åƒåˆ†æˆæ— é‡å åŒºåŸŸçš„patchã€‚æ¯ä¸ªpatchéƒ½è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªtokenï¼Œå®ƒçš„featureå°±æ˜¯å°†åŸå§‹çš„åƒç´ å€¼å±•å¼€ã€‚åœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼Œpatch sizeä¸º$4\times 4$ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªpatchçš„featureç»´åº¦ä¸º$4\times 4\times 3 = 48$ã€‚é€šè¿‡ä¸€ä¸ªçº¿æ€§embedding layerå¯ä»¥å°†ç‰¹å¾æ˜ å°„åˆ°ä»»æ„ç»´åº¦ï¼ˆå‡è®¾ä¸º$C$ï¼‰ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/4.png)

Fig3ä¸­çš„"Patch Partition"æŒ‡çš„æ˜¯å°†è¾“å…¥å›¾åƒåˆ†å‰²æˆpatchï¼Œæ¯ä¸ªpatchçš„å¤§å°ä¸º$4 \times 4$ï¼Œé‚£ä¸€å…±å¯å¾—åˆ°$\frac{H}{4} \times \frac{W}{4}$ä¸ªpatchï¼Œæ¯ä¸ªpatchçš„ç»´åº¦ä¸º$4\times 4\times 3=48$ã€‚å› æ­¤ç»è¿‡Patch Partitionä¹‹åï¼Œå¾—åˆ°çš„feature mapç»´åº¦ä¸º$\frac{H}{4} \times \frac{W}{4} \times 48$ã€‚

Fig3ä¸­çš„"Linear Embedding"æ˜¯ä¸€ä¸ªçº¿æ€§æ˜ å°„å±‚ï¼Œå°†ç»´åº¦48æ˜ å°„åˆ°ç»´åº¦$C$ï¼Œå³ç»è¿‡Linear Embeddingåçš„feature mapç»´åº¦ä¸º$\frac{H}{4} \times \frac{W}{4} \times C$ã€‚

Fig3ä¸­Swin Transformer blocksçš„å±‚æ•°éƒ½æ˜¯å¶æ•°ï¼Œå› ä¸ºæ¯ä¸ªblockéƒ½åŒ…å«ä¸¤å±‚ï¼Œè§Fig3(b)ã€‚Swin Transformer blocksä¸ä¼šæ”¹å˜feature mapçš„ç»´åº¦ã€‚

Fig3ä¸­"Patch Merging"çš„è§£é‡Šè§ä¸‹å›¾ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/5.png)

ç»´åº¦çš„å˜åŒ–ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/6.png)

è¿™äº›stagesè”åˆèµ·æ¥äº§ç”Ÿäº†hierarchical representationï¼Œå’Œä¸€äº›å…¸å‹CNNç½‘ç»œï¼ˆæ¯”å¦‚[VGG](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)å’Œ[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ï¼‰çš„feature mapæœ‰ç€ä¸€æ ·çš„åˆ†è¾¨ç‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ–¹ä¾¿çš„å–ä»£ç°æœ‰CVä»»åŠ¡æ¨¡å‹ä¸­çš„backboneã€‚

ğŸ‘‰**Swin Transformer block**

Swin Transformerå°†æ ‡å‡†çš„multi-head self attentionï¼ˆMSAï¼‰æ¨¡å—æ›¿æ¢ä¸ºäº†åŸºäºshifted windowsçš„MSAæ¨¡å—ï¼ˆè¯¦è§ç¬¬3.2éƒ¨åˆ†ï¼‰ï¼Œå…¶ä»–å±‚ä¿æŒä¸å˜ã€‚å¦‚Fig3(b)æ‰€ç¤ºï¼ŒSwin Transformer blockåŒ…å«ä¸€ä¸ªåŸºäºshifted windowsçš„MSAæ¨¡å—ï¼Œåé¢è·Ÿä¸€ä¸ª2å±‚çš„MLPï¼ˆæ¿€æ´»å‡½æ•°ä¸º[GELU](http://shichaoxin.com/2022/04/09/è®ºæ–‡é˜…è¯»-GAUSSIAN-ERROR-LINEAR-UNITS-(GELUS)/)ï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨æ¯ä¸ªMSAæ¨¡å—å’Œæ¯ä¸ªMLPä¹‹é—´è¿˜æœ‰ä¸€ä¸ª[LayerNorm](http://shichaoxin.com/2022/03/19/è®ºæ–‡é˜…è¯»-Layer-Normalization/)å±‚ï¼Œå¹¶ä¸”æ¯ä¸ªæ¨¡å—ä¹‹åè¿˜æœ‰æ®‹å·®è¿æ¥ã€‚

## 3.2.Shifted Window based Self-Attention

æ— è®ºæ˜¯æ ‡å‡†çš„[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/)æ¡†æ¶è¿˜æ˜¯[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)ï¼Œéƒ½ä½¿ç”¨äº†å…¨å±€è‡ªæ³¨æ„åŠ›ï¼Œå³è®¡ç®—äº†æŸä¸€tokenå’Œå…¶ä»–æ‰€æœ‰tokensä¹‹é—´çš„å…³ç³»ã€‚å…¨å±€è®¡ç®—ä½¿å¾—è®¡ç®—å¤æ‚åº¦å’Œtokensæ•°é‡å‘ˆäºŒæ¬¡ç›¸å…³ï¼Œè¿™å¯¼è‡´å®ƒä¸é€‚ç”¨äºè®¸å¤šéœ€è¦å¤§é‡tokensè¿›è¡Œdense predictionæˆ–ä½¿ç”¨é«˜åˆ†è¾¨ç‡å›¾åƒçš„CVä»»åŠ¡ã€‚

ğŸ‘‰**Self-attention in non-overlapped windows**

ä¸ºäº†æ›´æœ‰æ•ˆç‡çš„å»ºæ¨¡ï¼Œæˆ‘ä»¬å»ºè®®åœ¨local windowså†…è®¡ç®—è‡ªæ³¨æ„åŠ›ã€‚è¿™äº›çª—å£å‡åŒ€åˆ†å¸ƒä¸”æ— é‡å åŒºåŸŸã€‚å‡è®¾æ¯ä¸ªçª—å£åŒ…å«$M\times M$ä¸ªpatchï¼Œä¸€å¼ å›¾åƒä¸€å…±æœ‰$h \times w$ä¸ªpatchï¼Œåˆ™å…¨å±€MSAæ¨¡å—çš„è®¡ç®—å¤æ‚åº¦è§å¼(1)ï¼ŒåŸºäºwindowçš„è®¡ç®—å¤æ‚åº¦è§å¼(2)ï¼š

$$\Omega (MSA) = 4hwC^2 + 2(hw)^2C \tag{1}$$

$$\Omega (W-MSA) = 4hwC^2 + 2M^2 hw C \tag{2}$$

>æˆ‘ä»¬åœ¨ç¡®å®šå¤æ‚åº¦æ—¶çœç•¥äº†SoftMaxçš„è®¡ç®—ã€‚

å½“$M$å›ºå®šæ—¶ï¼ˆé»˜è®¤$M=7$ï¼‰ï¼Œå¼(1)çš„è®¡ç®—å¤æ‚åº¦å’Œpatchæ•°é‡ï¼ˆ$hw$ï¼‰å‘ˆäºŒæ¬¡æ–¹å…³ç³»ï¼Œå¼(2)çš„è®¡ç®—å¤æ‚åº¦å’Œpatchæ•°é‡å‘ˆçº¿æ€§å…³ç³»ã€‚å½“$hw$æ¯”è¾ƒå¤§æ—¶ï¼Œå…¨å±€è‡ªæ³¨æ„åŠ›çš„è®¡ç®—å¤æ‚åº¦é€šå¸¸æ˜¯æ— æ³•è´Ÿæ‹…çš„ï¼Œè€ŒåŸºäºçª—å£çš„è‡ªæ³¨æ„åŠ›çš„è®¡ç®—æˆæœ¬æ˜¯å¯æ¥å—çš„ã€‚

æ¥ä¸‹æ¥ç®€å•æ¨å¯¼ä¸€ä¸‹å¼(1)å’Œå¼(2)ã€‚ä¸‹å›¾æ˜¯ä¸€ä¸ªå•å¤´è‡ªæ³¨æ„åŠ›çš„æ ‡å‡†è®¡ç®—è¿‡ç¨‹ï¼Œé¦–å…ˆæ˜¯ä¸€ä¸ªè¾“å…¥ï¼Œå…¶åˆ†åˆ«ä¹˜ä¸Š3ä¸ªç³»æ•°çŸ©é˜µå¾—åˆ°$q,k,v$ï¼Œé€šè¿‡$q,k$ç›¸ä¹˜å¾—åˆ°è‡ªæ³¨æ„åŠ›çŸ©é˜µ$A$ï¼Œç„¶å$A$å’Œ$v$è¿›è¡Œç›¸ä¹˜ã€‚æˆ‘ä»¬å°†è¿™äº›å‘é‡è¯¥æœ‰çš„ç»´åº¦ä¹Ÿç”¨çº¢å­—æ ‡æ³¨åœ¨äº†ä¸‹å›¾ä¸­ï¼Œå‡è®¾æœ‰$a$ä¸ªå¤´ä¸”$q,k,v$çš„ç»´åº¦å¹³å‡åˆ†ä¸º$\frac{C}{a}$ï¼ˆè¿™ä¸ªå‡è®¾çš„åŸå› æ˜¯[Transformer](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/#322multi-head-attention)ä¸€æ–‡ä¸­ç¬¬3.2.2éƒ¨åˆ†æåˆ°â€œç”±äºæ¯ä¸ªHeadçš„ç»´åº¦é™ä½ï¼Œæ€»çš„è®¡ç®—æˆæœ¬ä¸å…¨ç»´åº¦å•å¤´æ³¨æ„åŠ›çš„è®¡ç®—æˆæœ¬ç›¸ä¼¼â€ï¼‰ã€‚æ­¤æ—¶ç”¨äºè®¡ç®—$q,k,v$çš„3ä¸ªç³»æ•°çŸ©é˜µéƒ½ä¸º$C\times \frac{C}{a}$å¤§å°ï¼Œè®¡ç®—$q$çš„å¤æ‚åº¦ï¼ˆä»…ç»Ÿè®¡ä¹˜æ³•è¿ç®—ï¼ŒååŒï¼‰ä¸º$hw\frac{C^2}{a}$ï¼Œ$k,v$ä¹Ÿä¸€æ ·ï¼Œæ‰€ä»¥è®¡ç®—$q,k,v$çš„å¤æ‚åº¦ä¸º$3hw\frac{C^2}{a}$ã€‚è®¡ç®—è‡ªæ³¨æ„åŠ›çŸ©é˜µ$A$çš„å¤æ‚åº¦ä¸º$(hw)^2\frac{C}{a}$ï¼ˆå¿½ç•¥é™¤ä»¥$\sqrt{q_k}$å’ŒSoftMaxçš„è®¡ç®—é‡ï¼‰ã€‚$A$å’Œ$v$ç›¸ä¹˜çš„è®¡ç®—å¤æ‚åº¦ä¹Ÿä¸º$(hw)^2\frac{C}{a}$ã€‚å°†ä¸Šè¿°åŠ æ€»å¾—åˆ°å•å¤´çš„è®¡ç®—å¤æ‚åº¦ä¸º$\frac{1}{a} [ 3hwC^2 + 2(hw)^2 C ]$ï¼Œé‚£ä¹ˆä¸€å…±$a$ä¸ªå¤´ï¼Œéœ€è¦è®¡ç®—$a$æ¬¡ã€‚æœ€åå°†å•å¤´çš„è¾“å‡º$hw \times \frac{C}{a}$æ‹¼æ¥åœ¨ä¸€èµ·ç»´åº¦ä¸º$hw \times C$ï¼Œå†ä¹˜ä¸Šä¸€ä¸ªè½¬åŒ–çŸ©é˜µ$W^O$ï¼ˆç»´åº¦ä¸º$C\times C$ï¼‰ï¼Œæœ€ç»ˆå¾—åˆ°å…¨å±€MSAæ¨¡å—çš„å¤æ‚åº¦ä¸ºï¼š

$$a * \frac{1}{a} [ 3hwC^2 + 2(hw)^2 C ] + hwC^2$$

å³å¼(1)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/7.png)

æ ¹æ®å¼(1)å¯å¾—ä¸€ä¸ª$M \times M$å¤§å°çš„çª—å£çš„MSAè®¡ç®—å¤æ‚åº¦ï¼ˆå³å¼(1)ä¸­æœ‰$h=w=M$ï¼‰ä¸ºï¼š

$$4M^2C^2 + 2M^4C$$

é‚£ä¹ˆæˆ‘ä»¬ç°åœ¨ä¸€å…±æœ‰$\frac{h}{M} \times \frac{w}{M}$ä¸ªçª—å£ï¼Œåˆ™æ‰€æœ‰çª—å£çš„æ€»è®¡ç®—å¤æ‚åº¦ä¸ºï¼š

$$\frac{h}{M} \times \frac{w}{M} \times (4M^2C^2 + 2M^4C)$$

å³å¼(2)ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœ$h=w=112,M=7,C=128$ï¼Œé‚£ä¹ˆW-MSAæ¯”MSAèŠ‚çœçš„è®¡ç®—é‡ä¸º40124743680FLOPsã€‚

ğŸ‘‰**Shifted window partitioning in successive blocks**

W-MSAæ¨¡å—ç¼ºå°‘çª—å£ä¹‹é—´çš„è”ç³»ï¼Œè¿™é™åˆ¶äº†å»ºæ¨¡èƒ½åŠ›ã€‚ä¸ºäº†åœ¨ä¿æŒæ— é‡å åŒºåŸŸçª—å£è®¡ç®—é«˜æ•ˆæ€§çš„åŒæ—¶å¼•å…¥ä¸åŒçª—å£ä¹‹é—´çš„è¿æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†shifted windowçš„æ–¹æ³•ã€‚

å¦‚Fig2æ‰€ç¤ºï¼Œç¬¬ä¸€ä¸ªæ¨¡å—ä½¿ç”¨å¸¸è§„çš„çª—å£åˆ’åˆ†ç­–ç•¥ï¼Œå°†$8\times 8$å¤§å°çš„feature mapåˆ’åˆ†ä¸º$2\times 2$ä¸ªçª—å£ï¼Œæ¯ä¸ªçª—å£çš„å¤§å°ä¸º$4\times 4$ï¼ˆå³$M=4$ï¼‰ã€‚ç„¶ååœ¨ä¸‹ä¸€ä¸ªæ¨¡å—ä¸­ï¼Œå°†çª—å£å‘å³ä¸‹ç§»åŠ¨$(\lfloor \frac{M}{2} \rfloor,\lfloor \frac{M}{2} \rfloor)$ã€‚

Swin Transformer blocksçš„è®¡ç®—å¦‚ä¸‹ï¼š

$$\hat{\mathbf{z}}^l = \text{W-MSA}( \text{LN} (\mathbf{z}^{l-1})) + \mathbf{z}^{l-1},$$

$$\mathbf{z}^l = \text{MLP} (\text{LN} (\hat{\mathbf{z}}^l)) + \hat{\mathbf{z}}^l,$$

$$\hat{\mathbf{z}}^{l+1} = \text{SW-MSA}( \text{LN} (\mathbf{z}^l)) + \mathbf{z}^l,$$

$$\mathbf{z}^{l+1} = \text{MLP} (\text{LN} (\hat{\mathbf{z}}^{l+1})) + \hat{\mathbf{z}}^{l+1}, \tag{3}$$

å…¶ä¸­ï¼Œ$\hat{\mathbf{z}}^l$å’Œ$\mathbf{z}^l$åˆ†åˆ«è¡¨ç¤ºç¬¬$l$å±‚ä¸­(S)W-MSAæ¨¡å—æˆ–MLPæ¨¡å—çš„è¾“å‡ºç‰¹å¾ã€‚W-MSAå’ŒSW-MSAåˆ†åˆ«è¡¨ç¤ºåŸºäºå¸¸è§„çª—å£åˆ’åˆ†å’ŒåŸºäºshiftedçª—å£åˆ’åˆ†çš„å¤šå¤´è‡ªæ³¨æ„åŠ›ã€‚

shifted windowæ–¹æ³•å¼•å…¥äº†å‰ä¸€å±‚ä¸­ç›¸é‚»ä¸”éé‡å çª—å£ä¹‹é—´çš„è¿æ¥ï¼Œå¦‚è¡¨4æ‰€ç¤ºï¼Œè¿™ä¸€æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­éƒ½å¾ˆæœ‰æ•ˆã€‚

ğŸ‘‰**Efficient batch computation for shifted configuration**

shifted windowçš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ä¼šå¯¼è‡´æ›´å¤šçš„çª—å£ï¼Œå¦‚Fig2æ‰€ç¤ºï¼Œçª—å£æ•°ç›®ä»$\lceil \frac{h}{M} \rceil \times \lceil \frac{w}{M} \rceil $å¢åŠ è‡³$(\lceil \frac{h}{M} \rceil +1)\times (\lceil \frac{w}{M} \rceil+1)$ï¼Œå¹¶ä¸”éƒ¨åˆ†çª—å£çš„å¤§å°ä¼šå°äº$M \times M$ï¼ˆä¸ºäº†ä½¿çª—å£å¤§å°$(M, M)$å¯ä»¥è¢«feature mapå¤§å°$(h,w)$æ•´é™¤ï¼Œå¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨feature mapçš„å³ä¸‹æ–¹è¿›è¡Œpaddingï¼‰ã€‚ä¸€ä¸ªç®€å•çš„è§£å†³åŠæ³•æ˜¯å°†å¤§å°ä¸è¶³$M\times M$çš„çª—å£paddingè‡³$M\times M$ï¼Œç„¶ååœ¨è®¡ç®—æ³¨æ„åŠ›æ—¶maskæ‰paddingæ·»åŠ çš„å€¼ã€‚å¦‚æœå¸¸è§„çª—å£åˆ’åˆ†ç­–ç•¥å¾—åˆ°$2\times 2$ä¸ªçª—å£ï¼Œé‚£ä¹ˆshiftä¹‹åï¼Œé€šè¿‡è¿™ç§ç®€å•çš„è§£å†³åŠæ³•ï¼Œçª—å£ä¼šå¢åŠ è‡³$3\times 3$ä¸ªï¼Œå¢åŠ äº†2.25å€ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›´æœ‰æ•ˆç‡çš„æ–¹æ³•ï¼Œè§Fig4ã€‚æŒ‰ç…§Fig4æ‰€ç¤ºçš„æ–¹æ³•è¿›è¡Œç§»ä½ï¼ˆä½œè€…ç§°ä¹‹ä¸ºcyclic-shiftï¼‰ä¹‹åï¼Œä¸€ä¸ªæ–°çš„çª—å£ï¼ˆå³batched windowï¼‰å¯èƒ½ä¼šåŒ…å«å¤šä¸ªåŸæ¥å¹¶ä¸ç›¸é‚»çš„å­çª—å£ï¼Œç„¶åé€šè¿‡maskæœºåˆ¶å°†è‡ªæ³¨æ„åŠ›è®¡ç®—é™åˆ¶åœ¨æ¯ä¸ªå­çª—å£å†…ã€‚é€šè¿‡cyclic-shiftï¼Œç›¸æ¯”å¸¸è§„çª—å£åˆ’åˆ†ç­–ç•¥ï¼Œshifted windowä¸å†å¯¼è‡´çª—å£æ•°é‡çš„å¢åŠ ï¼Œä¿æŒäº†åŸæœ‰çš„æ•ˆç‡ã€‚è¡¨5å±•ç¤ºäº†è¿™ç§æ–¹æ³•çš„low latencyã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/8.png)

è¿™é‡Œå†ç»§ç»­è¯¦è§£ä¸€ä¸‹shifted windowã€‚å¦‚Fig2æ‰€ç¤ºï¼Œç»è¿‡shifted windowä¹‹åï¼Œçª—å£çš„æ•°é‡å˜å¤šäº†ï¼Œå¹¶ä¸”æ¯ä¸ªçª—å£çš„å¤§å°éƒ½ä¸ä¸€æ ·ï¼Œè¿™å°±ä½¿å¾—æˆ‘ä»¬ä¸èƒ½å°†å…¶æ‰“åŒ…æˆä¸€ä¸ªbatchå¿«é€Ÿå¤„ç†ï¼Œå› ä¸ºæ¯ä¸ªåºåˆ—ï¼ˆå³æ¯ä¸ªçª—å£ï¼‰çš„tokenæ•°é‡ï¼ˆå³patchæ•°é‡ï¼‰éƒ½ä¸ä¸€æ ·ï¼Œè€ŒTransformeréœ€è¦è¾“å…¥çš„åºåˆ—é•¿åº¦å§‹ç»ˆä¿æŒä¸€è‡´ã€‚å¯ä»¥å¾ˆå®¹æ˜“çš„æƒ³åˆ°ä¸€ç§ç®€å•ç²—æš´çš„è§£å†³åŠæ³•ï¼Œå°±æ˜¯å°†æ¯ä¸ªçª—å£éƒ½paddingæˆ$4\times 4$å¤§å°ï¼Œä½†è¿™æ ·åšå°±å¢åŠ äº†å¤§é‡çš„è®¡ç®—æˆæœ¬ã€‚é‚£shifted windowä¹‹åï¼Œæ€ä¹ˆæ‰èƒ½æ—¢ä¿æŒ4ä¸ªçª—å£ä¸å¢åŠ åˆä¿è¯æ¯ä¸ªçª—å£å¤§å°ä¸€è‡´å‘¢ï¼Ÿä½œè€…æå‡ºäº†ä¸€ç§åŸºäºmaskå’Œcyclic-shiftçš„æ–¹å¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚Fig4å·¦èµ·ç¬¬äºŒå¼ å›¾æ‰€ç¤ºï¼Œé€šè¿‡å¯¹Aï¼ŒBå’ŒCä¸‰ä¸ªåŒºåŸŸçš„å¾ªç¯ç§»ä½ï¼Œçª—å£æ•°é‡åˆå›åˆ°äº†4ä¸ªä¸”æ¯ä¸ªçª—å£çš„å¤§å°éƒ½æ˜¯$4\times 4$ã€‚çª—å£çš„æ•°é‡ä¸å˜å°±æ„å‘³ç€è®¡ç®—å¤æ‚åº¦ä¸å˜ï¼Œå³æ²¡æœ‰å¼•èµ·è®¡ç®—å¤æ‚åº¦çš„å¢åŠ ã€‚ä½†è¿™ä¹Ÿå¯¼è‡´äº†ä¸€ä¸ªæ–°çš„é—®é¢˜ï¼Œå³ä¸€ä¸ªçª—å£å†…åŸæœ¬ä¸ç›¸é‚»çš„åŒºåŸŸä¹‹é—´ä¸åº”è¯¥åšè‡ªæ³¨æ„åŠ›ã€‚æ­¤æ—¶ä½œè€…ä¾¿å¼•å…¥äº†maskæœºåˆ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåªç”¨ä¸€æ¬¡å‰å‘è¿‡ç¨‹å°±è®¡ç®—å‡ºäº†æ‰€æœ‰åŒºåŸŸçš„è‡ªæ³¨æ„åŠ›ã€‚ç®—å®Œæ‰€æœ‰åŒºåŸŸçš„è‡ªæ³¨æ„åŠ›ä¹‹åï¼Œæœ€åä¸€æ­¥ä¾¿æ˜¯æŠŠå¾ªç¯ç§»ä½çš„åŒºåŸŸè¿˜åŸåˆ°åŸæ¥çš„ä½ç½®ï¼Œä»¥ä¿è¯åŸæœ‰è¯­ä¹‰ä¿¡æ¯çš„åŸºæœ¬ä¸å˜ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/9.png)

æ¥ä¸‹æ¥æ¥çœ‹ä¸‹maskæœºåˆ¶çš„å…·ä½“å®ç°ã€‚ä¸Šå›¾å·¦å°±æ˜¯ç»è¿‡å¾ªç¯ç§»ä½åçš„çª—å£ã€‚æ¯”å¦‚ï¼ŒåŒºåŸŸ2+åŒºåŸŸ5å°±æ˜¯Fig4ä¸­çš„Bï¼ŒåŒºåŸŸ6+åŒºåŸŸ7å°±æ˜¯Fig4ä¸­çš„Cï¼ŒåŒºåŸŸ8å°±æ˜¯Fig4ä¸­çš„Aã€‚ä¸Šå›¾å³å°±æ˜¯å„ä¸ªçª—å£å¯¹åº”çš„maskã€‚å› ä¸ºçª—å£0å†…çš„patchåŸæœ¬å°±åœ¨ä¸€èµ·ï¼Œæ‰€ä»¥ä¸éœ€è¦maskæ“ä½œï¼Œå³maskçš„å€¼éƒ½ä¸º0ã€‚ä»¥ä¸Šå›¾ä¸ºä¾‹ï¼Œfeature mapå¤§å°ä¸º$14 \times 14$ï¼Œæ¯ä¸ªçª—å£çš„å¤§å°ä¸º$7\times 7$ï¼Œshifted windowæ˜¯å¾€å³ä¸‹ç§»åŠ¨äº†3ä¸ªpatchï¼Œä»è€Œå¯ä»¥æ¨å¯¼å‡ºï¼ŒåŒºåŸŸ3çš„å¤§å°æ˜¯$4\times 7$ï¼ŒåŒºåŸŸ6çš„å¤§å°æ˜¯$3\times 7$ã€‚æˆ‘ä»¬å…ˆæ¥è®¡ç®—çª—å£2çš„maskï¼Œå°†çª—å£2çš„patchæŒ‰ä»å·¦å¾€å³ï¼Œä»ä¸Šå¾€ä¸‹çš„é¡ºåºä¾æ¬¡æ‹æ‰æ”¾åœ¨ä¸€èµ·ï¼Œç›¸å½“äºæ˜¯å¾—åˆ°ä¸€ä¸ª$49 \times C$çš„çŸ©é˜µï¼ˆ$C$ä¸ºpatchæ‹æˆä¸€ç»´åçš„é•¿åº¦ï¼‰ï¼Œå‰28è¡Œä¸ºåŒºåŸŸ3ï¼Œå21è¡Œä¸ºåŒºåŸŸ6ã€‚ç„¶åè¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—ï¼ˆè¿™é‡Œä¸æ˜¯çœŸçš„çŸ©é˜µç›¸ä¹˜ï¼Œåªæ˜¯ç®€åŒ–è¡¨ç¤ºè‡ªæ³¨æ„åŠ›çš„è®¡ç®—ï¼‰ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/10.png)

åŒºåŸŸ3å’ŒåŒºåŸŸ6ä¹‹é—´çš„è‡ªæ³¨æ„åŠ›è®¡ç®—å¯¹åº”çš„maskéƒ¨åˆ†ï¼ˆå³ç°è‰²éƒ¨åˆ†ï¼‰ä¼šæ˜¯ä¸€ä¸ªå¾ˆå°çš„è´Ÿæ•°ï¼ˆæ¯”å¦‚-100ï¼Œè¿™æ ·åç»­åœ¨ç»è¿‡SoftMaxå‡½æ•°æ—¶å°±ä¼šæ¥è¿‘äº0ï¼‰ã€‚masked MHSAæ¨¡å—çš„ç”¨æ³•è§[é“¾æ¥](http://shichaoxin.com/2022/03/26/è®ºæ–‡é˜…è¯»-Attention-Is-All-You-Need/#323applications-of-attention-in-our-model)ï¼Œç®€å•æ¥è¯´å°±æ˜¯maskä¼šåŠ åœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—çš„ç»“æœä¸Šã€‚å…¶ä»–çª—å£çš„maskè®¡ç®—ç±»ä¼¼ï¼Œä¸å†èµ˜è¿°ã€‚æ­¤æ—¶å°±å¯ä»¥ä¸€ä¸ªbatchï¼ˆåŒ…å«4ä¸ªçª—å£ï¼‰ä¸€èµ·è¿›Transformer blockçš„SW-MSAæ¨¡å—ï¼Œç„¶åç»è¿‡å¾ªç¯ç§»ä½ã€maskè®¡ç®—ã€å¤åŸç­‰ä¸€ç³»åˆ—æ“ä½œåï¼Œåœ¨è¿›å…¥åé¢çš„MLPæ¨¡å—ã€‚

ğŸ‘‰**Relative position bias**

åœ¨ä½ç½®ç¼–ç æ–¹é¢ï¼ŒSwin Transformeré‡‡ç”¨äº†Relative position biaçš„æ–¹å¼ï¼Œå…·ä½“å®ç°è§ä¸‹ï¼ˆå‡è®¾çª—å£å¤§å°$M=2$ï¼‰ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/11.png)

æ­¤æ—¶æˆ‘ä»¬éœ€è¦å°†ç›¸å¯¹ä½ç½®çŸ©é˜µä¸­çš„äºŒç»´åæ ‡è½¬æ¢æˆä¸€ç»´ï¼Œå¦‚æœä»…æ˜¯é€šè¿‡æ¨ªåæ ‡åŠ çºµåæ ‡çš„æ–¹æ³•æ¥è½¬æ¢ä¼šæŸå¤±ä¸€å®šçš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œæ¯”å¦‚ä»¥è“è‰²åŒºåŸŸAä¸º$(0,0)$ä¸ºä¾‹ï¼Œå…¶å³è¾¹çš„åŒºåŸŸBä¸º$(0,-1)$ï¼Œå…¶ä¸‹è¾¹çš„åŒºåŸŸCä¹Ÿä¸º$(-1,0)$ï¼Œè¿™ä¸¤ä¸ªåŒºåŸŸçš„æ¨ªçºµåæ ‡ç›¸åŠ éƒ½æ˜¯-1ï¼Œè¿™å°±æ— æ³•åŒºåˆ†è¿™ä¸¤ä¸ªåŒºåŸŸäº†ã€‚å› æ­¤ï¼Œä½œè€…çš„åšæ³•å¦‚ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/12.png)

1. å…ˆå°†æ¨ªçºµåæ ‡éƒ½åŠ ä¸Š$M-1$ä»¥ä¿è¯åæ ‡å€¼æ²¡æœ‰è´Ÿæ•°ï¼ˆåæ ‡å€¼æœ€å°ä¸º0ï¼‰ã€‚
2. ä»…å°†æ¨ªåæ ‡ä¹˜ä¸Š$2M-1$ã€‚
3. æ¨ªçºµåæ ‡ç›¸åŠ ï¼Œå¾—åˆ°ç›¸å¯¹ä½ç½®ç´¢å¼•çŸ©é˜µã€‚
4. é€šè¿‡relative position bias tableå°†ç›¸å¯¹ä½ç½®ç´¢å¼•çŸ©é˜µä¸­çš„ç›¸å¯¹ä½ç½®ç´¢å¼•æ›¿æ¢ä¸ºbiasï¼Œå¾—åˆ°æœ€ç»ˆçš„relative position biasï¼ˆå³ä¸‹é¢å…¬å¼ä¸­çš„$B$ï¼‰ã€‚

åœ¨æ·»åŠ relative position biasä¹‹åï¼Œæ³¨æ„åŠ›çš„è®¡ç®—å¯è¡¨ç¤ºä¸ºï¼š

$$\text{Attention} (Q,K,V) = \text{SoftMax} (QK^T / \sqrt{d} + B) V \tag{4}$$

å…¶ä¸­ï¼Œ$Q,K,V$åˆ†åˆ«ä¸ºquery,keyå’Œvalueçš„çŸ©é˜µï¼Œç»´åº¦éƒ½æ˜¯$M^2 \times d$ï¼ˆ$d$æ˜¯query/keyçš„ç»´åº¦ï¼Œ$M^2$æ˜¯ä¸€ä¸ªçª—å£å†…çš„patchæ•°é‡ï¼‰ï¼Œå³ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/Transformer/8.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/Transformer/9.png)

å¼(4)ä¸­çŸ©é˜µ$B$çš„ç»´åº¦ä¸º$M^2 \times M^2$ã€‚ç›¸å¯¹ä½ç½®ç´¢å¼•çŸ©é˜µæ¯ä¸ªè½´çš„ç»´åº¦éƒ½æ˜¯$[-M+1,M-1]$ï¼Œä¸€æ—¦çª—å£å¤§å°ç¡®å®šï¼Œç›¸å¯¹ä½ç½®ç´¢å¼•çŸ©é˜µå°±æ˜¯å›ºå®šçš„ã€‚æˆ‘ä»¬ç”¨$\hat{B}$è¡¨ç¤ºrelative position bias tableï¼Œå…¶èŒƒå›´ä¸º$\hat{B} \in \mathbb{R} ^{(2M-1) \times (2M-1)} $ï¼Œå³ä¾‹å­ä¸­çš„0ï½8ã€‚$\hat{B}$æ˜¯å¯å­¦ä¹ çš„ï¼Œæ˜¯è®­ç»ƒå¾—åˆ°çš„ã€‚

å¦‚è¡¨4æ‰€ç¤ºï¼Œä¸ä½¿ç”¨ç»å¯¹ä½ç½®æˆ–ä¸ä½¿ç”¨biasç›¸æ¯”ï¼Œrelative position biaså¯¹æ€§èƒ½æœ‰æ˜æ˜¾æ”¹å–„ã€‚å¦‚æœæˆ‘ä»¬åƒ[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)é‚£æ ·åœ¨è¾“å…¥ä¸Šè¿›ä¸€æ­¥æ·»åŠ absolute position embeddingä¼šå¯¼è‡´æ€§èƒ½çš„è½»å¾®ä¸‹é™ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨æœ€ç»ˆçš„å®ç°é‡Œæ²¡æœ‰ä½¿ç”¨absolute position embeddingã€‚

é€šè¿‡é¢„è®­ç»ƒå­¦ä¹ åˆ°çš„relative position biasï¼Œåœ¨fine-tuneæ—¶å¯ä»¥é€šè¿‡åŒä¸‰æ¬¡æ’å€¼ï¼ˆbi-cubic interpolationï¼‰æ¥é€‚åº”ä¸åŒçš„çª—å£å¤§å°ã€‚

## 3.3.Architecture Variants

æˆ‘ä»¬çš„base modelç§°ä¸ºSwin-Bï¼Œå…¶æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ä¸[ViT-B](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)/DeiT-Bç›¸å½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†Swin-Tï¼ŒSwin-Så’ŒSwin-Lï¼Œå…¶æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦åˆ†åˆ«ä¸ºSwin-Bçš„0.25ï¼Œ0.5ä»¥åŠ2å€ã€‚å…¶ä¸­ï¼ŒSwin-Tå’ŒSwin-Sçš„å¤æ‚åº¦åˆ†åˆ«å’ŒResNet-50(DeiT-S)å’ŒResNet-101ç›¸å½“ã€‚çª—å£å¤§å°é»˜è®¤ä¸º$M=7$ã€‚å¯¹äºæ‰€æœ‰çš„å®éªŒï¼Œæ¯ä¸ªå¤´çš„queryç»´åº¦éƒ½ä¸º$d=32$ï¼Œåç»­çš„MLPå±‚æ•°å‡ä¸º$\alpha = 4$ã€‚è¿™äº›æ¨¡å‹å˜ä½“çš„æ¡†æ¶è¶…å‚æ•°è§ä¸‹ï¼š

* Swin-Tï¼šC=96ï¼Œlayer numbers={2,2,6,2}
* Swin-Sï¼šC=96ï¼Œlayer numbers={2,2,18,2}
* Swin-Bï¼šC=128ï¼Œlayer numbers={2,2,18,2}
* Swin-Lï¼šC=192ï¼Œlayer numbers={2,2,18,2}

$C$å³ä¸ºFig3(a)ä¸­çš„$C$ã€‚è¡¨1åˆ—å‡ºäº†æ¨¡å‹çš„å¤§å°ä»¥åŠç†è®ºè®¡ç®—å¤æ‚åº¦ï¼ˆFLOPsï¼‰ï¼Œè¿˜æœ‰ä¸åŒæ¨¡å‹å˜ä½“åœ¨ImageNetå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„throughputï¼ˆä¸ªäººç†è§£å°±æ˜¯æ¨ç†é€Ÿåº¦ï¼‰ã€‚

# 4.Experiments

æˆ‘ä»¬åœ¨ImageNet-1Kå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒCOCOç›®æ ‡æ£€æµ‹ä»»åŠ¡ä»¥åŠADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šéƒ½è¿›è¡Œäº†å®éªŒã€‚åœ¨è¿™ä¸‰ä¸ªä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†Swin Transformerå’Œä¹‹å‰SOTAçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ€»ç»“äº†Swin Transformerçš„é‡è¦è®¾è®¡å…ƒç´ ã€‚

## 4.1.Image Classification on ImageNet-1K

ğŸ‘‰**Settings**

ImageNet-1KåŒ…å«1.28Må¼ è®­ç»ƒé›†å›¾åƒï¼Œ50Kå¼ éªŒè¯é›†å›¾åƒï¼Œå…±åˆ†ä¸º1000ä¸ªç±»åˆ«ã€‚è¯„ä»·æŒ‡æ ‡ä½¿ç”¨åŸºäºsingle cropçš„top-1å‡†ç¡®ç‡ã€‚æˆ‘ä»¬è€ƒè™‘äº†ä¸¤ç§è®­ç»ƒè®¾ç½®ï¼š

* **Regular ImageNet-1K training.**
	* optimizerä½¿ç”¨AdamWï¼Œ300ä¸ªepochä½¿ç”¨cosine decay learning rate schedulerï¼Œ20ä¸ªepochä½¿ç”¨linear warm-upã€‚batch size=1024ï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º0.001ï¼Œweight decayä¸º0.05ã€‚åœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¤§å¤šæ•°çš„augmentationå’Œæ­£åˆ™åŒ–æ–¹æ³•ï¼Œé™¤äº†repeated augmentationå’ŒEMAï¼ˆå› ä¸ºè¿™ä¸¤ç§æ–¹æ³•å¹¶æ²¡æœ‰æå‡æ€§èƒ½ï¼‰ã€‚ä½†æ˜¯ï¼Œrepeated augmentationå¯¹[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)çš„ç¨³å®šè®­ç»ƒæ˜¯éå¸¸é‡è¦çš„ã€‚
* **Pre-training on ImageNet-22K and fine-tuning on ImageNet-1K.**
	* æˆ‘ä»¬ä¹Ÿå°è¯•äº†åœ¨æ›´å¤§çš„æ•°æ®é›†ImageNet-22Kä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¯¥æ•°æ®é›†åŒ…å«14.2Må¼ å›¾åƒå’Œ22ä¸ªç±»åˆ«ã€‚optimizerä½¿ç”¨AdamWï¼Œ90ä¸ªepochä½¿ç”¨linear decay learning rate schedulerï¼Œ5ä¸ªepochä½¿ç”¨linear warm-upã€‚batch size=4096ï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º0.001ï¼Œweight decayä¸º0.01ã€‚ç„¶ååœ¨ImageNet-1Kä¸Šè¿›è¡Œfine-tuneï¼Œä¸€å…±fine-tuneäº†30ä¸ªepochï¼Œbatch sizeä¸º1024ï¼Œå­¦ä¹ ç‡æ’ä¸º$10^{-5}$ï¼Œweight decayä¸º$10^{-8}$ã€‚

>repeated augmentationï¼šElad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler, and Daniel Soudry. Augment your batch: Improving generalization through instance repetition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8129â€“8138, 2020.ã€‚
>
>EMAï¼šBoris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging. SIAM journal on control and optimization, 30(4):838â€“855, 1992.ã€‚

ğŸ‘‰**Results with regular ImageNet-1K training**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/13.png)

è¡¨1æ¯”è¾ƒäº†åœ¨ImageNet-1Kåˆ†ç±»ä»»åŠ¡ä¸Šï¼Œä¸åŒbackbonesçš„è¡¨ç°ã€‚Throughputçš„æµ‹è¯„ä½¿ç”¨Github repoï¼š[Pytorch image models](https://github.com/rwightman/pytorch-image-models)ï¼ŒåŸºäºV100 GPUï¼Œéµå¾ªè®ºæ–‡â€œHugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve Ì Je Ìgou. Training data-efficient image transformers & distillation through attention. arXiv preprint arXiv:2012.12877, 2020.â€ã€‚

è¡¨1(a)ä½¿ç”¨regular ImageNet-1K trainingè®¾ç½®ï¼Œæ¯”è¾ƒäº†ä¸åŒbackboneï¼ˆTransformer-basedå’ŒConvNet-basedï¼‰çš„è¡¨ç°ã€‚

å’Œä¹‹å‰Transformer-basedçš„SOTAæ¡†æ¶ï¼ˆæ¯”å¦‚DeiTï¼‰ç›¸æ¯”ï¼ŒSwin Transformersçš„è¡¨ç°è¦ä¼˜äºä¸å…¶è®¡ç®—å¤æ‚åº¦ç›¸ä¼¼çš„DeiTæ¡†æ¶ï¼šå½“è¾“å…¥å¤§å°ä¸º$224^2$æ—¶ï¼Œç›¸æ¯”DeiT-Sï¼ˆ79.8%ï¼‰ï¼ŒSwin-Tï¼ˆ81.3%ï¼‰çš„å‡†ç¡®ç‡é«˜å‡º1.5%ï¼›å½“è¾“å…¥åˆ†åˆ«ä¸º$224^2/384^2$æ—¶ï¼Œç›¸æ¯”DeiT-Bï¼ˆ81.8%/83.1%ï¼‰ï¼ŒSwin-Bï¼ˆ83.3%/84.5%ï¼‰çš„å‡†ç¡®ç‡åˆ†åˆ«é«˜å‡º1.5%/1.4%ã€‚

å¦‚æœå’ŒSOTAçš„ConvNetsæ¡†æ¶ç›¸æ¯”ï¼Œæ¯”å¦‚RegNetå’ŒEfficientNetï¼ŒSwin Transformeræœ‰ç€æ›´å¥½çš„speed-accuracy trade-offã€‚å› ä¸ºSwin Transformeræ˜¯åŸºäºæ ‡å‡†çš„Transformeræ„å»ºçš„ï¼Œå…¶å…·æœ‰è¿›ä¸€æ­¥æ”¹è¿›çš„å¼ºå¤§æ½œåŠ›ã€‚

>RegNetï¼šIlija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Dolla Ìr. Designing network design spaces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10428â€“ 10436, 2020.ã€‚

ğŸ‘‰**Results with ImageNet-22K pre-training**

æˆ‘ä»¬åœ¨ImageNet-22Kä¸Šé¢„è®­ç»ƒäº†æ›´å¤§çš„æ¨¡å‹Swin-Bå’ŒSwin-Lã€‚åœ¨ImageNet-1Kå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„fine-tuneç»“æœè§è¡¨1(b)ã€‚å¯¹äºSwin-Bï¼Œç›¸æ¯”åªåœ¨ImageNet-1Kä¸Šä»å¤´å¼€å§‹è®­ç»ƒï¼Œåœ¨ImageNet-22Kä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„æ–¹å¼å°†å‡†ç¡®ç‡æå‡äº†1.8%ï½1.9%ã€‚å’Œä¹‹å‰åŒæ ·åœ¨ImageNet-22Kä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„æœ€å¥½ç»“æœç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜æ˜¾æœ‰ç€æ›´å¥½çš„speed-accuracy trade-offsï¼šSwin-Bå’ŒViT-B/16åœ¨æ¨ç†é€Ÿåº¦å·®ä¸å¤šçš„æƒ…å†µä¸‹ï¼ˆ84.7 vs. 85.9 images/secï¼‰ï¼ŒSwin-Bçš„top-1å‡†ç¡®ç‡ä¸º86.4%ï¼Œæ¯”ViT-B/16é«˜å‡º2.4%ï¼Œå¹¶ä¸”FLOPsæ›´ä½ï¼ˆ47.0G vs. 55.4Gï¼‰ã€‚æ›´å¤§çš„Swin-Læ¨¡å‹è¾¾åˆ°äº†87.3%çš„top-1å‡†ç¡®ç‡ï¼Œæ¯”Swin-Bè¿˜é«˜å‡º0.9%ã€‚

## 4.2.Object Detection on COCO

ğŸ‘‰**Settings**

æˆ‘ä»¬åœ¨COCO 2017ä¸Šè¿›è¡Œäº†ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²æµ‹è¯•ï¼Œè¯¥æ•°æ®é›†åŒ…å«118Kè®­ç»ƒå›¾åƒï¼Œ5KéªŒè¯å›¾åƒï¼Œ20K test-devå›¾åƒã€‚åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œäº†æ¶ˆèå®éªŒï¼Œåœ¨test-devä¸Šè¿›è¡Œäº†system-levelçš„æ¯”è¾ƒã€‚å¯¹äºæ¶ˆèå®éªŒï¼Œæˆ‘ä»¬è€ƒè™‘äº†4ç§å…¸å‹çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼ˆåŸºäºmmdetectionï¼‰ï¼šCascade Mask R-CNNã€ATSSã€RepPoints v2å’ŒSparse RCNNã€‚å¯¹äºè¿™4ç§æ¡†æ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€æ ·çš„settingsï¼š

* multi-scale trainingã€‚resizeè¾“å…¥çš„å¤§å°ï¼Œä½¿çŸ­è¾¹ä½äº480ï½800ä¹‹é—´ï¼Œé•¿è¾¹æœ€é•¿ä¸è¶…è¿‡1333ã€‚
* AdamW optimizerã€‚åˆå§‹å­¦ä¹ ç‡ä¸º0.0001ï¼Œweight decayä¸º0.05ï¼Œbatch size=16ã€‚
* 3x scheduleï¼ˆ36 epochsï¼Œåˆ†åˆ«åœ¨ç¬¬27å’Œ33ä¸ªepochçš„æ—¶å€™ï¼Œå­¦ä¹ ç‡è¡°å‡10å€ï¼‰ã€‚

å¯¹äºsystem-levelçš„æ¯”è¾ƒï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ï¼š

* ä¸€ç§æ”¹è¿›çš„HTCï¼ˆè¡¨ç¤ºä¸ºHTC++ï¼‰+instaboost
* stronger multi-scale trainingï¼ˆå°†è¾“å…¥çš„çŸ­è¾¹resizeåˆ°400ï½1400ä¹‹é—´ï¼Œé•¿è¾¹ä¸è¶…è¿‡1600ï¼‰
* 6x scheduleï¼ˆ72 epochsï¼Œåˆ†åˆ«åœ¨ç¬¬63å’Œ69ä¸ªepochçš„æ—¶å€™ï¼Œå­¦ä¹ ç‡è¡°å‡10å€ï¼‰
* soft-NMS
* ImageNet-22Ké¢„è®­ç»ƒ

æˆ‘ä»¬æ¯”è¾ƒäº†Swin Transformerå’Œæ ‡å‡†çš„ConvNetsï¼ˆå³ResNe(X)tï¼‰ä»¥åŠä»¥å‰çš„Transformeræ¡†æ¶ï¼ˆå³DeiTï¼‰ã€‚æ¯”è¾ƒçš„æ—¶å€™settingséƒ½ä¸€æ ·ï¼Œåªæ˜¯æ›´æ¢äº†backbonesã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç”±äºSwin Transformerå’ŒResNe(X)téƒ½æœ‰hierarchical feature mapsï¼Œæ‰€ä»¥å…¶å¯ä»¥ç›´æ¥åº”ç”¨äºä¸Šè¿°æ¡†æ¶ï¼Œè€ŒDeiTåªèƒ½äº§ç”Ÿå•ä¸€åˆ†è¾¨ç‡çš„feature mapsï¼Œæ‰€ä»¥å…¶ä¸èƒ½ç›´æ¥åº”ç”¨ã€‚ä¸ºäº†æ¯”è¾ƒçš„å…¬å¹³æ€§ï¼Œæˆ‘ä»¬æŒ‰ç…§è®ºæ–‡â€œSixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. arXiv preprint arXiv:2012.15840, 2020.â€ä¸­çš„æ€è·¯ï¼Œé€šè¿‡åå·ç§¯å±‚æ¥ä½¿DeiTäº§ç”Ÿhierarchical feature mapsã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/14.png)

è¡¨2å±•ç¤ºäº†åœ¨COCOç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸Šçš„ç»“æœã€‚

ğŸ‘‰**Comparison to ResNe(X)t**

è¡¨2(a)åˆ—å‡ºäº†åˆ†åˆ«ä»¥Swin-Tå’ŒResNet-50ä¸ºbackboneçš„4ç§ç›®æ ‡æ£€æµ‹æ¡†æ¶çš„ç»“æœã€‚è™½ç„¶Swin-Tåœ¨æ¨¡å‹å¤§å°ã€FLOPsä»¥åŠlatencyæ–¹é¢æ¯”ResNet-50ç•¥é«˜ï¼Œä½†æ˜¯å…¶box APæ¯”ResNet-50åŸºæœ¬éƒ½èƒ½é«˜å‡º3.4ï½4.2ä¸ªç‚¹ã€‚

åœ¨è¡¨2(b)ä¸­ï¼ŒåŸºäºCascade Mask R-CNNæ¡†æ¶ï¼Œåˆ†åˆ«ä½¿ç”¨ä¸åŒcapacityçš„backbonesã€‚ç›¸æ¯”ResNeXt101-64x4dï¼ŒSwin-Bè¡¨ç°æ›´å¥½ï¼Œå–å¾—äº†51.9çš„box APï¼ˆæå‡äº†3.6ä¸ªç‚¹ï¼‰å’Œ45.0çš„mask APï¼ˆæå‡äº†3.3ä¸ªç‚¹ï¼‰ï¼Œå¹¶ä¸”äºŒè€…çš„æ¨¡å‹å¤§å°ã€FLOPsä»¥åŠlatencyç›¸è¿‘ã€‚åœ¨è¡¨2(c)ä¸­ï¼Œç›¸æ¯”X101-64(HTC++)çš„è¡¨ç°ï¼ˆ52.3çš„box APå’Œ46.0çš„mask APï¼‰ï¼ŒSwin-B(HTC++)çš„è¡¨ç°æ›´å¥½ï¼Œbox APæå‡äº†4.1ä¸ªç‚¹ï¼Œmask APæå‡äº†3.1ä¸ªç‚¹ã€‚å…³äºæ¨ç†é€Ÿåº¦ï¼ŒResNe(X)tæ˜¯åŸºäºé«˜åº¦ä¼˜åŒ–çš„Cudnnå‡½æ•°æ„å»ºçš„ï¼Œè€Œæˆ‘ä»¬çš„æ¨¡å‹ä»…ä»…ä½¿ç”¨å†…ç½®çš„PyTorchå‡½æ•°å®ç°ï¼Œè¿™äº›å‡½æ•°å¹¶æ²¡æœ‰å®Œå…¨ä¼˜åŒ–ã€‚å®Œå…¨å½»åº•çš„ä¼˜åŒ–å¹¶ä¸åœ¨æœ¬æ–‡çš„è®¨è®ºèŒƒå›´ä¹‹å†…ã€‚

ğŸ‘‰**Comparison to DeiT**

åœ¨è¡¨2(b)ä¸­ï¼Œç›¸æ¯”DeiT-Sï¼ŒSwin-Tå’Œå…¶æœ‰ç€ç›¸ä¼¼çš„æ¨¡å‹å¤§å°ï¼ˆ86M vs. 80Mï¼‰ï¼Œä½†è¡¨ç°æ›´å¥½ï¼Œbox APæå‡äº†2.5ä¸ªç‚¹ï¼Œmask APæå‡äº†2.3ä¸ªç‚¹ï¼Œå¹¶ä¸”æ¨ç†é€Ÿåº¦ä¹Ÿæ›´å¿«ï¼ˆ15.3 FPS vs. 10.4 FPSï¼‰ã€‚DeiTæ¨ç†é€Ÿåº¦æ…¢ä¸»è¦æ˜¯å› ä¸ºå…¶è®¡ç®—å¤æ‚åº¦å’Œè¾“å…¥å›¾åƒå¤§å°å‘ˆäºŒæ¬¡æ–¹å…³ç³»ã€‚

ğŸ‘‰**Comparison to previous state-of-the-art**

åœ¨è¡¨2(c)ä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†æˆ‘ä»¬æœ€å¥½çš„ç»“æœå’Œä¹‹å‰çš„SOTAæ¨¡å‹ã€‚åœ¨COCO test-devä¸Šï¼Œæˆ‘ä»¬æœ€å¥½çš„æ¨¡å‹è¾¾åˆ°äº†58.7çš„box APå’Œ51.1çš„mask APï¼Œç›¸æ¯”ä¹‹å‰æœ€é«˜çš„box APç»“æœï¼ˆCopy-paste without external dataï¼‰è¿˜æå‡äº†2.7ä¸ªç‚¹ï¼Œæ¯”ä¹‹å‰æœ€é«˜çš„mask APç»“æœï¼ˆDetectoRSï¼‰æå‡äº†2.6ä¸ªç‚¹ã€‚

## 4.3.Semantic Segmentation on ADE20K

ğŸ‘‰**Settings**

ADE20Kæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ï¼ŒåŒ…å«150ä¸ªè¯­ä¹‰ç±»åˆ«ã€‚è¯¥æ•°æ®é›†å…±åŒ…å«25Kå¼ å›¾åƒï¼Œå…¶ä¸­20Kç”¨äºè®­ç»ƒï¼Œ2Kç”¨äºéªŒè¯ï¼Œ3Kç”¨äºæµ‹è¯•ã€‚é‰´äºUperNetçš„é«˜æ•ˆæ€§ï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºæ¯”è¾ƒçš„base frameworkï¼Œæ›´å¤šç»†èŠ‚è§Appendixã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/15.png)

è¡¨3æ˜¯åœ¨ADE20KéªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šçš„ç»“æœã€‚

ğŸ‘‰**Results**

è¡¨3åˆ—å‡ºäº†ä¸åŒmethod/backbone pairçš„mIoUã€æ¨¡å‹å¤§å°ï¼ˆ#paraï¼‰ã€FLOPsä»¥åŠFPSã€‚å¯ä»¥çœ‹å‡ºï¼Œç›¸æ¯”DeiT-Sï¼ŒSwin-Så’Œå…¶æœ‰ç€å·®ä¸å¤šçš„è®¡ç®—æˆæœ¬ï¼Œä½†æ˜¯mIoUé«˜å‡ºäº†5.3ä¸ªç‚¹ï¼ˆ49.3 vs. 44.0ï¼‰ã€‚æ­¤å¤–ï¼ŒSwin-Sçš„mIoUæ¯”ResNet-101é«˜å‡º4.4ä¸ªç‚¹ï¼Œæ¯”ResNeSt-101é«˜å‡º2.4ä¸ªç‚¹ã€‚æˆ‘ä»¬çš„Swin-Læ¨¡å‹ï¼ˆç»è¿‡ImageNet-22Ké¢„è®­ç»ƒï¼‰åœ¨éªŒè¯é›†ä¸Šè¾¾åˆ°äº†53.5çš„mIoUï¼Œæ¯”ä¹‹å‰çš„æœ€å¥½æˆç»©ï¼ˆSETRçš„50.3 mIoUï¼‰é«˜å‡º3.2ä¸ªç‚¹ã€‚

## 4.4.Ablation Study

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ImageNet-1Kå›¾åƒåˆ†ç±»ï¼ŒCOCOç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„Cascade Mask R-CNNä»¥åŠADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„UperNetï¼Œè®¨è®ºäº†Swin Transformerä¸­çš„ä¸€äº›é‡è¦è®¾è®¡å…ƒç´ ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/16.png)

è¡¨4æ˜¯åŸºäºSwin-Tï¼Œåšçš„å…³äºshifted windowså’Œä¸åŒposition embeddingçš„æ¶ˆèå®éªŒï¼Œç”¨äº†3ç§benchmarksã€‚è¡¨4ä¸­ä¸€äº›æ¡ç›®çš„è§£é‡Šï¼š

* w/o shiftingï¼šæ‰€æœ‰è‡ªæ³¨æ„åŠ›æ¨¡å—éƒ½ä½¿ç”¨å¸¸è§„çª—å£åˆ’åˆ†ï¼Œä¸ä½¿ç”¨shiftingã€‚
* abs. pos.ï¼šæŒ‡çš„æ˜¯[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)ä¸­æ‰€ç”¨çš„ç»å¯¹ä½ç½®ç¼–ç ï¼ˆabsolute position embeddingï¼‰ã€‚
* rel. pos.ï¼šæœ¬æ–‡æå‡ºçš„ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œå³å…¬å¼(4)ä¸­çš„$B$ã€‚
* app.ï¼šå¼(4)ä¸­çš„$QK^T/\sqrt{d}$é¡¹ã€‚

ğŸ‘‰**Shifted windows**

ä»è¡¨4ä¸­å¯ä»¥çœ‹å‡ºï¼ŒåŸºäºSwin-Tï¼Œç›¸æ¯”å¸¸è§„çª—å£åˆ’åˆ†ï¼Œshifted windowså¸¦æ¥äº†æ€§èƒ½çš„æå‡ï¼Œåœ¨ImageNet-1Kä¸Šï¼Œå°†top-1å‡†ç¡®ç‡æå‡äº†1.1ä¸ªç‚¹ï¼›åœ¨COCOä¸Šï¼Œå°†box APæå‡äº†2.8ä¸ªç‚¹ï¼Œmask APæå‡äº†2.2ä¸ªç‚¹ï¼›åœ¨ADE20Kä¸Šï¼Œå°†mIoUæå‡äº†2.8ä¸ªç‚¹ã€‚è¿™äº›ç»“æœè¡¨æ˜äº†shifted windowsçš„æœ‰æ•ˆæ€§ã€‚å¹¶ä¸”ï¼Œshifted windowsçš„latencyä¹Ÿå¾ˆå°ï¼Œè¯¦è§è¡¨5ã€‚

ğŸ‘‰**Relative position bias**

ç›¸æ¯”ä¸ä½¿ç”¨ä½ç½®ç¼–ç æˆ–ä½¿ç”¨ç»å¯¹ä½ç½®ç¼–ç ï¼Œä½¿ç”¨ç›¸å¯¹ä½ç½®ç¼–ç ç»™Swin-Tå¸¦æ¥äº†æ€§èƒ½ä¸Šçš„æå‡ï¼Œåœ¨ImageNet-1Kä¸Šï¼Œå°†top-1å‡†ç¡®ç‡æå‡äº†1.2%/0.8%ï¼›åœ¨COCOä¸Šï¼Œå°†box APæå‡äº†1.3/1.5ï¼Œå°†mask APæå‡äº†1.1/1.3ï¼›åœ¨ADE20Kä¸Šï¼Œå°†mIoUæå‡äº†2.3/2.9ï¼Œä»¥ä¸Šç»“æœè¯´æ˜äº†ç›¸å¯¹ä½ç½®ç¼–ç çš„æœ‰æ•ˆæ€§ã€‚å¹¶ä¸”éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›¸æ¯”ä¸ä½¿ç”¨ä½ç½®ç¼–ç ï¼Œä½¿ç”¨ç»å¯¹ä½ç½®ç¼–ç ä»…ä»…æå‡äº†å›¾åƒåˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼ˆ+0.4%ï¼‰ï¼Œä½†æ˜¯å´é™ä½äº†åœ¨ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ˆåœ¨COCOä¸Šï¼Œ-0.2 box/mask APï¼Œåœ¨ADE20Kä¸Šï¼Œ-0.6 mIoUï¼‰ã€‚

ğŸ‘‰**Different self-attention methods**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/17.png)

ä¸åŒè‡ªæ³¨æ„åŠ›è®¡ç®—æ–¹å¼çš„real speedï¼ˆåŸºäºV100 GPUï¼‰æ¯”è¾ƒè§è¡¨5ã€‚ç›¸æ¯”ç›´æ¥paddingï¼Œæˆ‘ä»¬æå‡ºçš„å¾ªç¯ç§»ä½çš„æ–¹æ³•æ›´æœ‰æ•ˆç‡ï¼Œå°¤å…¶æ˜¯deeper stagesçš„æ—¶å€™ã€‚æ€»çš„æ¥çœ‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†Swin-Tã€Swin-Så’ŒSwin-Båˆ†åˆ«æé€Ÿäº†13%ã€18%å’Œ18%ã€‚

>(755-670)/670=0.1268656716
>
>(437-371)/371=0.1778975741
>
>(278-236)/236=0.1779661017

å¯¹äºæ¯ä¸ªstageï¼Œç›¸æ¯”sliding windowsï¼ˆnaiveï¼‰å’Œsliding windowsï¼ˆkernelï¼‰ï¼Œshifted windowçš„æ•ˆç‡åˆ†åˆ«æ˜¯å…¶çš„40.8/2.5ï¼Œ20.2/2.5ï¼Œ9.3/2.1ï¼Œ7.6/1.8å€ã€‚ä»æ¨ç†é€Ÿåº¦ä¸Šæ¥çœ‹ï¼Œå¯¹äºSwin-Tã€Swin-Sä»¥åŠSwin-Bï¼Œç›¸æ¯”sliding windowsï¼ˆnaiveï¼‰å’Œsliding windowsï¼ˆkernelï¼‰ï¼Œshifted windowçš„æ¨ç†é€Ÿåº¦åˆ†åˆ«æ˜¯å…¶çš„4.1/1.5ï¼Œ4.0/1.5ï¼Œ3.6/1.5å€ã€‚è¡¨6å±•ç¤ºäº†å®ƒä»¬åœ¨è¿™3ä¸ªä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡ï¼Œå¯ä»¥çœ‹å‡ºï¼Œå®ƒä»¬çš„å‡†ç¡®ç‡æ˜¯å·®ä¸å¤šçš„ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/18.png)

å’ŒPerformerï¼ˆæœ€å¿«çš„Transformeræ¡†æ¶ä¹‹ä¸€ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œshifted windowæ›´å¿«ï¼ˆè§è¡¨5ï¼‰ï¼Œä¸”åœ¨ImageNet-1Kä¸Šçš„top-1å‡†ç¡®ç‡æ›´é«˜ï¼ˆé«˜å‡º2.3%ï¼‰ã€‚

# 5.Conclusion

æœ¬æ–‡æå‡ºäº†Swin Transformerï¼Œä¸€ç§æ–°çš„vision Transformeræ¡†æ¶ï¼Œå¯ä»¥äº§ç”Ÿhierarchical feature representationï¼Œè®¡ç®—å¤æ‚åº¦å’Œè¾“å…¥å›¾åƒå¤§å°å‘ˆçº¿æ€§å…³ç³»ã€‚åœ¨COCOç›®æ ‡æ£€æµ‹å’ŒADE20Kè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šï¼ŒSwin Transformeréƒ½è¾¾åˆ°äº†SOTAçš„æ°´å¹³ã€‚æˆ‘ä»¬å¸Œæœ›Swin Transformeråœ¨CVé¢†åŸŸçš„ä¼˜å¼‚è¡¨ç°å¯ä»¥ä¿ƒè¿›CVå’ŒNLPçš„å¤§ä¸€ç»Ÿå»ºæ¨¡ã€‚

åŸºäºshifted windowçš„è‡ªæ³¨æ„åŠ›æ˜¯Swin Transformerçš„ä¸€ä¸ªå…³é”®å…ƒç´ ï¼Œå…¶åœ¨è§£å†³è§†è§‰é—®é¢˜ä¸Šè¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œæˆ‘ä»¬ä¹ŸæœŸå¾…ç€å…¶åœ¨NLPä¸­çš„åº”ç”¨ã€‚

# 6.A1.Detailed Architectures

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/19.png)

æ¨¡å‹æ¡†æ¶çš„è¯¦ç»†ä¿¡æ¯è§è¡¨7ï¼Œè¾“å…¥å¤§å°å‡ä¸º$224 \times 224$ã€‚

* "Concat $n\times n$"ï¼šè¡¨ç¤ºä¸‹é‡‡æ ·çš„æ¯”ä¾‹ã€‚Fig3(a)ä¸­çš„"Patch Partition"+"Linear Embedding"å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ª"Patch Merging"ã€‚
* "96-d"è¡¨ç¤ºç»è¿‡"Linear Embedding"æˆ–"Patch Merging"åçš„é€šé“æ•°ã€‚
* "LN"è¡¨ç¤º[LayerNorm](http://shichaoxin.com/2022/03/19/è®ºæ–‡é˜…è¯»-Layer-Normalization/)ã€‚
* "win. sz. $7\times 7$"è¡¨ç¤ºç”¨äºè®¡ç®—å¤šå¤´è‡ªæ³¨æ„åŠ›çš„çª—å£å¤§å°ä¸º$7\times 7$ã€‚

# 6.A2.Detailed Experimental Settings

## 6.A2.1.Image classification on ImageNet-1K

åœ¨æœ€åä¸€ä¸ªstageè¾“å‡ºçš„feature mapä¸Šåº”ç”¨ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–ï¼Œæœ€åå†æ¥ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨æ¥æ‰§è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æˆ‘ä»¬å‘ç°è¿™ç§ç­–ç•¥å’Œä½¿ç”¨é¢å¤–çš„class tokenï¼ˆ[ViT](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/)å’ŒDeiTï¼‰çš„æ•ˆæœå·®ä¸å¤šã€‚è¯„ä¼°æ—¶ä½¿ç”¨single cropçš„top-1å‡†ç¡®ç‡ã€‚

ğŸ‘‰**Regular ImageNet-1K training**

training settingså¤§éƒ¨åˆ†éµç…§è®ºæ–‡â€œHugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve Ì Je Ìgou. Training data-efficient image transformers & distillation through attention. arXiv preprint arXiv:2012.12877, 2020.â€ã€‚å¯¹äºæ‰€æœ‰çš„æ¨¡å‹å˜ä½“ï¼Œæˆ‘ä»¬é»˜è®¤è¾“å…¥å›¾åƒåˆ†è¾¨ç‡ä¸º$224^2$ã€‚å¯¹äºå…¶ä»–åˆ†è¾¨ç‡ï¼Œæ¯”å¦‚$384^2$ï¼Œæˆ‘ä»¬ä¼šå…ˆåœ¨$224^2$åˆ†è¾¨ç‡ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨$384^2$ä¸Šfine-tuneï¼Œè¿™æ ·åšä»¥å‡å°‘GPUæ¶ˆè€—ã€‚

é™¤äº†ç¬¬4.1éƒ¨åˆ†ä¸­æåˆ°çš„è®­ç»ƒç»†èŠ‚å¤–ï¼Œè¿˜ä½¿ç”¨äº†gradient clippingï¼ˆmax norm=1ï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¤§éƒ¨åˆ†çš„augmentationå’Œæ­£åˆ™åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬RandAugmentã€Mixupã€Cutmixã€random erasingå’Œstochastic depthï¼Œä½†æ˜¯æ²¡æœ‰ä½¿ç”¨repeated augmentationå’ŒExponential Moving Averageï¼ˆEMAï¼‰ï¼Œå› ä¸ºè¿™ä¸¤ç§æ–¹æ³•å¯¹æå‡æ€§èƒ½æ²¡æœ‰å¸®åŠ©ã€‚æ¨¡å‹è¶Šå¤§ï¼Œstochastic depthè¶Šå¤§ï¼Œæ¯”å¦‚Swin-Tã€Swin-Så’ŒSwin-Båˆ†åˆ«ä½¿ç”¨0.2ã€0.3å’Œ0.5ã€‚

å½“åœ¨æ›´å¤§çš„åˆ†è¾¨ç‡ä¸Šè¿›è¡Œfine-tuneçš„æ—¶å€™ï¼Œoptimizerä½¿ç”¨AdamWï¼Œè®­ç»ƒ30ä¸ªepochï¼Œå­¦ä¹ ç‡ä¿æŒä¸å˜ï¼ˆ$10^{-5}$ï¼‰ï¼Œweight decayä¸º$10^{-8}$ï¼Œä½¿ç”¨å’Œä¸Šä¸€æ®µä¸­ä¸€æ ·çš„augmentationå’Œæ­£åˆ™åŒ–ç­–ç•¥ï¼Œå”¯ä¸€ä¸åŒçš„åœ°æ–¹åœ¨äºstochastic depth ratioè®¾ä¸º0.1ã€‚

ğŸ‘‰**ImageNet-22K pre-training**

è®­ç»ƒåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œåœ¨ImageNet-22Ké¢„è®­ç»ƒé˜¶æ®µï¼Œè¾“å…¥å¤§å°ä¸º$224^2$ã€‚åœ¨ImageNet-1Kä¸Šfine-tuneé˜¶æ®µï¼Œè¾“å…¥å¤§å°ä¸º$224^2 / 384^2$ã€‚å…¶ä½™è®­ç»ƒç»†èŠ‚è§æœ¬æ–‡ç¬¬4.1éƒ¨åˆ†ã€‚

## 6.A2.2.Object detection on COCO

è¯¦è§ç¬¬4.2éƒ¨åˆ†çš„Settingsã€‚æ­¤å¤–ï¼Œåœ¨COCOä¸Šè¿›è¡Œç›®æ ‡æ£€æµ‹æ—¶ï¼Œåœ¨æœ€åä¸€ä¸ªstageçš„è¾“å‡ºåé¢åˆæ¥äº†ä¸€ä¸ªå…¨å±€çš„è‡ªæ³¨æ„åŠ›å±‚ã€‚åœ¨ImageNet-22Kä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚å¯¹äºæ‰€æœ‰çš„Swin Transformeræ¨¡å‹ï¼Œéƒ½ä½¿ç”¨äº†stochastic depthï¼ˆratio=0.2ï¼‰ã€‚

## 6.A2.3.Semantic segmentation on ADE20K

åœ¨è®­ç»ƒæ—¶ï¼Œoptimizerä½¿ç”¨AdamWï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º$6\times 10^{-5}$ï¼Œweight decayä¸º0.01ï¼Œlinear learning rate decayï¼Œlinear warmupï¼ˆ1500æ¬¡è¿­ä»£ï¼‰ã€‚ä½¿ç”¨8å—GPUï¼Œæ¯å—GPUå¤„ç†2å¼ å›¾åƒï¼Œè¿­ä»£160Kæ¬¡ã€‚è‡³äºaugmentationsï¼Œæˆ‘ä»¬é‡‡ç”¨mmsegmentationä¸­çš„é»˜è®¤è®¾ç½®ï¼ŒåŒ…æ‹¬random horizontal flippingã€random re-scaling within ratio range [0.5, 2.0]å’Œrandom photometric distortionã€‚å¯¹äºæ‰€æœ‰çš„Swin Transformeræ¨¡å‹ï¼Œstochastic depth ratioéƒ½ä¸º0.2ã€‚Swin-Tï¼ŒSwin-Sä¸ä¹‹å‰çš„æ–¹æ³•ä¸€æ ·ï¼Œåœ¨æ ‡å‡†è®¾ç½®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¾“å…¥å¤§å°ä¸º$512 \times 512$ã€‚å¸¦æœ‰$\mathop{}_{+}^{+}$çš„Swin-Bå’ŒSwin-Lä¸¤ä¸ªæ¨¡å‹åœ¨ImageNet-22Kä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¾“å…¥å¤§å°ä¸º$640 \times 640$ã€‚

åœ¨æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨multi-scale testï¼Œå³æµ‹è¯•å›¾åƒçš„åˆ†è¾¨ç‡åˆ†åˆ«è°ƒæ•´ä¸ºè®­ç»ƒå›¾åƒåˆ†è¾¨ç‡çš„$[0.5, 0.75, 1.0, 1.25, 1.5, 1.75]$å€ã€‚è®­ç»ƒé›†å’ŒéªŒè¯é›†è¢«ç”¨äºè®­ç»ƒï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

# 6.A3.More Experiments

## 6.A3.1.Image classification with different input size

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/20.png)

è¡¨8åˆ—å‡ºäº†Swin Transformersåœ¨ä¸åŒè¾“å…¥åˆ†è¾¨ç‡ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼ˆä»$224^2$åˆ°$384^2$ï¼‰ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ›´å¤§çš„è¾“å…¥åˆ†è¾¨ç‡æ„å‘³ç€æ›´é«˜çš„top-1å‡†ç¡®ç‡å’Œæ›´ä½çš„æ¨ç†é€Ÿåº¦ã€‚

## 6.A3.2.Different Optimizers for ResNe(X)t on COCO

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/21.png)

è¡¨9æ¯”è¾ƒäº†åœ¨COCOç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œä»¥ResNe(X)tä½œä¸ºbackbonesæ—¶ï¼ŒAdamWå’ŒSGDä¹‹é—´çš„åŒºåˆ«ã€‚æ¯”è¾ƒåŸºäºCascade Mask R-CNNæ¡†æ¶ã€‚è¯¥æ¡†æ¶é»˜è®¤çš„optimizeræ˜¯SGDï¼Œä½†æˆ‘ä»¬å‘ç°ä½¿ç”¨AdamWä½œä¸ºoptimizeré€šå¸¸å¯ä»¥æå‡å…¶æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å¯¹äºå°ä¸€ç‚¹çš„backbonesã€‚å› æ­¤ï¼Œåœ¨å’ŒSwin Transformeræ¯”è¾ƒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨AdamWä½œä¸ºResNe(X)t backbonesçš„optimizerã€‚

## 6.A3.3.Swin MLP-Mixer

æˆ‘ä»¬å°†hierarchical designå’Œshifted windowåº”ç”¨äºMLP-Mixeræ¡†æ¶ï¼Œå¹¶å°†å…¶ç§°ä¸ºSwin-Mixerã€‚åœ¨è¡¨10ä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†Swin-Mixerå’ŒåŸå§‹çš„MLP-Mixerï¼Œä»¥åŠå…¶åç»­å˜ä½“ResMLPã€‚Swin-Mixer-B/D24çš„è¡¨ç°æ˜æ˜¾ä¼˜äºMLP-Mixer-B/16ï¼Œå‡†ç¡®ç‡æ›´é«˜ï¼ˆ81.3% vs. 76.4%ï¼‰ï¼Œè®¡ç®—æˆæœ¬æ›´ä½ï¼ˆ10.4G vs. 12.7Gï¼‰ã€‚ç›¸æ¯”ResMLPï¼ŒSwin-Mixeræœ‰ç€æ›´å¥½çš„speed accuracy trade-offã€‚è¿™äº›ç»“æœè¡¨æ˜hierarchical designå’Œshifted windowæ˜¯å¯æ¨å¹¿çš„ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/SwinTransformer/22.png)

è¡¨10å±•ç¤ºäº†Swin MLP-Mixeråœ¨ImageNet-1Kå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚$D$è¡¨ç¤ºæ¯ä¸ªå¤´çš„é€šé“æ•°é‡ï¼ˆå³tokené•¿åº¦ï¼‰ã€‚Throughputçš„æµ‹è¯•åŸºäº[Pytorch image models](https://github.com/rwightman/pytorch-image-models)å’Œä¸€å—V100 GPUã€‚

# 7.åŸæ–‡é“¾æ¥

ğŸ‘½[Swin Transformerï¼šHierarchical Vision Transformer using Shifted Windows](https://github.com/x-jeff/AI_Papers/blob/master/Swin%20Transformerï¼šHierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf)

# 8.å‚è€ƒèµ„æ–™

1. [12.1 Swin-Transformerç½‘ç»œç»“æ„è¯¦è§£](https://www.bilibili.com/video/BV1pL4y1v7jC/?spm_id_from=333.337.search-card.all.click&vd_source=896374db59ca8f208a0bb9f453a24c25)
2. [Swin Transformerè®ºæ–‡ç²¾è¯»ã€è®ºæ–‡ç²¾è¯»ã€‘](https://www.bilibili.com/video/BV13L4y1475U/?spm_id_from=333.337.search-card.all.click&vd_source=896374db59ca8f208a0bb9f453a24c25)