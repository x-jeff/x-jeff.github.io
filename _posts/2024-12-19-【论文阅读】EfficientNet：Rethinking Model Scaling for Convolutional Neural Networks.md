---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘EfficientNetï¼šRethinking Model Scaling for Convolutional Neural Networks
subtitle:   EfficientNet
date:       2024-12-19
author:     x-jeff
header-img: blogimg/20200924.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>æºç åœ°å€ï¼š[EfficientNet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)ã€‚

æ‰©å±•ï¼ˆscaling upï¼‰å·ç§¯ç¥ç»ç½‘ç»œè¢«å¹¿æ³›ç”¨äºæé«˜æ¨¡å‹æ€§èƒ½ã€‚æœ€å¸¸è§çš„æ‰©å±•æ–¹æ³•æ˜¯å¢åŠ å·ç§¯ç¥ç»ç½‘ç»œçš„æ·±åº¦å’Œå®½åº¦ã€‚è¿˜æœ‰ä¸€ç§å°‘è§ä½†æ—¥ç›Šæµè¡Œçš„æ–¹æ³•æ˜¯é€šè¿‡æé«˜å›¾åƒåˆ†è¾¨ç‡æ¥æ‰©å±•æ¨¡å‹ã€‚åœ¨ä»¥å¾€çš„ç ”ç©¶ä¸­ï¼Œé€šå¸¸åªé‡‡ç”¨3ç§æ‰©å±•æ–¹æ³•ä¸­çš„ä¸€ç§å³å¯ï¼ŒåŒæ—¶ä½¿ç”¨å¤šç§æ‰©å±•æ–¹æ³•åå€’å¯èƒ½å¯¼è‡´æ¬¡ä¼˜çš„ç»“æœã€‚

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„å¤åˆæ‰©å±•æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿåšæ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¸€ç»„å›ºå®šçš„æ‰©å±•ç³»æ•°ï¼Œç»Ÿä¸€çš„æ‰©å±•ç½‘ç»œçš„å®½åº¦ã€æ·±åº¦å’Œåˆ†è¾¨ç‡ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨$2^N$å€çš„è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å°†ç½‘ç»œçš„æ·±åº¦å¢åŠ $\alpha^N$å€ã€å®½åº¦å¢åŠ $\beta^N$å€ã€å›¾åƒå¤§å°å¢åŠ $\gamma^N$å€ã€‚å…¶ä¸­ï¼Œ$\alpha,\beta,\gamma$æ˜¯åœ¨åŸæœ‰å°æ¨¡å‹åŸºç¡€ä¸Šé€šè¿‡å°èŒƒå›´ç½‘æ ¼æœç´¢ç¡®å®šçš„å›ºå®šç³»æ•°ã€‚Fig2å±•ç¤ºäº†æˆ‘ä»¬æå‡ºçš„å¤åˆæ‰©å±•æ–¹æ³•å’Œä¼ ç»Ÿæ–¹æ³•çš„ä¸åŒï¼ŒFig2(b)-(d)æ˜¯ä¼ ç»Ÿçš„æ‰©å±•æ–¹æ³•ï¼Œåªä»ä¸€ä¸ªç»´åº¦è¿›è¡Œæ‰©å±•ï¼ŒFig2(e)æ˜¯æˆ‘ä»¬æå‡ºçš„å¤åˆæ‰©å±•æ–¹æ³•ï¼Œä»ä¸‰ä¸ªç»´åº¦åŒæ—¶è¿›è¡Œæ‰©å±•ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/1.png)

æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ‰©å±•æ–¹æ³•å¯ä»¥åœ¨MobileNetså’Œ[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ä¸Šè¡¨ç°è‰¯å¥½ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ‰©å±•çš„æ•ˆæœå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºbaselineç½‘ç»œï¼Œå› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»æ¡†æ¶æœç´¢ï¼ˆneural architecture searchï¼‰å¼€å‘äº†ä¸€ä¸ªæ–°çš„baselineç½‘ç»œï¼Œå¹¶é€šè¿‡æ‰©å±•è¯¥ç½‘ç»œå¾—åˆ°ä¸€ç³»åˆ—æ¨¡å‹ï¼Œç§°ä¸º**EfficientNets**ã€‚Fig1æ˜¯ä¸åŒæ–¹æ³•åœ¨ImageNetä¸Šçš„æ€§èƒ½æ¯”è¾ƒã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/2.png)

# 2.Related Work

ä¸å†è¯¦è¿°ã€‚

# 3.Compound Model Scaling

## 3.1.Problem Formulation

æˆ‘ä»¬å¯ä»¥å°†å·ç§¯ç½‘ç»œçš„å±‚$i$å®šä¹‰ä¸ºå‡½æ•°ï¼š$Y_i = \mathcal{F}\_i (X_i)$ï¼Œå…¶ä¸­$\mathcal{F}_i$æ˜¯æ“ä½œå­ï¼Œ$Y_i$æ˜¯è¾“å‡ºå¼ é‡ï¼Œ$X_i$æ˜¯è¾“å…¥å¼ é‡ï¼Œå…¶å¼ é‡ç»´åº¦ä¸º$\langle H_i,W_i,C_i \rangle$ï¼ˆä¸ºäº†ç®€åŒ–ï¼Œçœç•¥äº†batchç»´åº¦ï¼‰ï¼Œå…¶ä¸­$H_i$å’Œ$W_i$æ˜¯ç©ºé—´ç»´åº¦ï¼Œ$C_i$æ˜¯é€šé“ç»´åº¦ã€‚å·ç§¯ç½‘ç»œ$\mathcal{N}$å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç³»åˆ—å±‚çš„ç»„åˆï¼š$\mathcal{N}=\mathcal{F}_k \odot \cdots \odot \mathcal{F}_2 \odot \mathcal{F}_1(X_1) = \odot_{j=1...k}\mathcal{F}_j(X_1)$ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œå·ç§¯ç½‘ç»œçš„å±‚ä¼šè¢«åˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µå†…çš„æ‰€æœ‰å±‚å…±äº«ç›¸åŒçš„ç»“æ„ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)æœ‰5ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µå†…çš„æ‰€æœ‰å±‚æœ‰ç€ç›¸åŒçš„å·ç§¯ç±»å‹ï¼ˆé™¤äº†ç¬¬ä¸€å±‚ç”¨äºæ‰§è¡Œä¸‹é‡‡æ ·ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†å·ç§¯ç½‘ç»œå®šä¹‰ä¸ºï¼š

$$\mathcal{N} = \bigodot_{i=1...s} \mathcal{F}_i^{L_i} ( X_{\langle H_i , W_i , C_i \rangle} ) \tag{1}$$

å…¶ä¸­ï¼Œ$\mathcal{F}_i^{L_i}$è¡¨ç¤ºåœ¨é˜¶æ®µ$i$ä¸­å±‚$\mathcal{F}_i$é‡å¤äº†$L_i$æ¬¡ï¼Œ$\langle H_i , W_i , C_i \rangle$æ˜¯å±‚$i$çš„è¾“å…¥å¼ é‡$X$çš„ç»´åº¦ã€‚Fig2(a)æ˜¯ä¸€ä¸ªå…¸å‹çš„å·ç§¯ç½‘ç»œï¼Œç©ºé—´ç»´åº¦é€å±‚å‡å°ï¼Œè€Œé€šé“ç»´åº¦é€å±‚åŠ å¤§ï¼Œä¾‹å¦‚ï¼Œåˆå§‹è¾“å…¥ç»´åº¦ä¸º$\langle 224,224,3 \rangle$ï¼Œæœ€ç»ˆè¾“å‡ºç»´åº¦ä¸º$\langle 7,7,512 \rangle$ã€‚

å¸¸è§„çš„å·ç§¯ç½‘ç»œè®¾è®¡é€šå¸¸èšç„¦äºæ‰¾åˆ°æœ€ä¼˜çš„å±‚ç»“æ„$\mathcal{F}_i$ï¼Œä¸ä¹‹ä¸åŒçš„æ˜¯ï¼Œæ¨¡å‹æ‰©å±•æ˜¯åœ¨ä¸æ”¹å˜baselineç½‘ç»œå±‚ç»“æ„çš„åŸºç¡€ä¸Šï¼Œå°è¯•å»æ‰©å±•ç½‘ç»œçš„é•¿åº¦$L_i$ã€å®½åº¦$C_i$å’Œåˆ†è¾¨ç‡$(H_i,W_i)$ã€‚ä½†å¯¹äºæ¯ä¸€å±‚ä»ç„¶å­˜åœ¨ä¸€ä¸ªå·¨å¤§çš„è®¾è®¡ç©ºé—´ï¼Œå³æˆ‘ä»¬å¯ä»¥æ¢ç´¢å¾ˆå¤šä¸åŒçš„$L_i,C_i,H_i,W_i$ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¼©å°è®¾è®¡ç©ºé—´ï¼Œæˆ‘ä»¬é™åˆ¶æ‰€æœ‰å±‚å¿…é¡»æŒ‰ç…§å›ºå®šçš„æ¯”ä¾‹è¿›è¡Œç»Ÿä¸€æ‰©å±•ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ç»™å®šçš„èµ„æºé™åˆ¶æ¡ä»¶ä¸‹ï¼Œæœ€å¤§åŒ–æ¨¡å‹ç²¾åº¦ï¼Œè¿™å¯ä»¥é€šè¿‡ä¸€ä¸ªä¼˜åŒ–é—®é¢˜æ¥è¡¨è¿°ï¼š

$$\begin{align}
\max_{d, w, r} \quad & \text{Accuracy}(\mathcal{N}(d, w, r)) \\
\text{s.t.} \quad & \mathcal{N}(d, w, r) = \bigodot_{i=1 \ldots s} \hat{\mathcal{F}}_i^{d\cdot \hat{L}_i} \left( X_{\langle r \cdot \hat{H}_i, r \cdot \hat{W}_i, w \cdot \hat{C}_i \rangle} \right) \\
& \text{Memory}(\mathcal{N}) \leq \text{target_memory} \\
& \text{FLOPS}(\mathcal{N}) \leq \text{target_flops}
\end{align} \tag{2}$$

å…¶ä¸­ï¼Œ$w,d,r$æ˜¯æ‰©å±•ç³»æ•°ã€‚$\hat{\mathcal{F}_i},\hat{L}_i,\hat{H}_i,\hat{W}_i,\hat{C}_i$æ˜¯baselineç½‘ç»œé¢„å®šä¹‰çš„å‚æ•°ï¼Œä¾‹å­è§è¡¨1ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/3.png)

## 3.2.Scaling Dimensions

ç¬¬äºŒä¸ªé—®é¢˜çš„éš¾ç‚¹åœ¨äºç¡®å®šæœ€ä¼˜çš„$d,w,r$ï¼Œå› ä¸º$d,w,r$å½¼æ­¤ä¾èµ–ï¼Œå¹¶ä¸”åœ¨ä¸åŒèµ„æºé™åˆ¶ä¸‹ï¼Œè¿™äº›å€¼ä¼šå‘ç”Ÿå˜åŒ–ã€‚ç”±äºè¿™ä¸€éš¾ç‚¹ï¼Œä¼ ç»Ÿæ–¹æ³•å¤§å¤šé€‰æ‹©åªåœ¨ä¸€ä¸ªç»´åº¦ä¸Šæ‰©å±•å·ç§¯ç½‘ç»œã€‚

ğŸ‘‰**Depth(d):**

æ‰©å±•ç½‘ç»œæ·±åº¦æ˜¯è®¸å¤šå·ç§¯ç½‘ç»œæœ€å¸¸ç”¨çš„æ–¹æ³•ã€‚ç›´è§‰ä¸Šæ¥è¯´ï¼Œæ›´æ·±çš„å·ç§¯ç½‘ç»œèƒ½å¤Ÿæ•è·æ›´ä¸°å¯Œå’Œæ›´å¤æ‚çš„ç‰¹å¾ï¼Œå¹¶ä¸”åœ¨æ–°ä»»åŠ¡ä¸Šæœ‰è¾ƒå¥½çš„æ³›åŒ–æ€§ã€‚ä½†æ˜¯ï¼Œæ›´æ·±çš„ç½‘ç»œä¹Ÿå› æ¢¯åº¦æ¶ˆå¤±é—®é¢˜è€Œéš¾ä»¥è®­ç»ƒã€‚å°½ç®¡ä¸€äº›æŠ€æœ¯ï¼Œæ¯”å¦‚[skip connections](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)å’Œ[batch normalization](http://shichaoxin.com/2021/06/01/è®ºæ–‡é˜…è¯»-Going-deeper-with-convolutions/)ï¼Œç¼“è§£äº†è®­ç»ƒé—®é¢˜ï¼Œä½†éšç€ç½‘ç»œçš„åŠ æ·±ï¼Œå‡†ç¡®ç‡çš„æ”¶ç›Šè¶Šæ¥è¶Šä½ï¼šæ¯”å¦‚ï¼Œ[ResNet-1000](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)è™½ç„¶æ›´æ·±ï¼Œä½†å…¶å‡†ç¡®ç‡å’Œ[ResNet-101](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ç›¸ä¼¼ã€‚Fig3ä¸­é—´çš„å›¾ä¹Ÿå°è¯äº†è¿™ä¸€ç»“è®ºã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/4.png)

ğŸ‘‰**Width(w):**

å¯¹äºè¾ƒå°çš„æ¨¡å‹ï¼Œæ‰©å±•ç½‘ç»œå®½åº¦ï¼ˆå³å¢åŠ é€šé“æ•°ï¼‰æ˜¯ä¸€ç§å¸¸è§çš„æ–¹æ³•ã€‚æ›´å®½çš„ç½‘ç»œå¾€å¾€èƒ½å¤Ÿæ•è·æ›´ç»†ç²’åº¦çš„ç‰¹å¾ï¼Œå¹¶ä¸”æ›´å®¹æ˜“è®­ç»ƒã€‚ä½†æ˜¯ï¼Œè¿‡å®½ä¸”è¾ƒæµ…çš„ç½‘ç»œéš¾ä»¥æ•è·é«˜å±‚æ¬¡çš„ç‰¹å¾ã€‚ä»Fig3å·¦å›¾å¯ä»¥çœ‹å‡ºï¼Œå½“ç½‘ç»œå˜å¾—éå¸¸å®½æ—¶ï¼ˆå³$w$è¾ƒå¤§æ—¶ï¼‰ï¼Œå‡†ç¡®ç‡å¾ˆå¿«å°±é¥±å’Œäº†ã€‚

ğŸ‘‰**Resolution(r):**

æ›´é«˜åˆ†è¾¨ç‡çš„è¾“å…¥å›¾åƒèƒ½å¤Ÿä½¿ç½‘ç»œæ•è·æ›´ç»†ç²’åº¦çš„ä¿¡æ¯ã€‚å¦‚Fig3å³å›¾æ‰€ç¤ºï¼Œæ›´é«˜çš„åˆ†è¾¨ç‡ç¡®å®å¯ä»¥æå‡å‡†ç¡®ç‡ï¼Œä½†å½“åˆ†è¾¨ç‡éå¸¸é«˜æ—¶ï¼Œå‡†ç¡®ç‡çš„å¢ç›Šä¼šé€æ¸å‡å¼±ï¼ˆ$r=1.0$è¡¨ç¤ºåˆ†è¾¨ç‡ä¸º$224 \times 224$ï¼Œ$r=2.5$è¡¨ç¤ºåˆ†è¾¨ç‡ä¸º$560 \times 560$ï¼‰ã€‚

ğŸ‘‰**Observation 1**

ç»¼ä¸Šï¼Œæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå‘ç°æ˜¯ï¼Œæ— è®ºæ‰©å±•ç½‘ç»œå®½åº¦ã€æ·±åº¦ã€åˆ†è¾¨ç‡ä¸­çš„å“ªä¸ªç»´åº¦ï¼Œå‡†ç¡®ç‡éƒ½å¯ä»¥å¾—åˆ°æå‡ï¼Œä½†éšç€æ¨¡å‹è¶Šæ¥è¶Šå¤§ï¼Œå‡†ç¡®ç‡çš„å¢ç›Šä¹Ÿè¶Šæ¥è¶Šå°ã€‚

## 3.3.Compound Scaling

æˆ‘ä»¬é€šè¿‡å®éªŒè§‚å¯Ÿåˆ°ï¼Œä¸åŒç»´åº¦çš„æ‰©å±•å¹¶ä¸æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚ç›´è§‚æ¥è¯´ï¼Œå¯¹äºæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼Œæˆ‘ä»¬åº”è¯¥å¢åŠ ç½‘ç»œæ·±åº¦ï¼Œè¿™æ ·å¯ä»¥æœ‰æ›´å¤§çš„æ„Ÿå—é‡ã€‚æ­¤å¤–ï¼Œå½“åˆ†è¾¨ç‡æ›´é«˜æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿåº”è¯¥å¢åŠ ç½‘ç»œçš„å®½åº¦ï¼Œè¿™æ ·èƒ½å¤Ÿæ•è·æ›´ç»†ç²’åº¦çš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥åè°ƒå’Œå¹³è¡¡ä¸åŒç»´åº¦çš„æ‰©å±•ï¼Œè€Œä¸æ˜¯å•ä¸€çš„åªæ‰©å±•æŸä¸€ç»´åº¦ã€‚

ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„çŒœæµ‹ï¼Œæˆ‘ä»¬åœ¨ä¸åŒç½‘ç»œæ·±åº¦å’Œåˆ†è¾¨ç‡ä¸‹ï¼Œæ¯”è¾ƒäº†å®½åº¦æ‰©å±•çš„æ•ˆæœï¼Œç»“æœè§Fig4ã€‚å¦‚æœæˆ‘ä»¬ä¸æ”¹å˜æ·±åº¦ï¼ˆ$d=1.0$ï¼‰å’Œåˆ†è¾¨ç‡ï¼ˆ$r=1.0$ï¼‰ï¼Œåªæ‰©å±•å®½åº¦ï¼Œå‡†ç¡®ç‡å¾ˆå¿«å°±é¥±å’Œäº†ã€‚ä½†å¦‚æœå¢åŠ æ·±åº¦ï¼ˆ$d=2.0$ï¼‰å’Œåˆ†è¾¨ç‡ï¼ˆ$r=2.0$ï¼‰ï¼Œåœ¨ç›¸åŒFLOPSä¸‹ï¼Œæ‰©å±•å®½åº¦å¯ä»¥å¾—åˆ°æ›´é«˜çš„å‡†ç¡®ç‡ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/5.png)

ğŸ‘‰**Observation 2**

ç»¼ä¸Šï¼Œæˆ‘ä»¬çš„ç¬¬äºŒä¸ªå‘ç°æ˜¯ï¼Œä¸ºäº†è¿½æ±‚æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ•ˆç‡ï¼Œåœ¨æ‰©å±•å·ç§¯ç½‘ç»œæ—¶ï¼Œå¹³è¡¡ç½‘ç»œçš„å®½åº¦ã€æ·±åº¦å’Œåˆ†è¾¨ç‡æ˜¯è‡³å…³é‡è¦çš„ã€‚

äº‹å®ä¸Šï¼Œä¸€äº›å…ˆå‰çš„ç ”ç©¶å·²ç»å°è¯•é€šè¿‡ä»»æ„æ–¹å¼å¹³è¡¡ç½‘ç»œçš„å®½åº¦å’Œæ·±åº¦ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½éœ€è¦ç¹ççš„æ‰‹åŠ¨è°ƒå‚ã€‚

æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤åˆæ‰©å±•æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä¸€ä¸ªå¤åˆç³»æ•°$\phi$æ¥ç»Ÿä¸€æ‰©å±•ç½‘ç»œçš„å®½åº¦ã€æ·±åº¦å’Œåˆ†è¾¨ç‡ï¼š

$$\begin{align}
\text{depth:} \quad d &= \alpha^\phi \\
\text{width:} \quad w &= \beta^\phi \\
\text{resolution:} \quad r &= \gamma^\phi \\
\text{s.t.} \quad & \alpha \cdot \beta^2 \cdot \gamma^2 \approx 2 \\
& \alpha \geq 1, \beta \geq 1, \gamma \geq 1
\end{align} \tag{3}$$

å…¶ä¸­ï¼Œ$\alpha,\beta,\gamma$æ˜¯é€šè¿‡å°èŒƒå›´ç½‘æ ¼æœç´¢ç¡®å®šçš„å¸¸æ•°ã€‚ç›´è§‚æ¥è¯´ï¼Œ$\phi$æ˜¯ä¸€ä¸ªç”±ç”¨æˆ·æŒ‡å®šçš„ç³»æ•°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¸¸è§„å·ç§¯æ“ä½œçš„FLOPSä¸$d,w^2,r^2$æˆæ­£æ¯”ï¼Œæ¯”å¦‚ï¼Œå°†ç½‘ç»œçš„æ·±åº¦åŠ å€ä¼šä½¿FLOPSåŠ å€ï¼Œè€Œå°†ç½‘ç»œçš„å®½åº¦æˆ–åˆ†è¾¨ç‡åŠ å€åˆ™ä¼šä½¿FLOPSå¢åŠ å››å€ã€‚ç”±äºå·ç§¯æ“ä½œé€šå¸¸åœ¨å·ç§¯ç½‘ç»œçš„è®¡ç®—æˆæœ¬ä¸­å ä¸»å¯¼åœ°ä½ï¼Œåœ¨ä½¿ç”¨å…¬å¼(3)æ‰©å±•å·ç§¯ç½‘ç»œæ—¶ï¼Œæ€»çš„FLOPSä¼šè¿‘ä¼¼å¢åŠ $(\alpha \cdot \beta^2 \cdot \gamma^2)^ \phi$ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é™åˆ¶$\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$ï¼Œä»¥ç¡®ä¿å¯¹äºä»»ä½•æ–°çš„$\phi$ï¼Œæ€»FLOPSå°†è¿‘ä¼¼å¢åŠ $2^{\phi}$ã€‚

# 4.EfficientNet Architecture

å› ä¸ºæ¨¡å‹æ‰©å±•ä¸æ”¹å˜baselineç½‘ç»œä¸­çš„å±‚$\hat{\mathcal{F}}_i$ï¼Œæ‰€ä»¥è®¾è®¡ä¸€ä¸ªå¥½çš„baselineç½‘ç»œä¹Ÿè‡³å…³é‡è¦ã€‚æˆ‘ä»¬åœ¨å·²æœ‰çš„å·ç§¯ç½‘ç»œä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ‰©å±•æ–¹æ³•ï¼Œä½†ä¸ºäº†æ›´å¥½çš„è¯æ˜æˆ‘ä»¬æ‰©å±•æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„mobile-sizeçš„baselineç½‘ç»œï¼Œç§°ä¸ºEfficientNetã€‚

å€Ÿé‰´è®ºæ–‡â€œTan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.â€ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨å¤šç›®æ ‡ç¥ç»æ¡†æ¶æœç´¢ï¼ˆmulti-objective neural architecture searchï¼‰å¼€å‘äº†æˆ‘ä»¬çš„baselineç½‘ç»œï¼Œè¯¥æ–¹æ³•åŒæ—¶ä¼˜åŒ–äº†å‡†ç¡®ç‡å’ŒFLOPSã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸è®ºæ–‡â€œTan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.â€ç›¸åŒçš„æœç´¢ç©ºé—´ï¼Œå¹¶å°†$ACC(m) \times [FLOPS(m) / T]^w$ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œå…¶ä¸­ï¼Œ$ACC(m)$å’Œ$FLOPS(m)$åˆ†åˆ«è¡¨ç¤ºæ¨¡å‹$m$çš„å‡†ç¡®ç‡å’ŒFLOPSï¼Œ$T$æ˜¯ç›®æ ‡FLOPSï¼Œ$w=-0.07$æ˜¯æ§åˆ¶å‡†ç¡®ç‡å’ŒFLOPSæƒè¡¡çš„è¶…å‚æ•°ã€‚ä¸è®ºæ–‡â€œTan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.â€ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„æ˜¯FLOPSï¼Œè€Œä¸æ˜¯latencyï¼Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸é’ˆå¯¹ä»»ä½•ç‰¹å®šçš„ç¡¬ä»¶è®¾å¤‡ã€‚æˆ‘ä»¬çš„æœç´¢è¿‡ç¨‹ç”Ÿæˆäº†ä¸€ä¸ªé«˜æ•ˆçš„ç½‘ç»œï¼Œæˆ‘ä»¬å°†å…¶å‘½åä¸ºEfficientNet-B0ã€‚ç”±äºæˆ‘ä»¬ä½¿ç”¨äº†ä¸è®ºæ–‡â€œTan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.â€ç›¸åŒçš„æœç´¢ç©ºé—´ï¼Œæ‰€ä»¥EfficientNet-B0çš„æ¡†æ¶ä¸MnasNetç±»ä¼¼ï¼Œä½†æ˜¯ç”±äºæˆ‘ä»¬çš„ç›®æ ‡FLOPSæ›´å¤§ï¼ˆæˆ‘ä»¬çš„ç›®æ ‡FLOPSä¸º400Mï¼‰ï¼Œæ‰€ä»¥EfficientNet-B0ä¼šç¨å¤§ä¸€äº›ã€‚EfficientNet-B0çš„æ¡†æ¶è§è¡¨1ã€‚å…¶ä¸»è¦ç»“æ„ä¸ºMBConvï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜æ·»åŠ äº†squeeze-and-excitation optimizationã€‚

>MBConvè§è®ºæ–‡ï¼šSandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018.ã€‚
>
>squeeze-and-excitation optimizationè®ºæ–‡ï¼šHu, J., Shen, L., and Sun, G. Squeeze-and-excitation networks. CVPR, 2018.ã€‚

ä»baselineæ¨¡å‹EfficientNet-B0å¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸¤æ­¥æ¥åº”ç”¨æˆ‘ä»¬æå‡ºçš„å¤åˆæ‰©å±•æ–¹æ³•ï¼š

* ç¬¬ä¸€æ­¥ï¼šé¦–å…ˆå›ºå®š$\phi = 1$ï¼Œå‡å®šæœ‰è¶…è¿‡ä¸¤å€çš„å¯ç”¨èµ„æºï¼ŒåŸºäºå¼(2)å’Œå¼(3)å¯¹$\alpha,\beta,\gamma$è¿›è¡Œå°èŒƒå›´çš„ç½‘æ ¼æœç´¢ã€‚å¯¹äºEfficientNet-B0ï¼Œæˆ‘ä»¬å®éªŒå¾—åˆ°çš„æœ€ä¼˜å€¼ä¸º$\alpha=1.2,\beta=1.1,\gamma=1.15$ï¼Œæ»¡è¶³çº¦æŸ$\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2$ã€‚
* ç¬¬äºŒæ­¥ï¼šç„¶åå›ºå®š$\alpha,\beta,\gamma$ï¼ŒåŸºäºå¼(3)ï¼Œä½¿ç”¨ä¸åŒçš„$\phi$ï¼Œå°±å¾—åˆ°äº†EfficientNet-B1åˆ°B7ï¼Œè¯¦è§è¡¨2ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/6.png)

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›´æ¥åœ¨å¤§å‹æ¨¡å‹ä¸Šæœç´¢$\alpha,\beta,\gamma$å‚æ•°ï¼Œå¯ä»¥å®ç°æ›´å¥½çš„æ€§èƒ½ï¼Œä½†åœ¨å¤§å‹æ¨¡å‹ä¸Šè¿›è¡Œæœç´¢çš„æˆæœ¬ä¼šå˜å¾—æå…¶é«˜æ˜‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼šä»…åœ¨ä¸€ä¸ªå°å‹baselineç½‘ç»œä¸Šè¿›è¡Œä¸€æ¬¡æœç´¢ï¼ˆç¬¬ä¸€æ­¥ï¼‰ï¼Œç„¶åå°†ç›¸åŒçš„æ‰©å±•ç³»æ•°åº”ç”¨äºæ‰€æœ‰å…¶ä»–æ¨¡å‹ï¼ˆç¬¬äºŒæ­¥ï¼‰ã€‚

# 5.Experiments

## 5.1.Scaling Up MobileNets and ResNets

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/7.png)

## 5.2.ImageNet Results for EfficientNet

EfficientNetåœ¨ImageNetä¸Šçš„è®­ç»ƒè®¾ç½®å’Œè®ºæ–‡â€œTan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.â€å·®ä¸å¤šï¼šä½¿ç”¨[RMSPropä¼˜åŒ–å™¨](http://shichaoxin.com/2020/03/13/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åå…«è¯¾-RMSprop/)ï¼ˆdecay=0.9ï¼Œmomentum=0.9ï¼‰ï¼Œbatch norm momentum=0.99ï¼Œweight decay=1e-5ï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º0.256ä¸”æ¯2.4ä¸ªepochè¡°å‡ä¸ºåŸæ¥çš„0.97å€ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨äº†[SiLUæ¿€æ´»å‡½æ•°](http://shichaoxin.com/2022/04/09/è®ºæ–‡é˜…è¯»-GAUSSIAN-ERROR-LINEAR-UNITS-(GELUS)/)ã€AutoAugmentå’Œstochastic depthï¼ˆå­˜æ´»æ¦‚ç‡ä¸º0.8ï¼‰ã€‚ä¼—æ‰€å‘¨çŸ¥ï¼Œæ›´å¤§çš„æ¨¡å‹éœ€è¦æ›´å¤šçš„æ­£åˆ™åŒ–ï¼Œæˆ‘ä»¬å°†dropoutæ¯”ç‡ä»EfficientNet-B0çš„0.2çº¿æ€§å¢åŠ åˆ°B7çš„0.5ã€‚æˆ‘ä»¬ä»trainingæ•°æ®é›†ä¸­éšæœºé€‰æ‹©25Kå¼ å›¾åƒä½œä¸ºminivalæ•°æ®é›†ï¼Œå¹¶ä¸”åœ¨minivalä¸Šæ‰§è¡Œäº†[early stopping](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#62early-stopping)ï¼Œç„¶ååœ¨validationæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°å¹¶æ±‡æŠ¥äº†å‡†ç¡®ç‡ã€‚ç»“æœè¯¦è§è¡¨2ã€‚

>AutoAugmentè®ºæ–‡ï¼šCubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. Autoaugment: Learning augmentation policies from data. CVPR, 2019.ã€‚
>
>stochastic depthè®ºæ–‡ï¼šHuang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. ECCV, pp. 646â€“661, 2016.ã€‚

Fig1æ˜¯å‚æ•°é‡å’Œå‡†ç¡®ç‡çš„å…³ç³»å›¾ï¼ŒFig5æ˜¯FLOPSå’Œå‡†ç¡®ç‡çš„å…³ç³»å›¾ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/8.png)

latencyçš„æµ‹è¯•ç»“æœè§è¡¨4ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/9.png)

## 5.3.Transfer Learning Results for EfficientNet

æˆ‘ä»¬è¿˜åœ¨å¸¸è§çš„ä¸€ç³»åˆ—è¿ç§»å­¦ä¹ æ•°æ®é›†ä¸Šè¯„ä¼°äº†EfficientNetï¼Œè¿™äº›æ•°æ®é›†è§è¡¨6ã€‚æˆ‘ä»¬å…ˆåœ¨ImageNetä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œç„¶ååœ¨æ–°æ•°æ®é›†ä¸Šè¿›è¡Œäº†fine-tuneã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/10.png)

æµ‹è¯•ç»“æœè§è¡¨5ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/11.png)

Fig6æ˜¯å‚æ•°é‡å’Œå‡†ç¡®ç‡çš„å…³ç³»å›¾ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/12.png)

# 6.Discussion

åŸºäºEfficientNet-B0ï¼Œä¸åŒæ‰©å±•æ–¹æ³•çš„æ¯”è¾ƒè§Fig8ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/13.png)

ä¸ºäº†è¿›ä¸€æ­¥ç†è§£ä¸ºä»€ä¹ˆæˆ‘ä»¬æå‡ºçš„å¤åˆæ‰©å±•æ–¹æ³•ä¼˜äºå…¶ä»–æ‰©å±•æ–¹æ³•ï¼ŒFig7æ¯”è¾ƒäº†ä¸åŒæ‰©å±•æ¨¡å‹çš„class activation mapã€‚

>class activation mapè®ºæ–‡ï¼šZhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. Learning deep features for discriminative localization. CVPR, pp. 2921â€“2929, 2016.ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/14.png)

æ‰€æœ‰è¿™äº›æ‰©å±•æ¨¡å‹éƒ½åŸºäºç›¸åŒçš„baselineï¼Œå®ƒä»¬çš„ç»Ÿè®¡ä¿¡æ¯è§è¡¨7ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/15.png)

# 7.Conclusion

ä¸å†èµ˜è¿°ã€‚

# 8.Appendix

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/EfficientNet/16.png)

# 9.åŸæ–‡é“¾æ¥

ğŸ‘½[EfficientNetï¼šRethinking Model Scaling for Convolutional Neural Networks](https://github.com/x-jeff/AI_Papers/blob/master/2024/EfficientNetï¼šRethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf)