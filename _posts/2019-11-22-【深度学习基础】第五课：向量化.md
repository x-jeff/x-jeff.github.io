---
layout:     post
title:      ã€æ·±åº¦å­¦ä¹ åŸºç¡€ã€‘ç¬¬äº”è¯¾ï¼šå‘é‡åŒ–
subtitle:   vectorizationï¼Œnumpyï¼Œbroadcastingï¼Œlogistic regression code
date:       2019-11-22
author:     x-jeff
header-img: blogimg/20191122.jpg
catalog: true
tags:
    - Deep Learning Series
---
>ã€æ·±åº¦å­¦ä¹ åŸºç¡€ã€‘ç³»åˆ—åšå®¢ä¸ºå­¦ä¹ Courseraä¸Šå´æ©è¾¾æ·±åº¦å­¦ä¹ è¯¾ç¨‹æ‰€åšçš„è¯¾ç¨‹ç¬”è®°ã€‚  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.å‰è¨€

**å‘é‡åŒ–(vectorization)**å¯ä»¥æ¶ˆé™¤ä»£ç ä¸­æ˜¾å¼çš„forå¾ªç¯ï¼Œå¤§å¤§æå‡ä»£ç çš„è¿è¡Œæ•ˆç‡ã€‚

å› æ­¤ï¼Œåªè¦æœ‰å¯èƒ½ï¼Œå°±å°½é‡é¿å…åœ¨ä»£ç ä¸­ä½¿ç”¨æ˜¾å¼çš„forå¾ªç¯ã€‚

# 2.ä»€ä¹ˆæ˜¯å‘é‡åŒ–

å‡è®¾æœ‰ï¼š$z=w^Tx+b$ï¼Œå…¶ä¸­ï¼Œ

$$w=\begin{bmatrix} w_1 \\ \vdots \\ w_n \end{bmatrix};x=\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}$$

æˆ‘ä»¬çœ‹ä¸‹åœ¨pythonä»£ç ä¸­ï¼Œåˆ†åˆ«ä½¿ç”¨éå‘é‡åŒ–å’Œå‘é‡åŒ–ä¸¤ç§æ–¹æ³•è®¡ç®—zæ—¶çš„å·®å¼‚ã€‚

ğŸ‘‰ä½¿ç”¨**éå‘é‡åŒ–**çš„æ–¹æ³•ï¼š

```python
z=0
for i in range n :
	z+=w[i]*x[i]
z+=b
```

ğŸ‘‰ä½¿ç”¨**å‘é‡åŒ–**çš„æ–¹æ³•ï¼š

```python
import numpy as np
z=np.dot(w,x)+b
```

ä¸‹é¢é€šè¿‡ä¸€ä¸ªæ›´åŠ ç›´è§‚çš„ä¾‹å­æ¥çœ‹ä¸‹å‘é‡åŒ–å’Œéå‘é‡åŒ–ä¸¤ç§æ–¹å¼çš„æ•ˆç‡ï¼š

```python
a = np.random.rand(1000000) #æ„å»º1000000ç»´çš„æ•°ç»„a
b = np.random.rand(1000000) #æ„å»º1000000ç»´çš„æ•°ç»„b

tic = time.time()
c = np.dot(a,b) #å‘é‡åŒ–æ–¹æ³•
toc = time.time()
print(c)
print("Vectorized Version : " + str(1000*(toc-tic)) + "ms")

c = 0
tic = time.time()
for i in range(1000000) :
    c += a[i]*b[i] #ä½¿ç”¨forå¾ªç¯ï¼Œéå‘é‡åŒ–æ–¹æ³•
toc = time.time()
print(c)
print("for loop : " + str(1000*(toc-tic)) + "ms")
```

è¾“å‡ºç»“æœè§ä¸‹ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/DeepLearningSeries/Lesson5/5x1.png)

é¦–å…ˆç¡®ä¿ä¸¤ç§æ–¹æ³•çš„è¾“å‡ºç»“æœcéƒ½æ˜¯ä¸€æ ·çš„ã€‚

ä»ç»“æœä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œå‘é‡åŒ–æ–¹æ³•çš„æ•ˆç‡æ¯”éå‘é‡åŒ–é«˜å¾ˆå¤šã€‚å› ä¸ºnumpyéšå»äº†æ˜¾å¼çš„forå¾ªç¯ï¼Œå¹¶å……åˆ†åˆ©ç”¨äº†å¹¶è¡ŒåŒ–ã€‚è¿™ä¸ªç‰¹ç‚¹å¯¹äºåœ¨CPUå’ŒGPUä¸Šè¿ç®—éƒ½æ˜¯æˆç«‹çš„ã€‚

## 2.1.æ›´å¤šçš„ä¾‹å­

ğŸ‘‰å‡è®¾å‘é‡vï¼š

$$v=\begin{bmatrix} v_1 \\ \vdots \\ v_n \end{bmatrix}$$

æ±‚vçš„æŒ‡æ•°ï¼š

$$v=\begin{bmatrix} e^{v_1} \\ \vdots \\ e^{v_n} \end{bmatrix}$$

éå‘é‡åŒ–çš„æ–¹æ³•ï¼š

```python
u = np.zeros((n,1))
for i in range(n):
	u[i]=math.exp(v[i])
```

å‘é‡åŒ–çš„æ–¹æ³•ï¼š

```python
import numpy as np
u = np.exp(v)
```

>numpyä¸­å…¶ä»–çš„ç±»ä¼¼ç”¨æ³•ï¼š  
>1. `u=np.log(v)`   
>2. `u=np.abs(v)`   
>3. `u=np.maximum(v,0)` #è¿”å›vä¸­æ¯ä¸ªå…ƒç´ å’Œ0ä¹‹é—´çš„æœ€å¤§å€¼       
>4. `v**2` #è®¡ç®—vä¸­æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹     
>5. `1/v` #è®¡ç®—vä¸­æ¯ä¸ªå…ƒç´ çš„å€’æ•°

# 3.ä½¿ç”¨å‘é‡åŒ–å®ç°logisticå›å½’æ¢¯åº¦ä¸‹é™ç®—æ³•

æ ¹æ®ä¹‹å‰åšå®¢[ã€æ·±åº¦å­¦ä¹ åŸºç¡€ã€‘ç¬¬å››è¯¾ï¼šæ­£å‘ä¼ æ’­ä¸åå‘ä¼ æ’­](http://shichaoxin.com/2019/11/09/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››è¯¾-æ­£å‘ä¼ æ’­ä¸åå‘ä¼ æ’­/)ä¸­æ‰€è®²çš„è®¡ç®—logisticå›å½’ä¸­æ¢¯åº¦çš„ç®—æ³•ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/DeepLearningSeries/Lesson5/5x2.png)

è¿™é‡Œæœ‰ä¸¤ä¸ªæ˜¾å¼forå¾ªç¯ã€‚

ğŸ‘‰ç°åœ¨å‘é‡åŒ–ç¬¬ä¸€ä¸ªforå¾ªç¯ï¼š

å®šä¹‰$Z=[z^{(1)},z^{(2)},...,z^{(m)}]$ï¼Œåˆ™æœ‰ï¼š

$$Z=[w_1,w_2,...,w_n] \begin{bmatrix} x^{(1)}_1 & x^{(2)}_1 & \cdots & x^{(m)}_1 \\ \vdots & \vdots & \vdots & \vdots \\ x^{(1)}_n & x^{(2)}_n & \cdots & x^{(m)}_n \\ \end{bmatrix} + [b,b,...,b]$$

å³ï¼š$Z=w^T X+b$ã€‚å¯ä½¿ç”¨numpyå°†ä¸Šå¼å†™ä¸ºï¼š`Z=np.dot(w.T,X)+b`ã€‚

â—ï¸åœ¨å®é™…è¿ç®—æ—¶ï¼Œnumpyä¼šå°†å®æ•°bæ‰©å±•ä¸º$[b,b,...,b]$ï¼Œè¿™ä¸ªæ“ä½œåœ¨pythonä¸­å«åš**å¹¿æ’­(broadcasting)**ã€‚

åŒç†ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰$A=[a^{(1)},a^{(2)},...,a^{(m)}]$ï¼Œç„¶åå°†$Z$ä½œä¸ºsigmoidå‡½æ•°çš„è¾“å…¥ï¼Œè¾“å‡ºä¸ºAã€‚

åŒæ—¶å®šä¹‰$dZ=[dz^{(1)},dz^{(2)},...,dz^{(m)}];Y=[y^{(1)},y^{(2)},...,y^{(m)}]$ï¼Œå› æ­¤æœ‰ï¼š$dZ=A-Y$ã€‚

ğŸ‘‰åŒæ ·çš„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ç¬¬äºŒä¸ªforå¾ªç¯å‘é‡åŒ–ï¼š

é¦–å…ˆå°†$dw_1,dw_2,...,dw_n$åˆå§‹åŒ–ä¸ºä¸€ä¸ªå‘é‡dwï¼š`dw=np.zeros((n,1))`ã€‚ç„¶åå¯ä»¥æŠŠç¬¬äºŒä¸ªforå¾ªç¯å‘é‡åŒ–ä¸ºï¼š$dw+=x^{(i)} dz^{(i)}$ï¼Œåœ¨æ¶ˆå»ç¬¬ä¸€ä¸ªforå¾ªç¯åå³ä¸ºï¼š$dw=X \cdot dZ^T$ã€‚

ä½†æ˜¯å…¶ä¸­è¿˜æœ‰å¯¹$dw,db$ä¸­å„å…ƒç´ ç´¯åŠ æ±‚å’Œç„¶åæ±‚å¹³å‡çš„è¿‡ç¨‹ï¼Œè¿™ä¹Ÿéœ€è¦å¯¹mä¸ªæ ·æœ¬åšä¸€ä¸ªéå†ã€‚åŒæ ·ä¹Ÿå¯ä»¥å¯¹å…¶è¿›è¡Œå‘é‡åŒ–ï¼š`db=(1/m)* np.sum(dZ)`ã€`dw=(1/m)* np.dot(X,dZ.T)`ã€‚

æœ€åï¼Œä¾¿å¯å¯¹å‚æ•°$(w,b)$è¿›è¡Œä¸€æ¬¡æ›´æ–°ï¼š$w:=w-\alpha dw$ã€$b:=b-\alpha db$ã€‚

åˆ°æ­¤ï¼Œæˆ‘ä»¬å°±å®ç°äº†ä¸ä½¿ç”¨ä»»ä½•ä¸€ä¸ªæ˜¾å¼çš„forå¾ªç¯å°±èƒ½åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•å®Œæˆä¸€æ¬¡å‚æ•°çš„æ›´æ–°ã€‚ä½†æ˜¯ï¼Œå¦‚æœæƒ³è¦å¯¹å‚æ•°è¿›è¡Œå¤šæ¬¡æ›´æ–°ï¼Œå³å¤šæ¬¡è¿­ä»£ï¼Œå°±ä¸å¾—ä¸ä½¿ç”¨ä¸€ä¸ªforå¾ªç¯äº†ï¼Œè¿™ä¸ªæ˜¯æ— æ³•é¿å…çš„ã€‚

# 4.å¹¿æ’­(Broadcasting)

é€šè¿‡å‡ ä¸ªä¾‹å­æ¥çœ‹ä¸‹pythonä¸­broadcastingçš„åŸç†ã€‚

æ›´åŠ è¯¦ç»†çš„ä»‹ç»è¯·æŸ¥é˜…[numpyå®˜æ–¹æ–‡æ¡£](https://numpy.org)ä¸­å¯¹broadcastingçš„ä»‹ç»ã€‚æœ¬èŠ‚æ‰€ä»‹ç»çš„broadcastingæ–¹å¼æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸»è¦ç”¨åˆ°çš„ã€‚

## 4.1.ä¾‹å­ä¸€

å‡è®¾ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†å››ç§é£Ÿç‰©çš„æˆåˆ†è¡¨ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/DeepLearningSeries/Lesson5/5x3.png)

å¦‚æœæˆ‘ä»¬ç°åœ¨æƒ³è¦çŸ¥é“æ¯ç§é£Ÿç‰©ä¸­ç¢³æ°´ã€è›‹ç™½è´¨å’Œè„‚è‚ªçš„å¡è·¯é‡Œå æ¯”ã€‚ä¾‹å¦‚è‹¹æœä¸­ç¢³æ°´çš„å¡è·¯é‡Œå æ¯”ä¸ºï¼š$\frac{56.0}{56.0+1.2+1.8}=94.9\%$ã€‚é‚£ä¹ˆæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯ç”¨æ¯åˆ—ä¸­çš„å„ä¸ªå…ƒç´ å»é™¤ä»¥å¯¹åº”åˆ—çš„å’Œã€‚æˆ‘ä»¬å°è¯•ä¸ä½¿ç”¨æ˜¾å¼çš„forå¾ªç¯æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚

å…ˆå°†æ•°æ®è¾“å…¥åˆ°æ•°ç»„ä¸­ï¼š

```python
A = np.array([
    [56.0, 0.0, 4.4, 68.0],
    [1.2, 104.0, 52.0, 8.0],
    [1.8, 135.0, 99.0, 0.9]
])
```

å¯¹å„åˆ—æ±‚å’Œï¼š

```python
cal = A.sum(axis=0) #è¾“å‡ºä¸ºï¼š[ 59.  239.  155.4  76.9]
```

>`axis=0`ä¸ºå„åˆ—æ±‚å’Œï¼›`axis=1`ä¸ºå„è¡Œæ±‚å’Œã€‚

è®¡ç®—å„æˆåˆ†æ‰€å ç™¾åˆ†æ¯”ï¼š

```python
percentage = A / cal.reshape(1,4)
```

>è°ƒç”¨reshapeçš„æˆæœ¬å¾ˆä½ï¼Œå¯ä»¥ç»å¸¸è°ƒç”¨reshapeä»¥ç¡®ä¿æ‰€ç”¨çš„çŸ©é˜µæ˜¯è‡ªå·±æƒ³è¦çš„å°ºå¯¸ã€‚

å¾—åˆ°æœ€åçš„ç»“æœï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/DeepLearningSeries/Lesson5/5x4.png)

## 4.2.ä¾‹å­äºŒ

$$\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \\  \end{bmatrix} + 100$$

broadcastingä¼šå°†å…¶æ‰©å±•ä¸ºï¼š

$$\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \\  \end{bmatrix} + \begin{bmatrix} 100 \\ 100 \\ 100 \\ 100 \\  \end{bmatrix}$$

åŒæ ·çš„ï¼Œè¿™ç§æ‰©å±•å½¢å¼ä¹Ÿé€‚ç”¨äºè¡Œå‘é‡ã€‚

$$\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ \end{bmatrix} + \begin{bmatrix} 100 & 200 & 300 \\ \end{bmatrix}$$

broadcastingä¼šå¤åˆ¶ç¬¬äºŒä¸ªçŸ©é˜µçš„è¡Œï¼Œä½¿ä¹‹ä¸ç¬¬ä¸€ä¸ªçŸ©é˜µçš„ç»´æ•°ç›¸åŒä»¥æ»¡è¶³çŸ©é˜µåŠ æ³•çš„æ¡ä»¶ï¼š

$$\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ \end{bmatrix} + \begin{bmatrix} 100 & 200 & 300 \\ 100 & 200 & 300 \\ \end{bmatrix}$$

ç±»ä¼¼çš„ï¼Œ

$$\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ \end{bmatrix} + \begin{bmatrix} 100 \\ 200 \\ \end{bmatrix}$$

è¢«broadcastingæ‰©å±•ä¸ºï¼š

$$\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ \end{bmatrix} + \begin{bmatrix} 100 & 100 & 100 \\ 200 & 200 & 200 \\ \end{bmatrix}$$

# 5.å…³äºnumpyä¸­çš„å‘é‡

numpyåœ¨èµ‹äºˆç¼–ç æå¤§çµæ´»æ€§çš„åŒæ—¶ä¹Ÿå®¹æ˜“å› ä½¿ç”¨ä¸å½“è€Œé€ æˆä¸€äº›ä¸æ˜“å¯Ÿè§‰ã€éš¾ä»¥è°ƒè¯•çš„bugã€‚

æœ¬èŠ‚æˆ‘ä»¬æ¥ç®€å•çš„è®²è§£ä¸€ä¸‹å¦‚ä½•é¿å…ä½¿ç”¨numpyæ„å»ºå‘é‡æ—¶å®¹æ˜“å‡ºç°çš„é”™è¯¯ã€‚

é¦–å…ˆä½¿ç”¨numpyç”Ÿæˆ5ä¸ªéšæœºé«˜æ–¯å˜é‡å¹¶å­˜åœ¨æ•°ç»„aä¸­ï¼š

```python
import numpy as np
a = np.random.randn(5)
```

é€šè¿‡`a.shape`å¯ä»¥çœ‹åˆ°açš„ç»“æ„ä¸º`(5,)`ï¼Œè¿™æ˜¯pythonä¸­ç§©ä¸º1çš„æ•°ç»„ï¼Œæ—¢ä¸æ˜¯è¡Œå‘é‡ä¹Ÿä¸æ˜¯åˆ—å‘é‡ã€‚å¦‚æœæ­¤æ—¶å¯¹aåšè½¬ç½®ï¼Œå³`a.T`ï¼Œä¼šå‘ç°aå’Œaè½¬ç½®æ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚

å› æ­¤ï¼Œåœ¨æ·±åº¦å­¦ä¹ ç¼–ç¨‹æ—¶ï¼Œåº”é¿å…ä½¿ç”¨è¿™ç§`(n,)`ç§©ä¸º1çš„æ•°ç»„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡`a = np.random.randn(5,1)`æ¥æ„å»ºä¸€ä¸ªç»´åº¦ä¸º$5\times 1$çš„æ•°ç»„ï¼Œä»è€Œé¿å…ç§©ä¸º1çš„æ•°ç»„ã€‚

ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®å‚æ•°`keepdims=True`æ¥é¿å…ç§©ä¸º1çš„æ•°ç»„ã€‚

>tips:     
>ç»å¸¸ä½¿ç”¨`assert`æ¥ç¡®ä¿æ„å»ºçš„æ•°ç»„æ˜¯è‡ªå·±æƒ³è¦çš„ç»´åº¦ï¼ˆ`assert`çš„æ‰§è¡Œæ•ˆç‡å¾ˆé«˜ï¼Œæ‰€ä»¥ä¸ç”¨æ‹…å¿ƒä¼šä½¿ä»£ç çš„è¿è¡Œé€Ÿåº¦å˜æ…¢ï¼‰ã€‚ä¾‹å¦‚ï¼š`assert(a.shape == (5,1))`ã€‚

æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨`a.reshape()`æ¥è½¬æ¢ç§©ä¸º1çš„æ•°ç»„çš„ç»´åº¦ã€‚

# 6.ä»£ç åœ°å€

1. [å‘é‡åŒ–ã€logisticå›å½’](https://github.com/x-jeff/DeepLearning_Code_Demo/tree/master/Demo1)