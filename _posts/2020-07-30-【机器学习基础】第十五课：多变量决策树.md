---
layout:     post
title:      【机器学习基础】第十五课：多变量决策树
subtitle:   多变量决策树
date:       2020-07-30
author:     x-jeff
header-img: blogimg/20200730.jpg
catalog: true
tags:
    - Machine Learning Series
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.多变量决策树

决策树所形成的分类边界有一个明显的特点：轴平行，即它的分类边界由若干个与坐标轴平行的分段组成。

例如有如下决策树：

![](https://github.com/x-jeff/BlogImage/raw/master/MachineLearningSeries/Lesson15/15x1.png)

其对应的分类边界：

![](https://github.com/x-jeff/BlogImage/raw/master/MachineLearningSeries/Lesson15/15x2.png)

可以看出此时分类边界并不简单，分成了好几段。若能使用斜的划分边界，则决策树模型将大为简化。

**“多变量决策树”**(multivariate decision tree)就是能实现这样的“斜划分”甚至更复杂划分的决策树。以实现斜划分的多变量决策树为例（这样的多变量决策树亦称**“斜决策树”**(oblique decision tree)），在此类决策树中，非叶结点不再是仅对某个属性，而是对属性的线形组合进行测试。例如：

![](https://github.com/x-jeff/BlogImage/raw/master/MachineLearningSeries/Lesson15/15x3.png)

其对应的分类边界：

![](https://github.com/x-jeff/BlogImage/raw/master/MachineLearningSeries/Lesson15/15x4.png)