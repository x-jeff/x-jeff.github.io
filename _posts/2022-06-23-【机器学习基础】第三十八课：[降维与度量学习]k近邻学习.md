---
layout:     post
title:      【机器学习基础】第三十八课：[降维与度量学习]k近邻学习
subtitle:   k近邻学习，懒惰学习（lazy learning），急切学习（eager learning）
date:       2022-06-23
author:     x-jeff
header-img: blogimg/20220623.jpg
catalog: true
tags:
    - Machine Learning Series
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.k近邻学习

k近邻（k-Nearest Neighbor，简称kNN）学习是一种常用的监督学习方法，其工作机制非常简单：给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个“邻居”的信息来进行预测。通常，在分类任务中可使用“投票法”，即选择这k个样本中出现最多的类别标记作为预测结果；在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。

k近邻学习没有显式的训练过程。它是“懒惰学习”（lazy learning）的著名代表，此类学习技术在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到测试样本后再进行处理；相应的，那些在训练阶段就对样本进行学习处理的方法，称为“急切学习”（eager learning）。

下图给出了k近邻分类器的一个示意图。显然，k是一个重要参数，当k取不同值时，分类结果会有显著不同。另一方面，若采用不同的距离计算方式，则找出的“近邻”可能有显著差别，从而也会导致分类结果有显著不同。

![](https://github.com/x-jeff/BlogImage/raw/master/MachineLearningSeries/Lesson38/38x1.png)