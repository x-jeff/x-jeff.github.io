---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘Scaled-YOLOv4ï¼šScaling Cross Stage Partial Network
subtitle:   Scaled-YOLOv4ï¼ŒYOLOv4-CSPï¼ŒYOLOv4-Tinyï¼ŒYOLOv4-Large
date:       2025-07-15
author:     x-jeff
header-img: blogimg/20220716.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

æ¨¡å‹ç¼©æ”¾ï¼ˆmodel scalingï¼‰æŠ€æœ¯éå¸¸é‡è¦ï¼Œè¿™å¯ä»¥è®©æ¨¡å‹åœ¨å„ç§è®¾å¤‡ä¸Šéƒ½è¾¾åˆ°é«˜ç²¾åº¦å’Œå®æ—¶æ¨ç†çš„æœ€ä½³å¹³è¡¡ã€‚

æœ€å¸¸è§çš„æ¨¡å‹ç¼©æ”¾æ–¹æ³•å°±æ˜¯æ”¹å˜backboneç½‘ç»œçš„æ·±åº¦ï¼ˆå³å·ç§¯å±‚çš„æ•°é‡ï¼‰å’Œå®½åº¦ï¼ˆå³å·ç§¯æ ¸çš„æ•°é‡ï¼‰ã€‚

æˆ‘ä»¬åŸºäº[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ï¼Œæå‡ºäº†YOLOv4-CSPï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¼€å‘å‡ºäº†scaled-YOLOv4ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/1.png)

# 2.Related work

ä¸å†èµ˜è¿°ã€‚

# 3.Principles of model scaling

åœ¨å¯¹æ¨¡å‹ç¼©æ”¾æ—¶ï¼Œéœ€è€ƒè™‘å®šé‡å› ç´ ï¼ˆquantitative factorsï¼‰å’Œå®šæ€§å› ç´ ï¼ˆqualitative factorsï¼‰ã€‚å®šé‡å› ç´ åŒ…æ‹¬æ¨¡å‹çš„å‚æ•°æ•°é‡ç­‰ã€‚å®šæ€§å› ç´ åŒ…æ‹¬æ¨¡å‹çš„æ¨ç†æ—¶é—´ã€å¹³å‡ç²¾åº¦ç­‰ã€‚

## 3.1.General principle of model scaling

åœ¨è®¾è®¡é«˜æ•ˆçš„æ¨¡å‹ç¼©æ”¾æ–¹æ³•æ—¶ï¼Œä¸»è¦çš„åŸåˆ™æ˜¯ï¼šå¢åŠ çš„å¼€é”€è¶Šå°‘è¶Šå¥½ï¼Œå‡å°‘çš„å¼€é”€è¶Šå¤šè¶Šå¥½ã€‚æˆ‘ä»¬å°†ä»ä¸‰ä¸ªæ–¹é¢æ¥ç†è§£å®šé‡å› ç´ å¸¦æ¥çš„å¼€é”€ï¼š1ï¼‰å›¾åƒå°ºå¯¸çš„å˜åŒ–ï¼›2ï¼‰ç½‘ç»œå±‚æ•°çš„å˜åŒ–ï¼›3ï¼‰é€šé“æ•°çš„å˜åŒ–ã€‚æˆ‘ä»¬ç”¨äºæ¯”è¾ƒçš„ç½‘ç»œæœ‰[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ã€[ResNeXt](https://shichaoxin.com/2023/12/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)å’Œ[Darknet](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)ã€‚

å‡è®¾æœ‰$k$å±‚çš„CNNï¼Œæ¯å±‚çš„åŸºç¡€é€šé“æ•°ä¸º$b$ï¼Œåˆ™[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)çš„è®¡ç®—é‡ä¸ºï¼š

$$k * [\text{conv}(1 \times 1, b/4) \to \text{conv}(3 \times 3, b/4) \to \text{conv}(1 \times 1,b)]$$

[ResNeXt](https://shichaoxin.com/2023/12/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)çš„è®¡ç®—é‡ä¸ºï¼š

$$k * [\text{conv}(1\times 1,b/2) \to \text{gconv}(3 \times 3 / 32, b/2) \to \text{conv}(1 \times 1,b)]$$

>å‚è§åšå®¢[ã€è®ºæ–‡é˜…è¯»ã€‘Aggregated Residual Transformations for Deep Neural Networks](https://shichaoxin.com/2023/12/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)ä¸­Fig3(c)çš„ç»“æ„ã€‚

[Darknet](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)çš„è®¡ç®—é‡ä¸ºï¼š

$$k * [\text{conv}(1 \times 1, b/2) \to \text{conv}(3 \times 3,b)]$$

æˆ‘ä»¬åˆ†åˆ«ç”¨ç¼©æ”¾å› å­$\alpha,\beta,\gamma$æ¥æ§åˆ¶å›¾åƒå°ºå¯¸ã€ç½‘ç»œå±‚æ•°å’Œé€šé“æ•°çš„å˜åŒ–ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/2.png)

åœ¨è¡¨1ä¸­ï¼Œ"original"åˆ—æ˜¯åŸå§‹çš„FLOPsï¼Œ"size"åˆ—æ˜¯å›¾åƒå°ºå¯¸å˜åŒ–åçš„FLOPsï¼Œ"depth"åˆ—æ˜¯ç½‘ç»œå±‚æ•°å˜åŒ–åçš„FLOPsï¼Œ"width"æ˜¯é€šé“æ•°å˜åŒ–åçš„FLOPsã€‚FLOPså°±æ˜¯ä¹˜åŠ è¿ç®—çš„æ€»æ¬¡æ•°ï¼Œå•å±‚çš„FLOPså¯è®¡ç®—ä¸ºï¼š

$$\text{feature map size} \times \text{input channels} \times \text{output channels} \times \text{kernel size}$$

å‡è®¾feature mapçš„å¤§å°ä¸º$w \times h$ï¼Œå¯¹äº[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä¸­çš„æŸä¸€å±‚ï¼Œ$\text{conv1}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot b \cdot \frac{b}{4} \cdot 1 \cdot 1= \frac{whb^2}{4}$ï¼Œ$\text{conv2}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot \frac{b}{4} \cdot \frac{b}{4} \cdot 3 \cdot 3 = \frac{9whb^2}{16}$ï¼Œ$\text{conv3}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot \frac{b}{4} \cdot b \cdot 1 \cdot 1 = \frac{whb^2}{4}$ï¼Œå•å±‚çš„æ€»è®¡ç®—é‡ä¸º$\frac{whb^2}{4} + \frac{9whb^2}{16} + \frac{whb^2}{4} = \frac{17whb^2}{16}$ï¼Œå› æ­¤$k$å±‚çš„æ€»è®¡ç®—é‡ä¸º$\frac{17whkb^2}{16}$ã€‚

å¯¹äº[ResNeXt](https://shichaoxin.com/2023/12/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)ä¸­çš„æŸä¸€å±‚ï¼Œ$\text{conv1}$çš„è®¡ç®—é‡ä¸º$w\cdot h\cdot b \cdot \frac{b}{2} \cdot 1 \cdot 1 = \frac{whb^2}{2}$ï¼Œå¯¹äº$\text{conv2}$ï¼Œå³$\text{gconv}$ï¼Œä¸€å…±åˆ†äº†32ç»„ï¼Œæ¯ç»„çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot \frac{b}{64} \cdot \frac{b}{64} \cdot 3 \cdot 3 = \frac{9whb^2}{4096}$ï¼Œ32ç»„æ€»çš„è®¡ç®—é‡ä¸º$\frac{9whb^2}{4096} \cdot 32 = \frac{9whb^2}{128}$ï¼Œ$\text{conv3}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot \frac{b}{2} \cdot b \cdot 1 \cdot 1 = \frac{whb^2}{2}$ï¼Œå•å±‚çš„æ€»è®¡ç®—é‡ä¸º$\frac{whb^2}{2} + \frac{9whb^2}{128} + \frac{whb^2}{2} = \frac{137whb^2}{128}$ï¼Œå› æ­¤$k$å±‚æ€»çš„è®¡ç®—é‡ä¸º$\frac{137whkb^2}{128}$ã€‚

å¯¹äº[Darknet](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)ä¸­çš„æŸä¸€å±‚ï¼Œ$\text{conv1}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot b \cdot \frac{b}{2} \cdot 1 \cdot 1 = \frac{whb^2}{2}$ï¼Œ$\text{conv2}$çš„è®¡ç®—é‡ä¸º$w \cdot h \cdot \frac{b}{2} \cdot b \cdot 3 \cdot 3 = \frac{9whb^2}{2}$ï¼Œå•å±‚çš„æ€»è®¡ç®—é‡ä¸º$\frac{whb^2}{2} + \frac{9whb^2}{2} = 5whb^2$ï¼Œå› æ­¤$k$å±‚æ€»çš„è®¡ç®—é‡ä¸º$5whkb^2$ã€‚

[CSPNet](https://shichaoxin.com/2023/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/)å¯ä»¥åº”ç”¨äºå¤šç§CNNæ¡†æ¶ï¼Œå¹¶ä¸”å¯ä»¥é™ä½å‚æ•°é‡å’Œè®¡ç®—é‡ã€‚æ­¤å¤–ï¼Œè¿˜èƒ½æé«˜ç²¾åº¦å’Œé™ä½æ¨ç†æ—¶é—´ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/3.png)

ä»è¡¨2å¯ä»¥çœ‹å‡ºï¼Œåº”ç”¨[CSPNet](https://shichaoxin.com/2023/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/)åï¼Œ[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ã€[ResNeXt](https://shichaoxin.com/2023/12/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Aggregated-Residual-Transformations-for-Deep-Neural-Networks/)å’Œ[Darknet](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)çš„è®¡ç®—é‡åˆ†åˆ«å‡å°‘äº†23.5%ã€46.7%å’Œ50.0%ã€‚å› æ­¤åç»­æˆ‘ä»¬å°†é‡‡ç”¨CSPåŒ–åçš„æ¨¡å‹ä½œä¸ºåŸºç¡€æ¡†æ¶ã€‚

## 3.2.Scaling Tiny Models for Low-End Devices

å¯¹äºä½ç«¯è®¾å¤‡è€Œè¨€ï¼Œæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ä¸ä»…å—åˆ°è®¡ç®—é‡å’Œæ¨¡å‹å¤§å°çš„å½±å“ï¼Œæ›´é‡è¦çš„æ˜¯å¿…é¡»è€ƒè™‘å¤–è®¾ç¡¬ä»¶èµ„æºçš„é™åˆ¶ã€‚å› æ­¤ï¼Œåœ¨è¿›è¡Œå°å‹æ¨¡å‹çš„ç¼©æ”¾æ—¶ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»è€ƒè™‘å†…å­˜å¸¦å®½ã€å†…å­˜è®¿é—®æˆæœ¬ï¼ˆMemory Access Costï¼ŒMACsï¼‰å’ŒDRAMè®¿é—®æµé‡ç­‰å› ç´ ã€‚ä¸ºäº†ç»¼åˆè€ƒè™‘ä¸Šè¿°å› ç´ ï¼Œæˆ‘ä»¬çš„è®¾è®¡å¿…é¡»éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

ğŸ‘‰åŸåˆ™ä¸€ï¼šå°†è®¡ç®—å¤æ‚åº¦æ§åˆ¶åœ¨$O(whkb^2)$ä»¥å†…ã€‚

è½»é‡çº§æ¨¡å‹ä¸å¤§å‹æ¨¡å‹çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œå®ƒä»¬çš„å‚æ•°åˆ©ç”¨æ•ˆç‡å¿…é¡»æ›´é«˜ï¼Œæ‰èƒ½åœ¨è¾ƒå°‘çš„è®¡ç®—é‡ä¸‹è¾¾åˆ°æ‰€éœ€çš„ç²¾åº¦ã€‚åœ¨è¿›è¡Œæ¨¡å‹ç¼©æ”¾æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦å°½å¯èƒ½ä½ã€‚åœ¨è¡¨3ä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†å‡ ç§å…·å¤‡é«˜å‚æ•°åˆ©ç”¨æ•ˆç‡çš„ç½‘ç»œç»“æ„çš„è®¡ç®—é‡ï¼Œå…¶ä¸­$g$è¡¨ç¤º[growth rate](https://shichaoxin.com/2023/11/12/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Densely-Connected-Convolutional-Networks/#3densenets)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/4.png)

é€šå¸¸æ¥è¯´ï¼Œæœ‰$k << g < b$ã€‚å› æ­¤ï¼Œ[DenseNet](https://shichaoxin.com/2023/11/12/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Densely-Connected-Convolutional-Networks/)çš„è®¡ç®—å¤æ‚åº¦æ˜¯$O(whgbk)$ï¼Œ[OSANet](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/)çš„è®¡ç®—å¤æ‚åº¦æ˜¯$O(\max (whbg,whkg^2))$ã€‚è¿™ä¸¤ä¸ªçš„è®¡ç®—å¤æ‚åº¦éƒ½è¦æ¯”[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ç³»åˆ—çš„$O(whkb^2)$è¦ä½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„tinyæ¨¡å‹å€ŸåŠ©äº†è®¡ç®—å¤æ‚åº¦æ›´ä½çš„[OSANet](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/)ã€‚

ğŸ‘‰åŸåˆ™äºŒï¼šæœ€å°åŒ–/å¹³è¡¡feature mapçš„å¤§å°ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/5.png)

è¡¨4è¡¨ç¤ºçš„æ˜¯ä¸»å¹²è·¯å¾„ï¼ˆå› ä¸ºshortcutä¸å‚ä¸è®¡ç®—ï¼Œæ‰€ä»¥ä¸ç»Ÿè®¡ï¼‰çš„ä¸€ä¸ªblockã€‚"original"åˆ—æ˜¯[OSANet](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/)ï¼Œ"CSP"åˆ—æ˜¯CSPOSANetï¼ˆå³èåˆäº†[CSP](https://shichaoxin.com/2023/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/)å’Œ[OSA](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/)ï¼‰ï¼Œ"partial in CB"åˆ—æ˜¯CSPOSANet with PCBï¼ŒPCBæ˜¯Partial in Computational Blockçš„ç¼©å†™ï¼Œå…¶è¯¦ç»†ç»“æ„å¯å‚ç…§Fig3ã€‚

ğŸ‘‰åŸåˆ™ä¸‰ï¼šä¿æŒå·ç§¯åçš„é€šé“æ•°ä¸å˜ã€‚

ä¸ºäº†è¯„ä¼°åœ¨ä½ç«¯è®¾å¤‡ä¸Šçš„è®¡ç®—æˆæœ¬ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»è€ƒè™‘èƒ½è€—é—®é¢˜ã€‚è€Œå½±å“èƒ½è€—çš„æœ€å¤§å› ç´ å°±æ˜¯å†…å­˜è®¿é—®æˆæœ¬ï¼ˆMemory Access Costï¼ŒMACï¼‰ã€‚é€šå¸¸ï¼Œå·ç§¯æ“ä½œçš„MACè®¡ç®—å¦‚ä¸‹ï¼š

$$MAC = hw (C_{in} + C_{out}) + KC_{in}C_{out} \tag{1}$$

å…¶ä¸­ï¼Œ$h,w$è¡¨ç¤ºfeature mapçš„heightå’Œwidthï¼Œ$C_{in},C_{out}$è¡¨ç¤ºè¾“å…¥å’Œè¾“å‡ºçš„é€šé“æ•°ï¼Œ$K$æ˜¯kernel sizeã€‚å½“$C_{in}=C_{out}$æ—¶ï¼ŒMACè¾¾åˆ°æœ€å°å€¼ï¼Œè¯æ˜å¯è§ï¼š[Rethinking Dense Connection](https://shichaoxin.com/2025/04/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-An-Energy-and-GPU-Computation-Efficient-Backbone-Network-for-Real-Time-Object-Detection/#31rethinking-dense-connection)ã€‚

ğŸ‘‰åŸåˆ™å››ï¼šæœ€å°åŒ–å·ç§¯è¾“å…¥/è¾“å‡ºï¼ˆ[CIO](https://shichaoxin.com/2023/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/#31cross-stage-partial-network)ï¼‰ã€‚

[CIO](https://shichaoxin.com/2023/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CSPNET-A-NEW-BACKBONE-THAT-CAN-ENHANCE-LEARNING-CAPABILITY-OF-CNN/#31cross-stage-partial-network)æ˜¯ä¸€ä¸ªç”¨äºè¡¡é‡DRAM IOçš„æŒ‡æ ‡ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/6.png)

å½“$kg > b/2$æ—¶ï¼ŒCSPOSANet with PCBè·å¾—æœ€ä½³çš„CIOã€‚

## 3.3.Scaling Large Models for High-End GPUs

ç”±äºæˆ‘ä»¬å¸Œæœ›åœ¨æ”¾å¤§CNNæ¨¡å‹çš„åŒæ—¶æå‡å‡†ç¡®ç‡å¹¶ä¿æŒå®æ—¶çš„æ¨ç†é€Ÿåº¦ï¼Œå› æ­¤åœ¨æ‰§è¡Œå¤åˆç¼©æ”¾æ—¶ï¼Œå¿…é¡»åœ¨ä¼—å¤šç›®æ ‡æ£€æµ‹å™¨çš„ç¼©æ”¾å› å­ä¸­æ‰¾åˆ°æœ€ä½³ç»„åˆã€‚é€šå¸¸ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´ç›®æ ‡æ£€æµ‹å™¨çš„è¾“å…¥ã€backboneä»¥åŠneckçš„ç¼©æ”¾å› å­ã€‚å¯ä»¥è°ƒæ•´çš„æ½œåœ¨ç¼©æ”¾å› å­æ±‡æ€»å¦‚è¡¨6æ‰€ç¤ºã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/7.png)

å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ä¹‹é—´æœ€å¤§çš„ä¸åŒç‚¹åœ¨äºå‰è€…åªéœ€è¯†åˆ«å‡ºä¸€å¼ å›¾åƒä¸­æœ€å¤§ç»„åˆ†çš„ç±»åˆ«å³å¯ï¼Œè€Œåè€…è¿˜éœ€è¦é¢„æµ‹ä½ç½®å’Œæ¯ä¸ªç›®æ ‡çš„å¤§å°ã€‚åœ¨å•é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨ä¸­ï¼Œæ¯ä¸ªä½ç½®å¯¹åº”çš„ç‰¹å¾å‘é‡ç”¨æ¥é¢„æµ‹è¿™ä¸ªä½ç½®ä¸Šæ½œåœ¨ç›®æ ‡çš„ç±»åˆ«å’Œç›®æ ‡å¤§å°ã€‚æ‰€èƒ½é¢„æµ‹çš„ç›®æ ‡å¤§å°å–å†³äºç‰¹å¾å‘é‡çš„æ„Ÿå—é‡ã€‚åœ¨CNNæ¡†æ¶ä¸­ï¼Œå’Œæ„Ÿå—é‡æœ€ç›´æ¥ç›¸å…³çš„å°±æ˜¯stageï¼Œé€šè¿‡[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)å¯ä»¥çŸ¥é“higher stageæ›´æœ‰åˆ©äºé¢„æµ‹å¤§ç›®æ ‡ã€‚åœ¨è¡¨7ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†å’Œæ„Ÿå—é‡ç›¸å…³çš„ä¸€äº›å‚æ•°ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/8.png)

åœ¨æ‰©å¤§æ¨¡å‹è§„æ¨¡æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šå¢å¤§è¾“å…¥å°ºå¯¸ï¼Œå¢åŠ stageæ•°é‡ï¼Œç„¶åå†è€ƒè™‘å®æ—¶æ€§è¦æ±‚ï¼Œè¿›ä¸€æ­¥æ‰©å¤§depthå’Œwidthã€‚

# 4.Scaled-YOLOv4

æˆ‘ä»¬è®¾è®¡äº†åˆ†åˆ«é€‚ç”¨äºæ™®é€šGPUã€ä½ç«¯GPUå’Œé«˜ç«¯GPUçš„Scaled-YOLOv4ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/11.png)

* é€‚ç”¨äºæ™®é€šGPUï¼šYOLOv4-CSPã€‚
* é€‚ç”¨äºä½ç«¯GPUï¼šYOLOv4-Tinyã€‚
* é€‚ç”¨äºé«˜ç«¯GPUï¼šYOLOv4-Largeï¼Œåˆè¿›ä¸€æ­¥åˆ†ä¸ºYOLOv4-P5ã€YOLOv4-P6å’ŒYOLOv4-P7ã€‚

## 4.1.CSP-ized YOLOv4

>æœ¬éƒ¨åˆ†ä»‹ç»YOLOv4-CSPã€‚

æˆ‘ä»¬é‡æ–°å°†[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)è®¾è®¡ä¸ºäº†YOLOv4-CSPï¼Œè¾¾åˆ°äº†æœ€ä¼˜çš„é€Ÿåº¦/ç²¾åº¦å¹³è¡¡ã€‚

ğŸ‘‰**Backbone**

å°†[CSPDarknet53](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/#34yolov4)çš„ç¬¬ä¸€ä¸ªCSP stageæ”¹æˆäº†åŸå§‹çš„[Darknet](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/#24feature-extractor)ä¸­çš„ç¬¬ä¸€ä¸ªæ®‹å·®å±‚ï¼Œç›¸å½“äºæ˜¯å»æ‰äº†[CSPDarknet53](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/#34yolov4)ä¸­ç¬¬ä¸€ä¸ªstageçš„CSPç»“æ„ã€‚

ğŸ‘‰**Neck**

åœ¨[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨[PANet](https://shichaoxin.com/2023/12/28/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Path-Aggregation-Network-for-Instance-Segmentation/)ä½œä¸ºæ¨¡å‹çš„Neckï¼Œåœ¨Scaled-YOLOv4ä¸­ï¼Œæˆ‘ä»¬å°†[PANet](https://shichaoxin.com/2023/12/28/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Path-Aggregation-Network-for-Instance-Segmentation/)ä¹ŸCSPåŒ–ï¼Œå¯¹åº”CSPSPPã€CSPUpã€CSPDownä¸‰ç§æ¨¡å—ã€‚è¿™ä¸€ä¿®æ”¹èŠ‚çœäº†40%çš„è®¡ç®—é‡ã€‚[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)çš„Neckä¸­ï¼ŒåŸå§‹çš„SPPæ¨¡å—è§Fig2(a)ï¼ŒCSPåŒ–åçš„SPPæ¨¡å—ï¼Œå³CSPSPPï¼Œè§Fig2(b)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/9.png)

rCSPåˆ†ä¸ºä¸¤ç§ï¼Œä¸€ç§æ˜¯rCSP with SPPï¼Œå³Fig2(b)ï¼›å¦ä¸€ç§æ˜¯rCSP without SPPï¼Œç”¨äºCSPUpå’ŒCSPDownã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/10.png)

## 4.2.YOLOv4-tiny

>æœ¬éƒ¨åˆ†ä»‹ç»YOLOv4-Tinyã€‚

YOLOv4-tinyè¢«è®¾è®¡ç”¨äºä½ç«¯GPUï¼Œéµå¾ªç¬¬3.2éƒ¨åˆ†æåˆ°çš„åŸåˆ™ã€‚

YOLOv4-tinyçš„backboneå’Œ[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)åŸºæœ¬ä¸€æ ·ï¼Œå”¯ä¸€çš„ä¿®æ”¹æ˜¯å°†backboneä¸­çš„CSP blockæ›¿æ¢ä¸ºCSPOSANet with PCBï¼Œå…¶ç»“æ„è§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/12.png)

YOLOv4-tinyçš„neckå’ŒYOLOv3-tinyä¸€æ ·ï¼Œæ˜¯ä¸€ä¸ª[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)ã€‚

>æ³¨ï¼š[YOLOv3](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)åŸè®ºæ–‡ä¸­æœªæåŠYOLOv3-tinyï¼ŒåŸä½œè€…åœ¨å…¶githubå…¬å¼€äº†YOLOv3-tinyçš„é…ç½®æ–‡ä»¶ï¼š[yolov3-tiny.cfg](https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg)ã€‚

YOLOv4-tinyçš„æ¡†æ¶å¯å‚è€ƒï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/16.png)

## 4.3.YOLOv4-large

>æœ¬éƒ¨åˆ†ä»‹ç»YOLOv4-Largeã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/13.png)

Fig4ä¸­ï¼Œè™šçº¿æŒ‡çš„æ˜¯åœ¨YOLOv4-P5æˆ–YOLOv4-P6ä¸­ï¼Œè¢«ç®­å¤´æŒ‡å‘çš„CSPUpä¼šè¢«æ›¿æ¢ä¸ºCSPSPPã€‚è¿™ä¸ªè®¾è®¡å’Œ[YOLOv4](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/#34yolov4)ä»¥åŠYOLOv4-CSPéƒ½æ˜¯ä¸€è‡´çš„ã€‚

# 5.Experiments

ä½¿ç”¨MSCOCO 2017ç›®æ ‡æ£€æµ‹æ•°æ®é›†æ¥éªŒè¯scaled-YOLOv4ã€‚æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ImageNeté¢„è®­ç»ƒæ¨¡å‹ï¼Œscaled-YOLOv4æ¨¡å‹éƒ½æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒçš„ï¼Œä½¿ç”¨SGDä¼˜åŒ–å™¨ã€‚YOLOv4-tinyè®­ç»ƒäº†600ä¸ªepochï¼ŒYOLOv4-CSPè®­ç»ƒäº†300ä¸ªepochã€‚å¯¹äºYOLOv4-largeï¼Œæˆ‘ä»¬å…ˆè®­ç»ƒäº†300ä¸ªepochï¼Œç„¶åä½¿ç”¨äº†æ›´å¼ºçš„æ•°æ®æ‰©å±•ï¼Œåˆè®­ç»ƒäº†150ä¸ªepochã€‚ä½¿ç”¨k-meanså’Œé—ä¼ ç®—æ³•ï¼ˆgenetic algorithmsï¼‰ç¡®å®šè¶…å‚æ•°çš„å€¼ã€‚

## 5.1.Ablation study on CSP-ized model

åœ¨COCO minvalæ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœè§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/14.png)

* "Backbone"åˆ—æ˜¯æ¨¡å‹çš„backboneã€‚D53æŒ‡çš„æ˜¯[Darknet53](https://shichaoxin.com/2022/06/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv3-An-Incremental-Improvement/)ã€‚CD53sæŒ‡çš„æ˜¯ç¬¬4.1éƒ¨åˆ†æåˆ°çš„backboneã€‚
* "Neck"åˆ—æ˜¯æ¨¡å‹çš„neckã€‚FPNSPPæŒ‡çš„æ˜¯[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)+[SPP](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ï¼ŒCFPNSPPæŒ‡çš„æ˜¯CSP-FPN+[SPP](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ï¼ŒPANSPPæŒ‡çš„æ˜¯[PAN](https://shichaoxin.com/2023/12/28/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Path-Aggregation-Network-for-Instance-Segmentation/)+[SPP](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ï¼ŒCPANSPPæŒ‡çš„æ˜¯CSP-PAN+[SPP](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ã€‚å¯å‚è€ƒç¬¬4éƒ¨åˆ†ç»™å‡ºçš„YOLOv4-CSPç»“æ„å›¾ã€‚
* "Act."åˆ—æ˜¯æ¿€æ´»å‡½æ•°ã€‚LeakyæŒ‡çš„æ˜¯[Leaky ReLU](https://shichaoxin.com/2019/12/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E7%AC%AC%E4%B8%83%E8%AF%BE-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/#23leaky-relu%E5%87%BD%E6%95%B0)ï¼ŒMishæŒ‡çš„æ˜¯[Mishæ¿€æ´»å‡½æ•°](https://shichaoxin.com/2024/01/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/#34yolov4)ã€‚
* "#Param."åˆ—æ˜¯æ¨¡å‹å‚æ•°é‡ã€‚
* "FLOPs"åˆ—æ˜¯è®¡ç®—é‡ã€‚
* "Batch 8 FPS"åˆ—æŒ‡çš„æ˜¯åœ¨batch size=8æ—¶çš„FPSã€‚
* "AP"åˆ—æ˜¯æ¨¡å‹æ€§èƒ½ã€‚

æ ¹æ®è¡¨8çš„ç»“æœï¼ŒYOLOv4-CSPæœ€ç»ˆé€‰æ‹©äº†æ€§èƒ½æœ€å¥½çš„CD53s-CPANSPP-Mishã€‚

## 5.2.Ablation study on YOLOv4-tiny

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/15.png)

æœ€ç»ˆé€‰æ‹©äº†é€Ÿåº¦/ç²¾åº¦æœ€å‡è¡¡çš„COSA-2x2xä½œä¸ºYOLOv4-tinyçš„æ¡†æ¶ã€‚

## 5.3.Ablation study on YOLOv4-large

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/17.png)

## 5.4.Scaled-YOLOv4 for object detection

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/18.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/19.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/20.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/21.png)

## 5.5.Scaled-YOLOv4 as naiive once-for-all model

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/scaledYOLOv4/22.png)

YOLOv4-P7æ˜¯å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå…¶ä½œä¸ºåŸºå‡†æ¨¡å‹å±•ç¤ºåœ¨Fig5ä¸­ï¼ŒFig5æ¨ªè½´è¡¨ç¤ºä¸åŒçš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œçºµè½´æ˜¯ä¸åŒæ¨¡å‹ç›¸å¯¹äºYOLOv4-P7çš„æ€§èƒ½ã€‚YOLOv4-P7\P7è¡¨ç¤ºç§»é™¤P7ï¼ŒYOLOv4-P7\P7\P6è¡¨ç¤ºç§»é™¤P7å’ŒP6ã€‚ä»Fig5å¯ä»¥çœ‹å‡ºï¼Œé«˜åˆ†è¾¨ç‡ä¸‹ï¼ŒYOLOv4-P7çš„æ€§èƒ½æœ€å¥½ï¼Œä¸­ç­‰åˆ†è¾¨ç‡ä¸‹ï¼ŒYOLOv4-P7\P7çš„æ€§èƒ½æœ€å¥½ï¼Œä½åˆ†è¾¨ç‡ä¸‹ï¼ŒYOLOv4-P7\P7\P6çš„æ€§èƒ½æœ€å¥½ã€‚è¿™è¯´æ˜å¯¹äºä¸åŒçš„è¾“å…¥åˆ†è¾¨ç‡ï¼Œå¯ä»¥ä½¿ç”¨åŒä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹çš„å­ç½‘ç»œï¼Œç›´æ¥éƒ¨ç½²ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œå…·å¤‡â€œä¸€æ¬¡è®­ç»ƒã€å¤šæ¬¡éƒ¨ç½²â€çš„æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºä¸åŒç®—åŠ›å’Œåœºæ™¯éœ€æ±‚ã€‚

# 6.Conclusions

ä¸å†èµ˜è¿°ã€‚

# 7.åŸæ–‡é“¾æ¥

ğŸ‘½[Scaled-YOLOv4ï¼šScaling Cross Stage Partial Network](https://github.com/x-jeff/AI_Papers/blob/master/2025/Scaled-YOLOv4%EF%BC%9AScaling%20Cross%20Stage%20Partial%20Network.pdf)

# 8.å‚è€ƒèµ„æ–™

1. [å…³äºyolov4çš„ç»“æ„å¯¹æ¯”å­¦ä¹ ï¼ˆyolov4/yolov4-tiny/scale yolov4ï¼‰](https://blog.csdn.net/weixin_38715903/article/details/110070836)
2. [Real-time object detection method for embedded devices](https://arxiv.org/pdf/2011.04244)