---
layout:     post
title:      【CUDA编程】【21】【3.Programming Interface】【3.4.Compute Modes】
subtitle:   Default compute mode，Exclusive-process compute mode，Prohibited compute mode
date:       2024-12-19
author:     x-jeff
header-img: blogimg/20181026.jpg
catalog: true
tags:
    - CUDA C++ Programming Guide
---
>【CUDA编程】系列博客参考NVIDIA官方文档[“CUDA C++ Programming Guide（v12.6）”](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.Compute Modes

在Windows Server 2008（及更高版本）或Linux上，可以通过`nvidia-smi`（NVIDIA’s System Management Interface）设置CUDA device的计算模式，一共有3种计算模式：

* 默认计算模式（Default compute mode）：适合多线程、多进程共享GPU的情况。可以通过调用`cudaSetDevice()`设置使用的GPU。
* 独占进程计算模式（Exclusive-process compute mode）：主要用于限制同一时间只有一个进程可以使用GPU，确保单进程性能或避免资源冲突。
* 禁止计算模式（Prohibited compute mode）：通常用于禁用device上的CUDA计算。

如果host线程没有显式调用`cudaSetDevice()`来指定目标GPU，那么运行时API会默认选择device 0，但如果device 0被设置为独占进程计算模式（且被另一个进程正在使用的情况下）或禁止计算模式，那么线程可能会自动切换到其他可用的device上。用户可以通过`cudaSetValidDevices()`指定一个CUDA device的优先级列表，CUDA会根据该列表尝试选择一个可用的device。

需要注意的是，从[Pascal架构](https://shichaoxin.com/2024/09/12/CUDA%E7%BC%96%E7%A8%8B-2-2.Programming-Model/#6compute-capability)开始，device支持计算抢占（Compute Preemption）。这允许计算任务以指令级粒度被抢占，而非像之前的[Maxwell架构和Kepler架构](https://shichaoxin.com/2024/09/12/CUDA%E7%BC%96%E7%A8%8B-2-2.Programming-Model/#6compute-capability)那样以线程块粒度抢占。这样做的好处是可以防止有着长时间运行kernel的应用程序垄断系统或者超时。然而，与计算抢占相关的context切换会带来额外的开销。对于支持该功能的device，此功能会自动启用。可以使用`cudaDeviceGetAttribute()`函数和属性`cudaDevAttrComputePreemptionSupported`来查询device是否支持计算抢占。如果用户希望避免因多个进程导致的context切换开销，可以通过选择独占进程计算模式来确保GPU上只有一个进程处于active的状态。

应用程序可以通过检查device属性`computeMode`来查询device的计算模式（见：[Device Enumeration](https://shichaoxin.com/2024/12/01/CUDA%E7%BC%96%E7%A8%8B-12-3.Programming-Interface-3.2.CUDA-Runtime-3.2.9.Multi-Device-System/#1device-enumeration)）。
