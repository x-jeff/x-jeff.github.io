---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘Aggregated Residual Transformations for Deep Neural Networks
subtitle:   ResNeXt
date:       2023-12-11
author:     x-jeff
header-img: blogimg/20200510.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>ä»£ç å’Œæ¨¡å‹è§ï¼š[https://github.com/facebookresearch/ResNeXt](https://github.com/facebookresearch/ResNeXt)ã€‚

æˆ‘ä»¬æå‡ºçš„ResNeXtèåˆäº†[VGG](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ã€[ResNets](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)å’ŒInceptionæ¨¡å‹ï¼ˆ[Inception-v1](http://shichaoxin.com/2021/06/01/è®ºæ–‡é˜…è¯»-Going-deeper-with-convolutions/)ï¼Œ[Inception-v2/v3](http://shichaoxin.com/2021/11/29/è®ºæ–‡é˜…è¯»-Rethinking-the-Inception-Architecture-for-Computer-Vision/)ï¼Œ[Inception-v4](http://shichaoxin.com/2022/01/13/è®ºæ–‡é˜…è¯»-Inception-v4,-Inception-ResNet-and-the-Impact-of-Residual-Connections-on-Learning/)ï¼‰çš„æ€æƒ³ï¼Œè§Fig1æ‰€ç¤ºã€‚Fig1ä¸­ï¼Œå·¦å³blockçš„å¤æ‚åº¦å‡ ä¹ä¸€æ ·ã€‚ç”¨åè¯â€œåŸºæ•°â€ï¼ˆcardinalityï¼‰æ¥è¡¨ç¤ºåˆ†æ”¯è·¯å¾„çš„æ•°é‡ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/1.png)

åœ¨ImageNetåˆ†ç±»æ•°æ®é›†ä¸Šï¼ŒResNeXtçš„è¡¨ç°è¶…è¿‡äº†[ResNet-101/152](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ã€ResNet-200ã€[Inception-v3](http://shichaoxin.com/2021/11/29/è®ºæ–‡é˜…è¯»-Rethinking-the-Inception-Architecture-for-Computer-Vision/)å’Œ[Inception-ResNet-v2](http://shichaoxin.com/2022/01/13/è®ºæ–‡é˜…è¯»-Inception-v4,-Inception-ResNet-and-the-Impact-of-Residual-Connections-on-Learning/)ã€‚101å±‚çš„ResNeXtç›¸æ¯”ResNet-200ç²¾åº¦æ›´é«˜ï¼Œå¹¶ä¸”å¤æ‚åº¦åªæœ‰ResNet-200çš„50%ã€‚æ­¤å¤–ï¼ŒResNeXtçš„è®¾è®¡æ¯”æ‰€æœ‰Inceptionæ¨¡å‹éƒ½è¦ç®€å•ã€‚ResNeXtåœ¨ILSVRC 2016åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†ç¬¬äºŒåçš„æˆç»©ã€‚æˆ‘ä»¬è¿˜åœ¨ImageNet-5Kå’ŒCOCOç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼ŒResNeXtçš„è¡¨ç°ä¹Ÿéƒ½ä¼˜äºResNetã€‚

# 2.Related Work

ä¸å†èµ˜è¿°ã€‚

# 3.Method

## 3.1.Template

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/2.png)

## 3.2.Revisiting Simple Neurons

æœ€ç®€å•çš„ç¥ç»å…ƒè®¡ç®—å¯ä»¥è§†ä¸ºï¼š

$$\sum_{i=1}^D w_i x_i \tag{1}$$

ç”¨å›¾è¡¨ç¤ºä¸ºï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/3.png)

å…¶ä¹Ÿå¯ä»¥è§†ä¸ºå’ŒInceptionæ¨¡å—ä¸€æ ·ï¼Œåˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šsplittingã€transformingå’Œaggregatingã€‚

1. *Splittingï¼š*å°†å‘é‡$\mathbf{x}$åˆ†å‰²æˆä½ç»´åº¦çš„$x_i$ã€‚
2. *Transformingï¼š*ä½ç»´åº¦çš„è¡¨å¾è¢«è½¬åŒ–ï¼Œå³$w_i x_i$ã€‚
3. *Aggregatingï¼š*å°†è½¬åŒ–ç»“æœèšåˆèµ·æ¥ï¼Œå³$\sum_{i=1}^D$ã€‚

## 3.3.Aggregated Transformations

é€šè¿‡3.2éƒ¨åˆ†çš„åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†èšåˆè½¬åŒ–ç»“æœè¿™ä¸€æ­¥æ‰©å±•ä¸ºä¸€ä¸ªæ›´é€šç”¨çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°æœ¬èº«ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªç½‘ç»œã€‚[Network-in-Network](http://shichaoxin.com/2023/12/10/è®ºæ–‡é˜…è¯»-Network-In-Network/)æ˜¯å°†ç½‘ç»œæ²¿ç€æ·±åº¦æ–¹å‘è¿›è¡Œæ‰©å±•ï¼Œè€Œæˆ‘ä»¬çš„â€Network-in-Neuronâ€åˆ™æ˜¯æ²¿ç€å¦ä¸€ä¸ªæ–°çš„ç»´åº¦è¿›è¡Œæ‰©å±•ã€‚

æˆ‘ä»¬å°†èšåˆè½¬åŒ–ç»“æœè¡¨ç¤ºä¸ºï¼š

$$\mathcal{F}(\mathbf{x}) = \sum_{i=1}^C \mathcal{T}_i (\mathbf{x}) \tag{2}$$

å…¶ä¸­ï¼Œ$\mathcal{T}_i(\mathbf{x})$å¯ä»¥æ˜¯ä»»æ„å‡½æ•°ã€‚

åœ¨å¼(2)ä¸­ï¼Œ$C$ï¼ˆå³Cardinalityï¼‰è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªè½¬åŒ–éœ€è¦è¢«èšåˆï¼Œç±»ä¼¼äºå¼(1)ä¸­çš„$D$ï¼Œä½†ä¸åŒä¹‹å¤„åœ¨äº$C$å¯ä»¥æ˜¯ä»»æ„æ•°é‡ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯æ˜äº†åŸºæ•°ï¼ˆå³$C$ï¼‰åœ¨æå‡ç½‘ç»œæ€§èƒ½æ–¹é¢æ¯”å®½åº¦å’Œæ·±åº¦æ›´æœ‰æ•ˆã€‚

>å®½åº¦ï¼ˆwidthï¼‰æŒ‡çš„æ˜¯ä¸€å±‚å†…é€šé“çš„æ•°é‡ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘ç”¨ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥è®¾è®¡è½¬åŒ–å‡½æ•°ï¼šæ‰€æœ‰çš„$\mathcal{T}_i$éƒ½æ˜¯ç›¸åŒçš„æ‹“æ‰‘ç»“æ„ï¼Œå³Fig1å³æ‰€ç¤ºç»“æ„ã€‚

åœ¨å¼(2)çš„åŸºç¡€ä¸ŠåŠ ä¸Šæ®‹å·®è¿æ¥ï¼š

$$\mathbf{y} = \mathbf{x} + \sum_{i=1}^C \mathcal{T}_i (\mathbf{x}) \tag{3}$$

Fig1å³ï¼Œå³Fig3(a)è¿˜æœ‰å¦å¤–ä¸¤ç§ç­‰æ•ˆæ¨¡å¼ï¼šFig3(b)å’ŒFig3(c)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/4.png)

Fig3(c)ä¸­ä½¿ç”¨çš„åˆ†ç»„å·ç§¯ï¼ˆgrouped convolutionï¼‰æŒ‡çš„æ˜¯[AlexNet](http://shichaoxin.com/2021/02/03/è®ºæ–‡é˜…è¯»-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/)åœ¨å¤šå—GPUä¸Šå¹¶è¡Œè®¡ç®—çš„æ–¹å¼ã€‚

æ­¤å¤–ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåªæœ‰å½“blockçš„æ·±åº¦å¤§äºç­‰äº3æ—¶ï¼Œè¿™ç§è½¬åŒ–æ‰æ˜¯æœ‰æ„ä¹‰çš„ã€‚Fig4æ˜¯blockæ·±åº¦ä¸º2çš„ä¾‹å­ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/5.png)

## 3.4.Model Capacity

åœ¨åŒç­‰çš„æ¨¡å‹å®¹é‡ï¼ˆç›¸åŒçš„æ¨¡å‹å¤æ‚åº¦å’Œå‚æ•°æ•°é‡ï¼‰ä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æœ‰ç€æ›´é«˜çš„å‡†ç¡®æ€§ã€‚

ä¸ºäº†ä¿è¯æ¨¡å‹å¤æ‚åº¦ä¸å˜ï¼ŒåŸºæ•°å’Œç½‘ç»œå®½åº¦çš„å¯¹åº”å˜åŒ–å¯è§è¡¨2ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/6.png)

åœ¨Fig1å·¦çš„blockä¸­ï¼Œå‚æ•°é‡çº¦ä¸º$256 \cdot 64 + 3 \cdot 3 \cdot 64 \cdot 64 + 64 \cdot 256 \approx 70k$ã€‚åœ¨Fig1å³çš„blockä¸­ï¼Œå‚æ•°é‡ä¸ºï¼š

$$C \cdot ( 256 \cdot d + 3 \cdot 3 \cdot d \cdot d + d\cdot 256 ) \tag{4}$$

å½“$C=32,d=4$æ—¶ï¼Œå¼(4)çš„ç»“æœçº¦ä¸º70kã€‚

# 4.Implementation details

ResNeXtçš„å®ç°éµå¾ª[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)å’Œ[`fb.resnet.torch`](https://github.com/facebookarchive/fb.resnet.torch)ã€‚æˆ‘ä»¬çš„æ¨¡å‹é€šè¿‡Fig3(c)çš„å½¢å¼æ¥å®ç°ã€‚åœ¨å·ç§¯ä¹‹åä½¿ç”¨äº†[BN](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ï¼ˆå¦‚æœæ˜¯æŒ‰Fig3(a)çš„å½¢å¼å®ç°ï¼Œ[BN](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)åº”è¯¥æ”¾åœ¨èšåˆè½¬åŒ–ä¹‹åï¼Œæ·»åŠ åˆ°shortcutä¹‹å‰ï¼‰ã€‚[BN](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ä¹‹åæ˜¯ReLUæ¿€æ´»å‡½æ•°ã€‚Fig3çš„ä¸‰ç§ç­‰æ•ˆæ¨¡å¼å¯ä»¥å¾—åˆ°å®Œå…¨ä¸€æ ·çš„ç»“æœï¼Œä½†Fig3(c)çš„å®ç°æ›´ä¸ºç®€æ´å’Œé«˜æ•ˆã€‚

# 5.Experiments

## 5.1.Experiments on ImageNet1K

æˆ‘ä»¬åœ¨1000ä¸ªç±»åˆ«çš„ImageNetåˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡Œäº†æ¶ˆèå®éªŒã€‚æˆ‘ä»¬éµå¾ª[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)æ„å»ºäº†50å±‚å’Œ101å±‚çš„æ®‹å·®ç½‘ç»œï¼Œå¹¶æŠŠå…¶ä¸­çš„blockæ›¿æ¢æˆäº†æˆ‘ä»¬æå‡ºçš„blockã€‚

ğŸ‘‰**Cardinality vs. Width.**

å¦‚è¡¨2æ‰€ç¤ºï¼Œåœ¨ä¿è¯ç›¸åŒå¤æ‚åº¦çš„æƒ…å†µä¸‹ï¼Œå¯¹åŸºæ•°$C$å’Œbottleneck width $d$è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè§è¡¨3å’ŒFig5ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/7.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/8.png)

ä»è¡¨3ä¸­å¯ä»¥çœ‹å‡ºï¼Œéšç€$d$çš„å‡å°ï¼Œæ¨¡å‹æ€§èƒ½åœ¨ä¸æ–­ä¸Šå‡ã€‚ä½†æˆ‘ä»¬è®¤ä¸º$d$æœ€å°ä¸º4å°±å¯ä»¥äº†ï¼Œå†å°å°±æ²¡æ„ä¹‰äº†ã€‚

ğŸ‘‰**Increasing Cardinality vs. Deeper/Wider.**

1. **Going deeperï¼š**ä½¿ç”¨ResNet-200ã€‚
2. **Going widerï¼š**å¢åŠ bottleneck widthã€‚
3. **Increasing cardinalityï¼š**æŠŠ$C$ç¿»å€ã€‚

ä¸Šè¿°ç­–ç•¥éƒ½ä¼šæŠŠåŸå§‹æ¨¡å‹çš„FLOPsç¿»å€ã€‚æ¯”è¾ƒç»“æœè§è¡¨4ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/9.png)

ğŸ‘‰**Residual connections.**

æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥çš„æµ‹è¯•è§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/10.png)

ğŸ‘‰**Performance.**

æˆ‘ä»¬ç›´æ¥ä½¿ç”¨äº†Torchå†…ç½®çš„åˆ†ç»„å·ç§¯å®ç°ï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•çš„ä¼˜åŒ–ã€‚ä½†å…¶å®ç°å¯¹å¹¶è¡ŒåŒ–éå¸¸ä¸å‹å¥½ã€‚åœ¨8å—M40 NVIDIA GPUä¸Šï¼Œè¡¨3ä¸­çš„$32 \times 4d$ ResNeXt-101å¤„ç†ä¸€ä¸ªpatchéœ€è¦0.95ç§’ï¼ˆbatch size=256ï¼Œè¾“å…¥å›¾åƒå¤§å°ä¸º$224 \times 224$ï¼‰ï¼Œè€ŒåŒç­‰FLOPsçš„ResNet-101 baselineå¤„ç†ä¸€ä¸ªbatchä»…éœ€è¦0.7ç§’ã€‚

ğŸ‘‰**Comparisons with state-of-the-art results.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/11.png)

æˆ‘ä»¬æ³¨æ„åˆ°å¾ˆå¤šæ¨¡å‹ï¼ˆåŒ…æ‹¬æˆ‘ä»¬çš„æ¨¡å‹ï¼‰åœ¨ä½¿ç”¨äº†multi-scaleæˆ–multi-crop testingåï¼Œåœ¨è¯¥æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¶‹äºé¥±å’Œã€‚

## 5.2.Experiments on ImageNet5K

é‰´äºåœ¨ImageNet-1Kä¸Šçš„æ€§èƒ½å·²ç»é¥±å’Œäº†ï¼ˆé¥±å’Œçš„åŸå› ä¸æ˜¯æ¨¡å‹æœ¬èº«ï¼Œè€Œæ˜¯æ•°æ®é›†çš„å¤æ‚æ€§ï¼‰ï¼Œå› æ­¤åœ¨æ›´å¤§çš„ImageNet-5Kæ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚

æˆ‘ä»¬æ‰€ç”¨çš„5Kæ•°æ®é›†æ˜¯ImageNet-22Kçš„ä¸€ä¸ªå­é›†ã€‚è¿™5000ä¸ªç±»åˆ«åŒ…å«ImageNet-1Kä¸­çš„1000ä¸ªç±»åˆ«ã€‚è¿™ä¸ª5Kæ•°æ®é›†å…±æœ‰680ä¸‡å¼ å›¾åƒï¼Œçº¦ä¸º1Kæ•°æ®é›†çš„5å€ã€‚å› ä¸ºæ²¡æœ‰å®˜æ–¹çš„è®­ç»ƒé›†/éªŒè¯é›†åˆ’åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨ImageNet-1Kçš„éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚åŸºäº5Kæ•°æ®é›†çš„æ¨¡å‹éƒ½æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒçš„ã€‚æµ‹è¯•ç»“æœè§è¡¨6å’ŒFig6ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/12.png)

5K-way classificationå°±æ˜¯é¢„æµ‹æ‰€æœ‰çš„5Kä¸ªç±»åˆ«ï¼Œä½†å…¶ä½™4Kä¸ªç±»åˆ«éƒ½è§†ä¸ºé¢„æµ‹é”™è¯¯ã€‚1K-way classificationå°±æ˜¯åªé¢„æµ‹è¿™1Kä¸ªç±»åˆ«ã€‚

## 5.3.Experiments on CIFAR

æˆ‘ä»¬åœ¨CIFAR-10å’ŒCIFAR-100ä¸Šä¹Ÿè¿›è¡Œäº†æµ‹è¯•ã€‚æˆ‘ä»¬ä½¿ç”¨[è¿™é‡Œçš„](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/#42cifar-10-and-analysis)æ¡†æ¶å¹¶æŠŠblockæ›¿æ¢æˆæˆ‘ä»¬çš„blockï¼š

$$\begin{bmatrix} 1 \times 1,64 \\ 3 \times 3,64 \\ 1 \times 1, 256 \end{bmatrix}$$

æˆ‘ä»¬çš„ç½‘ç»œå¼€å¤´æ˜¯ä¸€ä¸ª$3\times 3$å·ç§¯å±‚ï¼Œç„¶åæ˜¯3ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µæœ‰3ä¸ªæ®‹å·®å—ï¼Œæœ€åæ˜¯ä¸€ä¸ªå¹³å‡æ± åŒ–å’Œä¸€ä¸ªå…¨è¿æ¥åˆ†ç±»å™¨ï¼ˆä¸€å…±æœ‰29å±‚ï¼‰ã€‚ä½¿ç”¨äº†å’Œ[è¿™é‡Œ](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/#42cifar-10-and-analysis)ä¸€æ ·çš„å¹³ç§»å’Œç¿»è½¬çš„æ•°æ®æ‰©å±•æ–¹å¼ã€‚æ›´å¤šå®ç°ç»†èŠ‚è§é™„ä»¶ã€‚

åŸºäºä¸Šè¿°baselineæ¨¡å‹ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†ä¸¤ç§å¢åŠ å¤æ‚åº¦çš„æƒ…å†µï¼š(i)å¢åŠ åŸºæ•°ï¼Œå›ºå®šwidthä¸å˜ï¼›(ii)å¢åŠ bottleneckçš„widthï¼Œå›ºå®šåŸºæ•°ä¸º1ã€‚ç»“æœè§Fig7ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/13.png)

ä»Fig7å¯ä»¥çœ‹å‡ºï¼Œå¢åŠ åŸºæ•°æ¯”å¢åŠ widthæ›´æœ‰æ•ˆã€‚å’ŒWide ResNetçš„æ¯”è¾ƒè§è¡¨7ï¼Œæˆ‘ä»¬è¾ƒå¤§çš„æ¨¡å‹å–å¾—äº†SOTAçš„ç»“æœã€‚

>Wide ResNetï¼šS. Zagoruyko and N. Komodakis. Wide residual networks. In BMVC, 2016.ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/14.png)

## 5.4.Experiments on COCO object detection

æˆ‘ä»¬åœ¨80kè®­ç»ƒé›†+35kéªŒè¯å­é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œåœ¨5kçš„minivalä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬é‡‡ç”¨åŸºç¡€çš„[Faster R-CNN](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ï¼Œå¹¶æŒ‰ç…§[è¿™é‡Œ](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/#43object-detection-on-pascal-and-ms-coco)çš„åšæ³•æŠŠResNetæˆ–ResNeXtåµŒå…¥è¿›å»ã€‚æ¨¡å‹åœ¨ImageNet-1Kä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œå¹¶åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè¿›è¡Œäº†fine-tuneã€‚æ›´å¤šå®ç°ç»†èŠ‚è§é™„å½•ã€‚

ç»“æœè§è¡¨8ã€‚åœ¨åŒç­‰æ¨¡å‹å¤æ‚åº¦çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ•ˆæœæ›´å¥½ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/ResNeXt/15.png)

æ­¤å¤–ï¼Œ[Mask R-CNN](http://shichaoxin.com/2023/12/25/è®ºæ–‡é˜…è¯»-Mask-R-CNN/)ä¹Ÿé‡‡ç”¨äº†ResNeXtï¼Œå¹¶åœ¨COCOå®ä¾‹åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†SOTAçš„ç»“æœã€‚

# 6.Appendix

## 6.A.Implementation Details: CIFAR

åœ¨50kè®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåœ¨10kæµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡zero-paddingå°†åŸå§‹å›¾åƒæ‰©å……åˆ°$40 \times 40$å¤§å°ï¼Œç„¶åå†éšæœºè£å‰ªå‡º$32 \times 32$å¤§å°çš„å›¾åƒæˆ–è€…å…¶ç¿»è½¬å›¾åƒä½œä¸ºè¾“å…¥ã€‚æ²¡æœ‰ä½¿ç”¨å…¶ä»–çš„æ•°æ®æ‰©å±•æ–¹å¼ã€‚ç¬¬ä¸€ä¸ª$3 \times 3$å·ç§¯å±‚æœ‰64ä¸ªå·ç§¯æ ¸ã€‚ä¸€å…±æœ‰3ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰3ä¸ªæ®‹å·®å—ï¼Œ3ä¸ªé˜¶æ®µè¾“å‡ºçš„feature mapå¤§å°åˆ†åˆ«ä¸º32ã€16å’Œ8ã€‚ç½‘ç»œç»“æŸæ˜¯ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–å±‚å’Œä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚å½“é˜¶æ®µå˜åŒ–æ—¶ï¼ˆå³ä¸‹é‡‡æ ·æ—¶ï¼‰ï¼Œwidthå¢åŠ 2å€ã€‚è®­ç»ƒåœ¨8å—GPUä¸Šè¿›è¡Œï¼Œbatch size=128ï¼Œweight decay=0.0005ï¼Œmomentum=0.9ã€‚åˆå§‹å­¦ä¹ ç‡ä¸º0.1ï¼Œè®­ç»ƒäº†300ä¸ªepochï¼Œåœ¨ç¬¬150å’Œç¬¬225ä¸ªepochæ—¶é™ä½å­¦ä¹ ç‡ã€‚

## 6.B.Implementation Details: Object Detection

æˆ‘ä»¬ä½¿ç”¨[Faster R-CNN](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ã€‚ä¸ºäº†ç®€åŒ–ï¼ŒRPNå’ŒFast R-CNNä¹‹é—´ä¸å…±äº«ç‰¹å¾ï¼ˆå‚è§ï¼š[Sharing Features for RPN and Fast R-CNN](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/#32sharing-features-for-rpn-and-fast-r-cnn)ï¼‰ã€‚åœ¨RPNè®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨äº†8å—GPUï¼Œæ¯ä¸ªGPUçš„batchå†…æœ‰2å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒæœ‰256ä¸ªanchorã€‚RPNçš„è®­ç»ƒï¼Œå‰120kä¸ªmini-batchçš„å­¦ä¹ ç‡ä¸º0.02ï¼Œå60kä¸ªmini-batchçš„å­¦ä¹ ç‡ä¸º0.002ã€‚åœ¨Fast R-CNNè®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬åŒæ ·ä¹Ÿä½¿ç”¨äº†8å—GPUï¼Œæ¯ä¸ªGPUå†…ä¸€ä¸ªmini-batchæœ‰1å¼ å›¾åƒå’Œ64ä¸ªregionã€‚Fast R-CNNçš„è®­ç»ƒï¼Œå‰120kä¸ªmini-batchçš„å­¦ä¹ ç‡ä¸º0.005ï¼Œå60kä¸ªmini-batchçš„å­¦ä¹ ç‡ä¸º0.0005ï¼Œweight decay=0.0001ï¼Œmomentum=0.9ã€‚

# 7.åŸæ–‡é“¾æ¥

ğŸ‘½[Aggregated Residual Transformations for Deep Neural Networks](https://github.com/x-jeff/AI_Papers/blob/master/Aggregated%20Residual%20Transformations%20for%20Deep%20Neural%20Networks.pdf)