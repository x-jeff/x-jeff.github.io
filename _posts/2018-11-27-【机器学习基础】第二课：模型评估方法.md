---
layout:     post
title:      【机器学习基础】第二课：模型评估方法
subtitle:   误差，过拟合，留出法，交叉验证法，自助法
date:       2018-11-27
author:     x-jeff
header-img: blogimg/20181127.jpg
catalog: true
tags:
    - Machine Learning
    - Element Knowledge
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.经验误差与过拟合

* **误差**：把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”。
* **训练误差（经验误差）**：学习器在训练集上的误差。
* **泛化误差**：在新样本上的误差。

>过拟合（又称过配）  
>欠拟合（又称欠配）

**过拟合是无法彻底避免的。**我们所能做的只是“缓解”，或者说减小其风险。如果可以避免，我们只要追求经验误差最小化即可，这显然是不可能的。

❗️**针对“模型选择”问题，理想的解决方案当然是对候选模型的泛化误差进行评估**（但是在现实任务中，往往还会考虑时间开销、存储开销、可解释性等方面的因素，这里暂且只考虑泛化误差）。

# 2.模型评估方法

⚠️**通常以测试集的“测试误差”作为泛化误差的近似。**

测试集应尽可能与训练集互斥，即测试样本尽量不在训练集中出现，未在训练过程中使用过。

## 2.1.留出法

**“留出法”**：直接将数据集*D*划分为两个互斥的集合，其中一个集合作为训练集*S*，另一个作为测试集*T*。

训练/测试集的划分要尽可能保持数据分布的一致性。

一般采用若干次随机划分，重复进行实验评估后取平均值作为留出法的评估结果。

* 测试集小时，评估结果的**方差**较大
* 训练集小时，评估结果的**偏差**较大

常见做法是将大约$\frac{2}{3}\sim\frac{4}{5}$的样本用于训练，剩余样本用于测试（一般而言，测试集至少应含30个样例）。

## 2.2.交叉验证法
10折交叉验证示意图：
![10折交叉验证](https://ws2.sinaimg.cn/large/006tNbRwly1fxo3u4s7ctj30ru0dc0w3.jpg)

“k折交叉验证”：返回平均结果。进一步，p次k折交叉验证，如10次10折交叉验证。

假定数据集*D*中包含*m*个样本，若令$k=m$，则得到了交叉验证法的一个特例：**留一法（Leave-One-Out，简称LOO）**。

* 优点：留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用*D*训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。
* 缺点：
	1. 在训练集比较大时，训练*m*个模型的计算开销可能是难以忍受的。
	2. 留一法的评估结果也未必永远比其他评估方法准确。

## 2.3.自助法
为什么要引入“自助法”？

原因有以下两点：

1. 在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比*D*小，这必然会引入一些因训练样本规模不同而导致的估计偏差。
2. 留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。

那什么是“自助法”呢？

“自助法”是以自助采样（又称可重复采样、有放回采样）为基础。

给定包含*m*个样本的数据集*D*，对它进行采样产生新数据集$D'$，每次随机从*D*中挑选一个样本，将其“拷贝”至$D'$，然后将该样本放回*D*，此过程重复*m*次，最终得到包含*m*个样本的数据集$D'$。

⚠️自助法有两个要点：1⃣️有放回抽样；2⃣️样本量$D=D'$

很显然，*D*中一部分样本会在$D'$中多次出现，而另一部分样本不出现。

样本在*m*次采样中始终不被采到的概率是$(1-\frac{1}{m})^m$，取极限得：

$$\lim_{m\to\infty}(1-\frac{1}{m})^m=[\lim_{m\to\infty}(1+\frac{1}{-m})^{-m}]^{-1}=\frac{1}{e}\approx0.368$$

>关于公式的推导，这里补充一些相关的数学知识：