---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘YOLOv3ï¼šAn Incremental Improvement
subtitle:   YOLOv3ï¼ŒDarknet-53
date:       2022-06-29
author:     x-jeff
header-img: blogimg/20220629.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŽŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜Žå‡ºå¤„ã€‚

# 1.Introduction

æˆ‘ä»¬é’ˆå¯¹YOLOæ¡†æž¶ï¼ˆ[YOLOv1](http://shichaoxin.com/2022/05/11/è®ºæ–‡é˜…è¯»-You-Only-Look-Once-Unified,-Real-Time-Object-Detection/)ï¼Œ[YOLOv2ã€YOLO9000](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)ï¼‰åªæ˜¯åšäº†ä¸€äº›å°çš„æ”¹åŠ¨å’Œä¼˜åŒ–ï¼Œå½¢æˆäº†YOLOv3ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/1.png)

# 2.The Deal

## 2.1.Bounding Box Prediction

åœ¨[YOLO9000](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨èšç±»çš„æ–¹æ³•äº§ç”Ÿanchor boxã€‚æ¯ä¸ªbounding boxé¢„æµ‹å‡º4ä¸ªåæ ‡ï¼š$t_x,t_y,t_w,t_h$ã€‚å‡è®¾cellçš„å·¦ä¸Šè§’ç›¸å¯¹äºŽæ•´å¹…å›¾åƒçš„å·¦ä¸Šè§’çš„offsetä¸º$(c_x,c_y)$ï¼Œanchor boxçš„å®½å’Œé«˜ä¸º$p_w,p_h$ï¼Œé‚£ä¹ˆé¢„æµ‹ç»“æžœä¸ºï¼š

$$b_x = \sigma (t_x) + c_x$$

$$b_y = \sigma (t_y) + c_y$$

$$b_w = p_w e^{t_w}$$

$$b_h = p_h e^{t_h}$$

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/2.png)

è®­ç»ƒä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆsum of squared error lossï¼‰ã€‚

YOLOv3ä½¿ç”¨é€»è¾‘å›žå½’ä¸ºæ¯ä¸ªbounding boxéƒ½é¢„æµ‹ä¸€ä¸ªobjectness scoreã€‚ä¸åƒ[Faster R-CNN](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ï¼Œå¯¹äºŽæ¯ä¸ªground truth objectï¼Œæˆ‘ä»¬åªåˆ†é…ä¸€ä¸ªbounding box priorã€‚æ²¡æœ‰è¢«åˆ†é…åˆ°ground truth objectçš„bounding box priorä¸ä¼šå‚ä¸Žcoordinateå’Œclassçš„lossè®¡ç®—ï¼Œåªä¿ç•™objectnesséƒ¨åˆ†ï¼ˆçš„lossï¼‰ã€‚

## 2.2.Class Prediction

bounding boxçš„ç±»åˆ«æ ‡ç­¾å¯èƒ½æœ‰å¤šä¸ªï¼ˆæ¯”å¦‚æŸä¸€objectæ—¢å±žäºŽwomanï¼Œä¹Ÿå±žäºŽpersonï¼‰ï¼Œå¯¹äºŽè¿™ç§multilabel classificationä»»åŠ¡ï¼Œsoftmaxå‡½æ•°å°±ä¸æ˜¯å¾ˆåˆé€‚ã€‚å› æ­¤æˆ‘ä»¬ä½¿ç”¨å¤šä¸ªç‹¬ç«‹çš„é€»è¾‘å›žå½’äºŒåˆ†ç±»å™¨ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œå¯¹äºŽç±»åˆ«çš„é¢„æµ‹ï¼Œä½¿ç”¨binary cross-entropy lossã€‚

è¿™ä¸€ç­–ç•¥ä¹Ÿä½¿å¾—æˆ‘ä»¬å¯ä»¥å°†ç®—æ³•ç§»æ¤åˆ°æ›´å¤æ‚çš„Open Images Datasetã€‚

## 2.3.Predictions Across Scales

>å¯¹äºŽèšç±»äº§ç”Ÿanchorï¼Œåœ¨[YOLOv2](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)ä¸­ï¼Œæ˜¯ä¸æ˜¯ä¹Ÿæœ‰è¿™ç§å¯èƒ½ï¼šå¯¹äºŽæ•´å¹…å›¾åƒæ¥è¯´ï¼Œæ•´ä¸ªæ•°æ®é›†èšç±»å¾—åˆ°kç§anchor boxçš„å¤§å°ï¼Œå¦‚æžœæ˜¯é’ˆå¯¹æ¯ä¸ªgrid cellï¼Œå¥½åƒæ²¡è¿™ä¸ªå¿…è¦ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/3.png)

æˆ‘ä»¬ä½¿ç”¨äº†3ç§ä¸åŒscaleçš„feature mapæ¥é¢„æµ‹boxï¼ˆè§ä¸Šå›¾ï¼‰ã€‚å¯¹äºŽæ¯ç§scaleçš„feature mapï¼Œæ¯ä¸ªgrid celléƒ½è´Ÿè´£é¢„æµ‹3ä¸ªboxï¼Œæ‰€ä»¥è¾“å‡ºçš„tensorç»´åº¦ä¸ºï¼š$N \times N \times [ 3 * (4+1+80) ]$ï¼Œ4ä¸ºbounding boxçš„offsetï¼Œ1ä¸ºobjectness predictionï¼Œ80ä¸ºCOCOæ•°æ®é›†çš„ç±»åˆ«æ•°ã€‚

æˆ‘ä»¬ä¾ç„¶ä½¿ç”¨[k-means](http://shichaoxin.com/2022/03/21/æœºå™¨å­¦ä¹ åŸºç¡€-ç¬¬ä¸‰åäº”è¯¾-èšç±»ä¹‹åŽŸåž‹èšç±»/#2kå‡å€¼ç®—æ³•)ç”Ÿæˆanchor boxã€‚å¯¹äºŽCOCOæ•°æ®é›†ï¼Œä¸€å…±ä½¿ç”¨äº†9ç§anchor boxï¼š$(10\times 13),(16 \times 30),(33\times 23),(30\times 61),(62\times 45),(59 \times 119),(116 \times 90),(156\times 198),(373\times 326)$ã€‚è¿™9ç§anchor boxæˆ‘ä»¬éšæœºå‡åŒ€åˆ†é…ç»™3ä¸ªscaleçš„feature mapï¼Œå³æ¯ä¸ªscaleçš„feature mapåˆ†åˆ°3ç§anchor boxã€‚

## 2.4.Feature Extractor

æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ–°çš„ç½‘ç»œç”¨äºŽç‰¹å¾æå–ï¼Œè¿™ä¸ªæ–°çš„ç½‘ç»œåŸºäºŽ[YOLOv2](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)ä¸­çš„Darknet-19ï¼Œæˆ‘ä»¬æ·»åŠ äº†[æ®‹å·®è¿žæŽ¥](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªç½‘ç»œç§°ä¹‹ä¸ºDarknet-53ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/4.png)

Darknet-53æ¯”Darknet-19æ€§èƒ½æ›´å¥½ï¼Œæ¯”[ResNet-101ã€ResNet-152](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)æ•ˆçŽ‡æ›´é«˜ï¼Œå…¶åœ¨ImageNetä¸Šçš„æµ‹è¯•ç»“æžœè§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/5.png)

æ¯ä¸ªç½‘ç»œçš„å‚æ•°é…ç½®éƒ½ä¸€æ ·ï¼Œå›¾åƒå¤§å°å‡ä¸º$256 \times 256$ï¼Œç»Ÿè®¡single cropå‡†ç¡®çŽ‡ã€‚run timeåœ¨Titan Xä¸Šè¿›è¡Œæµ‹è¯•ã€‚Darknet-53å’ŒSOTAåˆ†ç±»å™¨çš„æ€§èƒ½ç›¸å½“ï¼Œä½†æ˜¯è®¡ç®—æˆæœ¬æ›´ä½Žï¼Œé€Ÿåº¦æ›´å¿«ã€‚Darknet-53æ€§èƒ½æ¯”[ResNet-101](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)è¦é«˜ï¼Œå¹¶ä¸”é€Ÿåº¦æ˜¯[ResNet-101](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)çš„1.5å€å¿«ã€‚Darknet-53å’Œ[ResNet-152](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)çš„æ€§èƒ½ç›¸è¿‘ï¼Œä½†æ˜¯é€Ÿåº¦å´æ˜¯[ResNet-152](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)çš„2å€å¿«ã€‚

Darknet-53æ¯ç§’æ‰§è¡Œçš„æµ®ç‚¹æ•°è®¡ç®—ï¼ˆfloating point operationsï¼‰æ˜¯æœ€å¤šçš„ï¼Œè¯´æ˜ŽDarknet-53å¯¹GPUçš„åˆ©ç”¨æ›´ä¸ºå……åˆ†ã€‚[ResNet](http://shichaoxin.com/2022/01/07/è®ºæ–‡é˜…è¯»-Deep-Residual-Learning-for-Image-Recognition/)å› ä¸ºå±‚æ•°å¤ªå¤šï¼Œæ‰€ä»¥æ•ˆçŽ‡ä¸é«˜ã€‚

## 2.5.Training

æˆ‘ä»¬åœ¨full imageä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ²¡æœ‰ä½¿ç”¨[hard negative mining](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/#23è®­ç»ƒtraining)ã€‚ä½¿ç”¨multi-scale trainingå’Œå¤šç§æ•°æ®æ‰©å±•æ–¹å¼ã€[BatchNorm](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ç­‰ä¸€äº›æ ‡å‡†æ“ä½œã€‚

# 3.How We Do

YOLOv3çš„ç»“æžœç›¸å½“å¥½ï¼Œè§è¡¨3ã€‚ä½¿ç”¨äº†COCOä¸­å„ç§å¥‡æ€ªçš„APæŒ‡æ ‡ä½œä¸ºè¯„ä»·æ ‡å‡†ï¼ŒYOLOv3å’ŒSSDå˜ä½“çš„æ€§èƒ½ç›¸è¿‘ï¼Œä½†é€Ÿåº¦å¿«äº†3å€ã€‚ä½†YOLOv3çš„æ€§èƒ½è¿œè½åŽäºŽRetinaNetã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/6.png)

ä½†æ˜¯å¦‚æžœæˆ‘ä»¬çœ‹ä¸€äº›è€çš„å¸¸ç”¨çš„APæŒ‡æ ‡ï¼Œä¾‹å¦‚$AP_{50}$ï¼ˆå³IoUé˜ˆå€¼ä¸º0.5æ—¶çš„mAPï¼‰ï¼ŒYOLOv3çš„æ€§èƒ½è¿˜æ˜¯éžå¸¸ä¸é”™çš„ï¼Œå…¶å’ŒRetinaNetæ€§èƒ½ç›¸å½“ï¼Œä¸”è¿œä¼˜äºŽSSDå˜ä½“ã€‚ä½†æ˜¯å½“IoUçš„é˜ˆå€¼å˜å¤§æ—¶ï¼Œä¾‹å¦‚$AP_{75}$ï¼ŒYOLOv3çš„æ€§èƒ½ä¼šå‡ºçŽ°å¤§å¹…çš„ä¸‹æ»‘ã€‚

ä¹‹å‰çš„YOLOç‰ˆæœ¬å¯¹å°ç›®æ ‡çš„æ£€æµ‹å¹¶ä¸å¥½ï¼Œä½†æ˜¯YOLOv3å¯¹è¿™ä¸€ç¼ºç‚¹è¿›è¡Œäº†æ”¹è¿›ã€‚$AP_S,AP_M,AP_L$åˆ†åˆ«ä»£è¡¨å¯¹å°åž‹ç›®æ ‡ã€ä¸­åž‹ç›®æ ‡ã€å¤§åž‹ç›®æ ‡çš„æ£€æµ‹ç»“æžœã€‚ä»Žè¡¨3ä¸­å¯ä»¥çœ‹åˆ°ï¼ŒYOLOv3åœ¨å°ç›®æ ‡æ£€æµ‹ä¸Šçš„ç»“æžœè¿˜ç®—å¯ä»¥ï¼Œä½†æ˜¯å…¶æ£€æµ‹ç²¾åº¦ä¾ç„¶è¿œä½ŽäºŽå¯¹ä¸­åž‹ç›®æ ‡å’Œå¤§åž‹ç›®æ ‡çš„æ£€æµ‹ç²¾åº¦ã€‚

# 4.Things We Tried That Didnâ€™t Work

æˆ‘ä»¬åˆ—å‡ºäº†å°è¯•è¿‡å´æ²¡æœ‰èµ·ä½œç”¨çš„æ–¹æ³•ã€‚

**Anchor box x,y offset predictions.**

ä½¿ç”¨$x,y$çš„offsetï¼ˆä¸ªäººç†è§£å°±æ˜¯$t_x,t_y$ï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªçº¿æ€§å‡½æ•°æ¥é¢„æµ‹bounding boxçš„å®½å’Œé«˜ï¼ˆæœ€ç»ˆä½¿ç”¨çš„ä¸æ˜¯çº¿æ€§å‡½æ•°ï¼Œè€Œæ˜¯ä¸€ä¸ªæŒ‡æ•°å‡½æ•°ï¼‰ã€‚æˆ‘ä»¬å‘çŽ°ä½¿ç”¨çº¿æ€§å‡½æ•°é¢„æµ‹bounding boxçš„å®½å’Œé«˜ä¼šé™ä½Žæ¨¡åž‹çš„ç¨³å®šæ€§ï¼Œæ•ˆæžœå¹¶ä¸å¥½ã€‚

**Linear x,y predictions instead of logistic.**

åœ¨[YOLOv2](http://shichaoxin.com/2022/06/01/è®ºæ–‡é˜…è¯»-YOLO9000-Better,-Faster,-Stronger/)ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é€»è¾‘å›žå½’æ¥é¢„æµ‹$t_x,t_y,t_w,t_h$ï¼Œä»¥é™åˆ¶å…¶èŒƒå›´åœ¨0~1ä¹‹é—´ã€‚æˆ‘ä»¬å°è¯•æ¢æˆæ™®é€šçš„çº¿æ€§æ¨¡åž‹ï¼Œç»“æžœå¯¼è‡´mAPå¤§å¹…ä¸‹é™ã€‚

**Focal loss.**

æˆ‘ä»¬å°è¯•ä½¿ç”¨focal lossï¼Œå¯¼è‡´mAPä¸‹é™äº†2ä¸ªç™¾åˆ†ç‚¹ã€‚

**Dual IOU thresholds and truth assignment.**

[Faster R-CNN](http://shichaoxin.com/2022/04/03/è®ºæ–‡é˜…è¯»-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªIoUé˜ˆå€¼ï¼šIoU>0.7ä¸ºæ­£æ ·æœ¬ï¼ŒIoUåœ¨[0.3,0.7]ä¹‹é—´ä¼šè¢«å¿½ç•¥ï¼ŒIoU<0.3ä¸ºè´Ÿæ ·æœ¬ã€‚æˆ‘ä»¬ä¹Ÿå°è¯•äº†ç›¸ä¼¼çš„ç­–ç•¥ï¼Œä½†ç»“æžœå¹¶ä¸å¥½ã€‚

# 5.What This All Means

YOLOv3é€Ÿåº¦å¿«ï¼Œç²¾åº¦é«˜ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/7.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/YOLOv3/8.png)

# 6.åŽŸæ–‡é“¾æŽ¥

ðŸ‘½[YOLOv3ï¼šAn Incremental Improvement](https://github.com/x-jeff/AI_Papers/blob/master/YOLOv3ï¼šAn%20Incremental%20Improvement.pdf)

# 7.å‚è€ƒèµ„æ–™

1. [ã€è®ºæ–‡è§£è¯»ã€‘Yoloä¸‰éƒ¨æ›²è§£è¯»â€”â€”Yolov3](https://zhuanlan.zhihu.com/p/76802514)