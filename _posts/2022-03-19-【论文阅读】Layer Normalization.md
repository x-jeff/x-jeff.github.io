---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘Layer Normalization
subtitle:   Layer Normalization
date:       2022-03-19
author:     x-jeff
header-img: blogimg/20220319.jpg
catalog: true
tags:
    - Natural Language Processing
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Abstract

>æœ¬åšæ–‡åªä»‹ç»åŸæ–‡çš„æ‘˜è¦å’Œç¬¬3éƒ¨åˆ†ï¼ŒåŸæ–‡é“¾æ¥åœ¨æœ¬æ–‡æœ«å°¾ã€‚

è®­ç»ƒSOTAçš„æ·±åº¦ç¥ç»ç½‘ç»œçš„è®¡ç®—æˆæœ¬éƒ½éå¸¸é«˜ã€‚ä¸€ä¸ªå‡å°‘è®­ç»ƒæ—¶é—´çš„æ–¹æ³•æ˜¯normalizeç¥ç»å…ƒçš„æ¿€æ´»å€¼ï¼ˆactivitiesï¼‰ã€‚æ¯”å¦‚[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)å°±æ˜¾è‘—å‡å°‘äº†å‰é¦ˆç¥ç»ç½‘ç»œçš„è®­ç»ƒæ—¶é—´ã€‚ä½†æ˜¯[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)çš„æ•ˆæœå–å†³äºmini-batch sizeï¼Œå¹¶ä¸”å…¶éš¾ä»¥åº”ç”¨åœ¨[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)å½“ä¸­ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)è½¬æ¢ä¸ºLayer Normalizationï¼Œåªåˆ©ç”¨å•ä¸ªè®­ç»ƒæ ·æœ¬åœ¨ä¸€å±‚å†…çš„å‡å€¼å’Œæ–¹å·®ã€‚å’Œ[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ç±»ä¼¼ï¼Œæˆ‘ä»¬ä¹Ÿä½¿ç”¨äº†$\gamma$ï¼ˆæœ¬æ–‡æè¿°ä¸ºgainï¼‰å’Œ$\beta$ï¼ˆæœ¬æ–‡æè¿°ä¸ºbiasï¼‰ã€‚å’Œ[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ä¸åŒçš„æ˜¯ï¼ŒLayer Normalizationåœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶æ‰§è¡Œå®Œå…¨ç›¸åŒçš„è®¡ç®—ã€‚å¹¶ä¸”ï¼ŒLayer Normalizationå¯ä»¥ç›´æ¥åº”ç”¨äº[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼ˆtime stepï¼‰ã€‚æ­¤å¤–ï¼ŒLayer Normalizationå¯¹ç¨³å®š[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­çš„hidden stateéå¸¸æœ‰æ•ˆã€‚Layer Normalizationå¯ä»¥æ˜¾è‘—å‡å°‘è®­ç»ƒæ—¶é—´ã€‚

# 2.Layer normalization

æˆ‘ä»¬ç°åœ¨ä½¿ç”¨Layer Normalizationæ¥è§£å†³[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)å­˜åœ¨çš„é—®é¢˜ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸Šä¸€å±‚è¾“å‡ºçš„å˜åŒ–å’Œä¸‹ä¸€å±‚è¾“å…¥çš„å˜åŒ–æ€»æ˜¯é«˜åº¦ç›¸å…³çš„ï¼Œå°¤å…¶æ˜¯ReLUå‡½æ•°ã€‚è¿™è¡¨æ˜æˆ‘ä»¬å¯ä»¥é€šè¿‡å›ºå®šæ¯ä¸€å±‚å†…æ€»è¾“å…¥çš„å‡å€¼å’Œæ–¹å·®æ¥å‡å°‘â€œcovariate shiftâ€çš„é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¡ç®—åŒä¸€å±‚å†…æ‰€æœ‰éšè—ç¥ç»å…ƒçš„å½’ä¸€åŒ–ç»Ÿè®¡é‡å¦‚ä¸‹ï¼š

$$\mu ^l = \frac{1}{H} \sum^H_{i=1} a_i^l \quad \sigma^l=\sqrt{\frac{1}{H} \sum^H_{i=1} (a_i^l - \mu^l)^2} \tag{3} $$

$l$è¡¨ç¤ºç¬¬$l$ä¸ªéšè—å±‚ï¼Œ$H$ä¸ºç¬¬$l$ä¸ªéšè—å±‚å†…éšè—ç¥ç»å…ƒçš„æ•°é‡ï¼Œ$a_i^l$ä¸ºç¬¬$l$ä¸ªéšè—å±‚ä¸­ç¬¬$i$ä¸ªç¥ç»å…ƒçš„è¾“å…¥ï¼ˆè¿›æ¿€æ´»å‡½æ•°å‰ï¼‰ï¼š

$$a_i^l = w_i^{l^\top} h^l \quad h_i^{l+1} = f(a_i^l + b_i^l) \tag{1}$$

å…¶ä¸­ï¼Œ$f(\cdot)$ä¸ºæ¿€æ´»å‡½æ•°ï¼Œ$b_i^l$ä¸ºåç½®é¡¹ã€‚

ä¸€å±‚å†…çš„æ‰€æœ‰éšè—ç¥ç»å…ƒéƒ½å…±äº«ä¸€ç»„$\mu$å’Œ$\sigma$ï¼Œä½†æ˜¯ä¸åŒçš„è®­ç»ƒæ ·æœ¬æœ‰ç€ä¸ä¸€æ ·çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼ˆå³$\mu$å’Œ$\sigma$ï¼‰ã€‚å’Œ[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ä¸åŒï¼ŒLayer Normalizationä¸å—mini-batch sizeçš„çº¦æŸï¼Œä¸”å¯ä»¥åœ¨mini-batch size=1çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚

## 2.1.Layer normalized recurrent neural networks

åœ¨NLPä¸­ï¼Œæœ€è¿‘çš„[Seq2Seq](http://shichaoxin.com/2021/02/23/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åå…­è¯¾-Beam-Search/#1seq2seqæ¨¡å‹)å¤§å¤šé‡‡ç”¨[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)æ¥è§£å†³åºåˆ—é¢„æµ‹é—®é¢˜ã€‚åœ¨NLPä»»åŠ¡ä¸­ï¼Œå¯¹äºä¸åŒçš„è®­ç»ƒæ ·æœ¬ï¼Œå¥å­çš„é•¿åº¦ä¸åŒæ˜¯å¾ˆå¸¸è§çš„ï¼Œ[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)é€šè¿‡æ—¶é—´æ­¥å¯ä»¥å¾ˆå®¹æ˜“çš„å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœåœ¨[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­ä½¿ç”¨[Batch Normalization](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)çš„è¯ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥è®¡ç®—å¹¶å­˜å‚¨å•ç‹¬çš„ç»Ÿè®¡ä¿¡æ¯ã€‚æ­¤æ—¶å¦‚æœä¸€ä¸ªæµ‹è¯•åºåˆ—æ¯”ä»»ä½•ä¸€ä¸ªè®­ç»ƒåºåˆ—éƒ½é•¿ï¼Œå°±ä¼šå‡ºç°é—®é¢˜ã€‚ä½†æ˜¯Layer Normalizationå°±ä¸ä¼šå­˜åœ¨è¿™æ ·çš„é—®é¢˜ã€‚å¹¶ä¸”åœ¨Layer Normalizationä¸­ï¼Œæ‰€æœ‰æ—¶é—´æ­¥å…±ç”¨ä¸€ç»„gainå’Œbiasã€‚

åœ¨æ ‡å‡†çš„[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­ï¼Œå¾ªç¯å±‚çš„æ€»è¾“å…¥æ¥è‡ªå½“å‰è¾“å…¥$\mathbf{x}^t$å’Œä¸Šä¸€ä¸ªhidden state $\mathbf{h}^{t-1}$ã€‚æ€»è¾“å…¥$\mathbf{a}^t=W_{hh}\mathbf{h}^{t-1}+W_{xh}\mathbf{x}^t$ã€‚Layer Normalizationçš„è®¡ç®—è§ä¸‹ï¼š

$$\mathbf{h}^t=f\left[ \frac{\mathbf{g}}{\sigma^t} \odot (\mathbf{a}^t - \mu^t) + \mathbf{b} \right] \quad \mu^t = \frac{1}{H} \sum^H_{i=1} a_i^t \quad \sigma^t = \sqrt{\frac{1}{H} \sum^H_{i=1} (a_i^t - \mu^t)^2} \tag{4}$$

å…¶ä¸­ï¼Œ$\odot$ä¸ºä¸¤ä¸ªå‘é‡ä¹‹é—´element-wiseçš„ä¹˜æ³•ã€‚$\mathbf{g},\mathbf{b}$åˆ†åˆ«ä»£è¡¨gainå’Œbiasã€‚

Layer Normalizationçš„ä½¿ç”¨å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­çš„[æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸](http://shichaoxin.com/2020/02/07/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸‰è¯¾-æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸/)é—®é¢˜ã€‚

# 3.åŸæ–‡é“¾æ¥

ğŸ‘½[Layer Normalization](https://github.com/x-jeff/AI_Papers/blob/master/Layer%20Normalization.pdf)