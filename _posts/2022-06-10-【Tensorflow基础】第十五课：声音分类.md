---
layout:     post
title:      ã€TensorflowåŸºç¡€ã€‘ç¬¬åäº”è¯¾ï¼šå£°éŸ³åˆ†ç±»
subtitle:   librosaï¼Œenumerate()ï¼Œendswith()ï¼Œos.sepï¼Œos.sep.joinï¼Œos.path.joinï¼Œnp.transposeï¼Œtf.contrib.rnn.GRUCellï¼Œtf.contrib.rnn.DropoutWrapperï¼Œtf.contrib.rnn.MultiRNNCell
date:       2022-06-10
author:     x-jeff
header-img: blogimg/20220610.jpg
catalog: true
tags:
    - Tensorflow Series
---
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.å£°éŸ³åˆ†ç±»

ä½¿ç”¨æ•°æ®é›†ï¼š[URBANSOUND8K DATASET](https://urbansounddataset.weebly.com/urbansound8k.html)ã€‚å…±åŒ…å«8732æ¡è¯­éŸ³ï¼ˆæ¯æ¡è¯­éŸ³çš„é•¿åº¦å‡åœ¨4ç§’ä»¥å†…ï¼‰ï¼Œè¢«æ ‡è®°ä¸º10ä¸ªç±»åˆ«ï¼š

```
0 = air_conditioner
1 = car_horn
2 = children_playing
3 = dog_bark
4 = drilling
5 = engine_idling
6 = gun_shot
7 = jackhammer
8 = siren
9 = street_music
```

æˆ‘ä»¬åœ¨å®é™…æµ‹è¯•æ—¶åªç”¨åˆ°äº†ä¸Šè¿°æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬ä½¿ç”¨[librosa](https://github.com/librosa/librosa)ï¼ˆä¸€ä¸ªpythonåŒ…ï¼‰æ¥å¤„ç†å£°éŸ³ã€‚

ğŸ‘‰è½½å…¥åŒ…ï¼š

```python
import os
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import time
import librosa
from tqdm import tqdm 
import random
```

ğŸ‘‰å®šä¹‰å‚æ•°ï¼š

```python
# Parameters
# ==================================================

# Data loading params
# validationæ•°æ®é›†å æ¯”
tf.flags.DEFINE_float("dev_sample_percentage", .2, "Percentage of the training data to use for validation")
# çˆ¶ç›®å½•
tf.flags.DEFINE_string("parent_dir", "audio/", "Data source for the data.")
# å­ç›®å½•
tf.flags.DEFINE_list("tr_sub_dirs", ['fold1/', 'fold2/', 'fold3/'], "Data source for the data.")

# Model Hyperparameters
# ç¬¬ä¸€å±‚è¾“å…¥ï¼ŒMFCCä¿¡å·
tf.flags.DEFINE_integer("n_inputs", 40, "Number of MFCCs (default: 40)")
# cellä¸ªæ•°
tf.flags.DEFINE_integer("n_hidden", 300, "Number of cells (default: 300)")
# åˆ†ç±»æ•°
tf.flags.DEFINE_integer("n_classes", 10, "Number of classes (default: 10)")
# å­¦ä¹ ç‡
tf.flags.DEFINE_float("lr", 0.005, "Learning rate (default: 0.005)")
# dropoutå‚æ•°
tf.flags.DEFINE_float("dropout_keep_prob", 0.5, "Dropout keep probability (default: 0.5)")

# Training parameters
# æ‰¹æ¬¡å¤§å°
tf.flags.DEFINE_integer("batch_size", 50, "Batch Size (default: 50)")
# è¿­ä»£å‘¨æœŸ
tf.flags.DEFINE_integer("num_epochs", 100, "Number of training epochs (default: 100)")
# å¤šå°‘stepæµ‹è¯•ä¸€æ¬¡
tf.flags.DEFINE_integer("evaluate_every", 50, "Evaluate model on dev set after this many steps (default: 50)")
# å¤šå°‘stepä¿å­˜ä¸€æ¬¡æ¨¡å‹
tf.flags.DEFINE_integer("checkpoint_every", 500, "Save model after this many steps (default: 500)")
# æœ€å¤šä¿å­˜å¤šå°‘ä¸ªæ¨¡å‹
tf.flags.DEFINE_integer("num_checkpoints", 2, "Number of checkpoints to store (default: 2)")

# flagsè§£æ
FLAGS = tf.flags.FLAGS
FLAGS.flag_values_dict()

# æ‰“å°æ‰€æœ‰å‚æ•°
print("\nParameters:")
for attr, value in sorted(FLAGS.flag_values_dict().items()):
    print("{}={}".format(attr.upper(), value))
print("")
```

```
Parameters:
ALSOLOGTOSTDERR=False
BATCH_SIZE=50
CHECKPOINT_EVERY=500
DEV_SAMPLE_PERCENTAGE=0.2
DROPOUT_KEEP_PROB=0.5
EVALUATE_EVERY=50
LOG_DIR=
LOGTOSTDERR=False
LR=0.005
N_CLASSES=10
N_HIDDEN=300
N_INPUTS=40
NUM_CHECKPOINTS=2
NUM_EPOCHS=100
ONLY_CHECK_ARGS=False
OP_CONVERSION_FALLBACK_TO_WHILE_LOOP=False
PARENT_DIR=audio/
PDB_POST_MORTEM=False
PROFILE_FILE=None
RUN_WITH_PDB=False
RUN_WITH_PROFILING=False
SHOWPREFIXFORINFO=True
STDERRTHRESHOLD=fatal
TEST_RANDOM_SEED=301
TEST_RANDOMIZE_ORDERING_SEED=
TEST_SRCDIR=
TEST_TMPDIR=/var/folders/qg/0r2bywpn6s16dsr8j9xyjnm80000gn/T/absl_testing
TR_SUB_DIRS=['fold1/', 'fold2/', 'fold3/']
USE_CPROFILE_FOR_PROFILING=True
V=-1
VERBOSITY=-1
XML_OUTPUT_FILE=
```

`tf.flags`çš„è®²è§£è§[ã€TensorflowåŸºç¡€ã€‘ç¬¬åå››è¯¾ï¼šCNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨](http://shichaoxin.com/2022/05/02/TensorflowåŸºç¡€-ç¬¬åå››è¯¾-CNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨/)ã€‚

ğŸ‘‰è·å¾—è®­ç»ƒç”¨çš„wavæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼š

```python
def get_wav_files(parent_dir, sub_dirs):
    wav_files = []
    for l, sub_dir in enumerate(sub_dirs):
        wav_path = os.path.join(parent_dir, sub_dir)
        for (dirpath, dirnames, filenames) in os.walk(wav_path):
            for filename in filenames:
                if filename.endswith('.wav') or filename.endswith('.WAV'):
                    filename_path = os.sep.join([dirpath, filename])
                    wav_files.append(filename_path)
    return wav_files
```

`enumerate()`å‡½æ•°ç”¨äºå°†ä¸€ä¸ªå¯éå†çš„æ•°æ®å¯¹è±¡ï¼ˆå¦‚åˆ—è¡¨ã€å…ƒç»„æˆ–å­—ç¬¦ä¸²ï¼‰ç»„åˆä¸ºä¸€ä¸ªç´¢å¼•åºåˆ—ï¼ŒåŒæ—¶åˆ—å‡ºæ•°æ®å’Œæ•°æ®ä¸‹æ ‡ï¼Œä¸€èˆ¬ç”¨åœ¨forå¾ªç¯ä¸­ï¼š

```python
seasons=['Spring','Summer','Fall','Winter']
list(enumerate(seasons))
#output : [(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]
list(enumerate(seasons,start=1)) #ä¸‹æ ‡ä»1å¼€å§‹
#output : [(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]
seq=['one','two','three']
for i,element in enumerate(seq):
	print(i,element)
#output : 
#0 one
#1 two
#2 three
```

`endswith()`æ–¹æ³•ç”¨äºåˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šåç¼€ç»“å°¾ï¼Œå¦‚æœä»¥æŒ‡å®šåç¼€ç»“å°¾è¿”å›Trueï¼Œå¦åˆ™è¿”å›Falseã€‚å¯é€‰å‚æ•°â€œstartâ€ä¸â€œendâ€ä¸ºæ£€ç´¢å­—ç¬¦ä¸²çš„å¼€å§‹ä¸ç»“æŸä½ç½®ã€‚è¯­æ³•ä¸ºï¼š

```python
str.endswith(suffix,start,end)
```

* suffixä¸ºå¾…åŒ¹é…çš„åç¼€ã€‚
* startä¸ºåŒ¹é…æœç´¢çš„strå¼€å§‹ä½ç½®ï¼Œé»˜è®¤ä¸º0ã€‚
* endä¸ºåŒ¹é…æœç´¢çš„strç»“æŸä½ç½®ï¼Œé»˜è®¤ä¸ºstrçš„æœ€å¤§é•¿åº¦ã€‚

ä¸¾ä¸ªä¾‹å­ï¼š

```python
str = "this is string example....wow!!!";
 
suffix = "wow!!!";
print str.endswith(suffix);
print str.endswith(suffix,20);
 
suffix = "is";
print str.endswith(suffix, 2, 4);
print str.endswith(suffix, 2, 6);
```

è¾“å‡ºä¸ºï¼š

```
True
True
True
False
```

`os.sep`æ˜¯ä¸ºäº†è§£å†³ä¸åŒå¹³å°ä¸Šæ–‡ä»¶è·¯å¾„åˆ†éš”ç¬¦å·®å¼‚é—®é¢˜ï¼Œä¾‹å¦‚åœ¨windowså¹³å°ä¸Šï¼Œè·¯å¾„åˆ†éš”ç¬¦ä¸º`\`ï¼›linuxå¹³å°ä¸Šä¸º`/`ï¼›macä¸Šæ˜¯`:`ã€‚é‚£ä¹ˆå½“åœ¨ä¸åŒå¹³å°ä¸Šä½¿ç”¨`os.sep`æ—¶ï¼Œå¯¹åº”çš„è·¯å¾„åˆ†éš”ç¬¦å°±åˆ†åˆ«æ˜¯ä»¥ä¸Šåˆ—ä¸¾çš„å‡ ç§ã€‚`os.sep.join`å’Œ`os.path.join`ä¸¤ä¸ªå‡½æ•°ä¼ å…¥çš„å‚æ•°ç±»å‹ä¸åŒï¼Œå‰è€…æ˜¯åˆ—è¡¨ï¼ˆåˆ—è¡¨ä¸­çš„å…ƒç´ ä¹Ÿå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼‰ï¼Œåè€…æ˜¯å¤šä¸ªå­—ç¬¦ä¸²ã€‚ä¸¤ä¸ªå‡½æ•°å®ç°çš„åŠŸèƒ½åŸºæœ¬ç›¸åŒï¼š

```python
import os
os.sep.join(['hello','world']) #'hello/world'
os.path.join('hello','world') #'hello/world'
```

ğŸ‘‰è·å–æ–‡ä»¶mfccç‰¹å¾å’Œå¯¹åº”æ ‡ç­¾ï¼š

```python
def extract_features(wav_files):
    inputs = []
    labels = []

    for wav_file in tqdm(wav_files):
        # è¯»å…¥éŸ³é¢‘æ–‡ä»¶
        audio, fs = librosa.load(wav_file)

        # è·å–éŸ³é¢‘mfccç‰¹å¾
        # [n_steps, n_inputs]
        mfccs = np.transpose(librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=FLAGS.n_inputs), [1, 0])
        inputs.append(mfccs.tolist())
        # è·å–label
    for wav_file in wav_files:
        label = wav_file.split('/')[-1].split('-')[1]
        labels.append(label)
    return inputs, np.array(labels, dtype=np.int)
```

æˆ‘ä»¬ä½¿ç”¨[librosa](https://github.com/librosa/librosa)åŒ…æ¥è½½å…¥å£°éŸ³æ–‡ä»¶å¹¶æå–mfccç‰¹å¾ï¼ˆä¸€ç§å¹¿æ³›ä½¿ç”¨çš„è¯­éŸ³ç‰¹å¾ï¼‰ã€‚tqdmæ˜¯ä¸€ä¸ªå¯ä»¥æ˜¾ç¤ºpythonè¿›åº¦æ¡çš„æ¨¡å—ã€‚`np.transpose`çš„ç”¨æ³•è§æœ¬æ–‡ç¬¬2éƒ¨åˆ†ã€‚

ğŸ‘‰å› ä¸ºæˆ‘ä»¬è¦ä½¿ç”¨[GRUæ¨¡å‹](http://shichaoxin.com/2020/12/09/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åäºŒè¯¾-GRUå’ŒLSTM/#2gru)ï¼Œå› æ­¤æŠŠè¾“å…¥çš„æ¯ä¸ªç‰¹å¾åºåˆ—éƒ½ç”¨0å¡«å……ä¸ºç»Ÿä¸€é•¿åº¦ï¼š

```python
# è®¡ç®—æœ€é•¿çš„step
wav_max_len = max([len(feature) for feature in tr_features])
print("max_len:", wav_max_len) # 173

# å¡«å……0
tr_data = []
for mfccs in tr_features:
    while len(mfccs) < wav_max_len:  # åªè¦å°äºwav_max_lenå°±è¡¥n_inputsä¸ª0
        mfccs.append([0] * FLAGS.n_inputs)
    tr_data.append(mfccs)

tr_data = np.array(tr_data)
```

`tr_features`é‡Œæœ‰2685ä¸ª`feature`ï¼Œå³2685æ¡è¯­éŸ³çš„ç‰¹å¾åºåˆ—ï¼Œå¯ä»¥çœ‹ä½œæ˜¯2685ä¸ªå¥å­ã€‚æ¯ä¸ªå¥å­é‡Œçš„å•è¯æ•°é‡ï¼ˆå•è¯å¯ä»¥ç†è§£ä¸ºè¯­éŸ³æ‹†åˆ†æˆçš„å¸§ï¼‰ä¸ä¸€æ ·ï¼Œæœ€å¤šçš„æœ‰173ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯çš„è¯åµŒå…¥å‘é‡ï¼ˆå³æ¯ä¸€å¸§çš„ç‰¹å¾å‘é‡ï¼‰çš„é•¿åº¦ä¸º40ï¼Œå³`n_inputs`ã€‚

ğŸ‘‰å°†æ•°æ®é›†æ‰“ä¹±å¹¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š

```python
# Randomly shuffle data
np.random.seed(10)
shuffle_indices = np.random.permutation(np.arange(len(tr_data)))
x_shuffled = tr_data[shuffle_indices]
y_shuffled = tr_labels[shuffle_indices]

# Split train/test set
# æ•°æ®é›†åˆ‡åˆ†ä¸ºä¸¤éƒ¨åˆ†
dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y_shuffled)))
train_x, test_x = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]
train_y, test_y = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]
```

`np.random.permutation`çš„ç”¨æ³•è§ï¼š[ã€TensorflowåŸºç¡€ã€‘ç¬¬åå››è¯¾ï¼šCNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨](http://shichaoxin.com/2022/05/02/TensorflowåŸºç¡€-ç¬¬åå››è¯¾-CNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨/)ã€‚

ğŸ‘‰ç½‘ç»œçš„å®šä¹‰ï¼š

```python
# placeholder
x = tf.placeholder("float", [None, wav_max_len, FLAGS.n_inputs])
y = tf.placeholder("float", [None])
dropout = tf.placeholder(tf.float32)
# learning rate
lr = tf.Variable(FLAGS.lr, dtype=tf.float32, trainable=False)

# å®šä¹‰RNNç½‘ç»œ
# åˆå§‹åŒ–è¾“å‡ºå±‚çš„æƒå€¼å’Œåç½®å€¼
weights = tf.Variable(tf.truncated_normal([FLAGS.n_hidden, FLAGS.n_classes], stddev=0.1))
biases = tf.Variable(tf.constant(0.1, shape=[FLAGS.n_classes]))

# å¤šå±‚ç½‘ç»œ
num_layers = 3

def grucell():
    cell = tf.contrib.rnn.GRUCell(FLAGS.n_hidden)
    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout)
    return cell


cell = tf.contrib.rnn.MultiRNNCell([grucell() for _ in range(num_layers)])

outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)

# é¢„æµ‹å€¼
prediction = tf.nn.softmax(tf.matmul(final_state[0], weights) + biases)

# labelsè½¬one_hotæ ¼å¼
one_hot_labels = tf.one_hot(indices=tf.cast(y, tf.int32), depth=FLAGS.n_classes)

# loss
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=one_hot_labels))

# optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cross_entropy)

# Evaluate model
correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(one_hot_labels, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
```

`tf.contrib.rnn.GRUCell`ç”¨äºæ„å»º[GRUå•å…ƒ](http://shichaoxin.com/2020/12/09/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åäºŒè¯¾-GRUå’ŒLSTM/#2gru)ï¼Œå…¶å‚æ•°ä¸ºï¼š

```python
__init__(
    num_units,
    activation=None,
    reuse=None,
    kernel_initializer=None,
    bias_initializer=None,
    name=None,
    dtype=None
)
```

å¤§éƒ¨åˆ†å‚æ•°å’Œ[tf.nn.rnn_cell.BasicLSTMCell](http://shichaoxin.com/2021/03/22/TensorflowåŸºç¡€-ç¬¬å…«è¯¾-å¾ªç¯ç¥ç»ç½‘ç»œçš„å®ç°/#3tfnnrnn_cellbasiclstmcell)ä¸€æ ·ï¼Œä¸å†é‡å¤è§£é‡Šã€‚å‚æ•°`kernel_initializer`å’Œå‚æ•°`bias_initializer`å¯ç”¨äºæƒé‡çŸ©é˜µå’Œåç½®é¡¹çš„åˆå§‹åŒ–ã€‚

`tf.contrib.rnn.DropoutWrapper`ç”¨äºåœ¨[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)ä¸­åº”ç”¨[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ï¼Œå…¶å‚æ•°ä¸ºï¼š

```python
__init__(
    cell,
    input_keep_prob=1.0,
    output_keep_prob=1.0,
    state_keep_prob=1.0,
    variational_recurrent=False,
    input_size=None,
    dtype=None,
    seed=None,
    dropout_state_filter_visitor=None
)
```

å‚æ•°è¯¦è§£ï¼š

* `cell`ï¼šä¸€ä¸ª[RNN](http://shichaoxin.com/2020/11/22/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åè¯¾-å¾ªç¯ç¥ç»ç½‘ç»œ/)å•å…ƒï¼Œæ¯”å¦‚[GRUå•å…ƒ](http://shichaoxin.com/2020/12/09/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åäºŒè¯¾-GRUå’ŒLSTM/#2gru)æˆ–[LSTMå•å…ƒ](http://shichaoxin.com/2020/12/09/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åäºŒè¯¾-GRUå’ŒLSTM/#3lstm)ã€‚
* `input_keep_prob`ï¼šå¯¹è¾“å…¥å±‚æ‰§è¡Œ[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ã€‚
* `output_keep_prob`ï¼šå¯¹è¾“å‡ºå±‚æ‰§è¡Œ[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ã€‚
* `state_keep_prob`ï¼šè¿™ä¸ªæ˜¯é’ˆå¯¹[æ·±å±‚RNN](http://shichaoxin.com/2020/12/16/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åå››è¯¾-æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œ/)æ¥è¯´çš„ï¼Œåœ¨å±‚ä¸å±‚ä¹‹é—´ä½¿ç”¨[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ï¼ˆçºµå‘ä¸æ˜¯æ¨ªå‘ï¼Œå³æ¯å±‚å†…çš„æ¨ªå‘ä¼ æ’­ä¸€èˆ¬ä¸ä½¿ç”¨[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ï¼‰ã€‚
* `variational_recurrent`ï¼šå¸ƒå°”ç±»å‹ã€‚å¦‚æœä¸ºFalseï¼Œåˆ™å¯¹æ‰€æœ‰çš„æ—¶é—´æ­¥éƒ½ä½¿ç”¨ä¸€æ ·çš„[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)é…ç½®ï¼Œå³æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä½¿ç”¨`input_keep_prob`ã€`output_keep_prob`å’Œ`state_keep_prob`çš„å€¼ã€‚å¦‚æœä¸ºTrueï¼Œåˆ™éœ€è¦æä¾›ä¸‹ä¸€ä¸ªå‚æ•°`input_size`çš„å€¼ã€‚
* `input_size`ï¼šå¯é€‰å‚æ•°ï¼Œå½“`variational_recurrent=True`ä¸”`input_keep_prob<1`æ—¶éœ€è¦æä¾›è¯¥å‚æ•°çš„å€¼ã€‚è¯¥å‚æ•°ä¸ºä¸€ä¸ªå¯åµŒå¥—çš„tupleï¼Œä¸ªäººç†è§£å°±æ˜¯æ”¾å…¥æ¯ä¸ªæ—¶é—´æ­¥çš„[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)é…ç½®ã€‚
* `dtype`ï¼šå¯é€‰å‚æ•°ã€‚å½“`variational_recurrent=True`æ—¶éœ€è¦æä¾›è¯¥å‚æ•°çš„å€¼ï¼Œä½œç”¨æ˜¯æŒ‡å®šinput tensorã€state tensorå’Œoutput tensorçš„ç±»å‹ã€‚
* `seed`ï¼šå¯é€‰å‚æ•°ï¼Œintç±»å‹ï¼Œéšæœºæ•°ç§å­ã€‚
* `dropout_state_filter_visitor`ï¼šå¯é€‰å‚æ•°ã€‚ä¸ªäººç†è§£è¿™ä¸ªå‚æ•°ä¹Ÿæ˜¯é’ˆå¯¹[æ·±å±‚RNN](http://shichaoxin.com/2020/12/16/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åå››è¯¾-æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œ/)ï¼Œé€šè¿‡Trueå’ŒFalseæ§åˆ¶æ˜¯å¦è¦å¯¹æŸå±‚æ‰§è¡Œ[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)ï¼Œ[dropout](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#5dropoutæ­£åˆ™åŒ–)çš„æ¦‚ç‡åˆ™ç”±`state_keep_prob`æŒ‡å®šã€‚

`tf.contrib.rnn.MultiRNNCell`æ˜¯é’ˆå¯¹[æ·±å±‚RNN](http://shichaoxin.com/2020/12/16/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬å››åå››è¯¾-æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œ/)çš„ï¼Œç”¨äºå®šä¹‰æ¯ä¸€å±‚çš„cellã€‚

`tf.nn.dynamic_rnn`çš„ç”¨æ³•è§[é“¾æ¥](http://shichaoxin.com/2021/03/22/TensorflowåŸºç¡€-ç¬¬å…«è¯¾-å¾ªç¯ç¥ç»ç½‘ç»œçš„å®ç°/#4tfnndynamic_rnn)ã€‚

ğŸ‘‰å®šä¹‰batchï¼š

```python
def batch_iter(data, batch_size, num_epochs, shuffle=True):
    """
        Generates a batch iterator for a dataset.
    """
    data = np.array(data)
    data_size = len(data)
    # æ¯ä¸ªepochçš„num_batch
    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1
    print("num_batches_per_epoch:", num_batches_per_epoch)
    for epoch in range(num_epochs):
        # Shuffle the data at each epoch
        if shuffle:
            shuffle_indices = np.random.permutation(np.arange(data_size))
            shuffled_data = data[shuffle_indices]
        else:
            shuffled_data = data
        for batch_num in range(num_batches_per_epoch):
            start_index = batch_num * batch_size
            end_index = min((batch_num + 1) * batch_size, data_size)
            yield shuffled_data[start_index:end_index]
```

è¯¥å‡½æ•°å’Œæˆ‘ä»¬åœ¨[ã€TensorflowåŸºç¡€ã€‘ç¬¬åå››è¯¾ï¼šCNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨](http://shichaoxin.com/2022/05/02/TensorflowåŸºç¡€-ç¬¬åå››è¯¾-CNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨/)ä¸­ä½¿ç”¨çš„ä¸€æ ·ï¼Œåœ¨æ­¤ä¸å†èµ˜è¿°ã€‚

ğŸ‘‰æ¨¡å‹çš„è®­ç»ƒï¼Œæµ‹è¯•ä»¥åŠä¿å­˜ï¼š

```python
# Initializing the variables
init = tf.global_variables_initializer()
# å®šä¹‰saver
saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init)

    # Generate batches
    batches = batch_iter(list(zip(train_x, train_y)), FLAGS.batch_size, FLAGS.num_epochs)

    for i, batch in enumerate(batches):
        i = i + 1
        x_batch, y_batch = zip(*batch)
        sess.run([optimizer], feed_dict={x: x_batch, y: y_batch, dropout: FLAGS.dropout_keep_prob})

        # æµ‹è¯•
        if i % FLAGS.evaluate_every == 0:
            sess.run(tf.assign(lr, FLAGS.lr * (0.99 ** (i // FLAGS.evaluate_every))))
            learning_rate = sess.run(lr)
            tr_acc, _loss = sess.run([accuracy, cross_entropy], feed_dict={x: train_x, y: train_y, dropout: 1.0})
            ts_acc = sess.run(accuracy, feed_dict={x: test_x, y: test_y, dropout: 1.0})
            print("Iter {}, loss {:.5f}, tr_acc {:.5f}, ts_acc {:.5f}, lr {:.5f}".format(i, _loss, tr_acc, ts_acc,
                                                                                         learning_rate))

        # ä¿å­˜æ¨¡å‹
        if i % FLAGS.checkpoint_every == 0:
            path = saver.save(sess, "sounds_models/model", global_step=i)
            print("Saved model checkpoint to {}\n".format(path))
```

# 2.`np.transpose`

`np.transpose`ç”¨äºå®ŒæˆçŸ©é˜µçš„è½¬ç½®æ“ä½œã€‚ä¾‹å¦‚ï¼Œ`x=np.arange(4).reshape((2,2))`ï¼Œxä¸ºï¼š

```
array([[0, 1],
       [2, 3]])
```

`x.transpose()`ä¸ºï¼š

```
array([[0, 2],
       [1, 3]])
```

`np.transpose`è¿˜èƒ½æŒ‡å®šäº¤æ¢çš„ç»´åº¦ã€‚ä¾‹å¦‚ä¸€ä¸ªä¸‰ç»´æ•°æ®`t = np.arange(1,17).reshape(2, 2, 4)`ï¼š

```
array([[[ 1,  2,  3,  4],
        [ 5,  6,  7,  8]],
       [[ 9, 10, 11, 12],
        [13, 14, 15, 16]]])
```

`t.shape`ä¸º(2,2,4)ï¼Œå¯¹åº”æ¯ä¸ªç»´åº¦çš„å¤§å°ï¼šç¬¬0ç»´å¯¹åº”ç¬¬ä¸€ä¸ª2ï¼Œç¬¬1ç»´å¯¹åº”ç¬¬äºŒä¸ª2ï¼Œç¬¬2ç»´å¯¹åº”4ã€‚æˆ‘ä»¬å°†å…¶å¯è§†åŒ–è¡¨ç¤ºï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/TensorflowSeries/Lesson15/15x1.png)

æ­¤æ—¶å¦‚æœè¿è¡Œ`t1 = t.transpose(1, 0, 2)`ï¼Œåˆ™t1ä¸ºï¼š

```
array([[[ 1,  2,  3,  4],
        [ 9, 10, 11, 12]],
       [[ 5,  6,  7,  8],
        [13, 14, 15, 16]]])
```

ç›¸å½“äºäº¤æ¢ç¬¬0ç»´å’Œç¬¬1ç»´ï¼Œç¬¬2ç»´ä¿æŒä¸å˜ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/TensorflowSeries/Lesson15/15x2.png)

# 3.ä»£ç åœ°å€

1. [å£°éŸ³åˆ†ç±»](https://github.com/x-jeff/Tensorflow_Code_Demo/tree/master/Demo14)

# 4.å‚è€ƒèµ„æ–™

1. [Python enumerate()å‡½æ•°è¯¦è§£](https://wenku.baidu.com/view/9da6451d5b0216fc700abb68a98271fe910eaf1e.html)
2. [Python endswith()æ–¹æ³•ï¼ˆèœé¸Ÿæ•™ç¨‹ï¼‰](https://www.runoob.com/python/att-string-endswith.html)
3. [Pythonä¸­os.sep.join( )å’Œos.path.join()çš„ç”¨æ³•å’ŒåŒºåˆ«](https://blog.csdn.net/sunmingyang1987/article/details/103126899)
4. [Numpyä¸­transpose()å‡½æ•°çš„å¯è§†åŒ–ç†è§£](https://zhuanlan.zhihu.com/p/61203757)