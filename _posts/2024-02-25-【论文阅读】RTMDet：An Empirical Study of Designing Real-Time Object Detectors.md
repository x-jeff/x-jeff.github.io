---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘RTMDetï¼šAn Empirical Study of Designing Real-Time Object Detectors
subtitle:   RTMDet
date:       2024-02-25
author:     x-jeff
header-img: blogimg/20221107.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>å®˜æ–¹github repoï¼š[RTMDet](https://github.com/open-mmlab/mmdetection/tree/3.x/configs/rtmdet)ã€‚
>
>å®˜æ–¹æ–‡æ¡£ï¼š[RTMDET åŸç†å’Œå®ç°å…¨è§£æ](https://mmyolo.readthedocs.io/zh-cn/latest/recommended_topics/algorithm_descriptions/rtmdet_description.html)ã€‚

æˆ‘ä»¬çš„ç›®çš„æ—¨åœ¨çªç ´YOLOç³»åˆ—æ¨¡å‹çš„æé™ï¼Œæå‡ºä¸€ä¸ªæ–°çš„ç”¨äºç›®æ ‡æ£€æµ‹çš„å®æ—¶æ¨¡å‹å®¶æ—ï¼Œç§°ä¸ºRTMDetï¼ˆ**R**eal-**T**ime **M**odels for object **Det**ectionï¼ŒRTMä¹Ÿå¯ä»¥ç†è§£ä¸º**R**elease **T**o **M**anufactureï¼‰ï¼Œå…¶è¿˜å¯ä»¥è¿›è¡Œå®ä¾‹åˆ†å‰²å’Œæ—‹è½¬ç›®æ ‡çš„æ£€æµ‹ï¼Œè¿™æ˜¯ä»¥å‰çš„å·¥ä½œæ²¡æœ‰æ¢ç´¢è¿‡çš„ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/1.png)

Fig1å·¦ä¸ºRTMDetåœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ŒFig1å³ä¸ºRTMDet-Insåœ¨å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

# 2.Related Work

ä¸å†èµ˜è¿°ã€‚

# 3.Methodology

## 3.1.Macro Architecture

RTMDetæ˜¯ä¸€ä¸ªone-stageçš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œå…¶å®è§‚æ¡†æ¶åŒ…æ‹¬backboneã€neckã€headç­‰å‡ éƒ¨åˆ†ï¼Œå¦‚Fig2æ‰€ç¤ºã€‚æœ€è¿‘çš„[YOLOv4](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)å’Œ[YOLOX](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)éƒ½ä½¿ç”¨CSPDarkNetä½œä¸ºbackboneï¼ŒCSPDarkNet blockå¦‚Fig3(a)æ‰€ç¤ºã€‚neckéƒ¨åˆ†åˆ™ä»backboneä¸­æå–å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”ï¼Œå¹¶ä½¿ç”¨å’Œbackboneç›¸åŒçš„building blockï¼Œé€šè¿‡è‡ªä¸Šè€Œä¸‹å’Œè‡ªä¸‹è€Œä¸Šçš„ç‰¹å¾ä¼ æ’­æ¥å¢å¼ºpyramid feature mapã€‚æœ€åï¼Œheadéƒ¨åˆ†åŸºäºæ¯ç§å°ºåº¦çš„feature mapæ¥é¢„æµ‹ç›®æ ‡çš„bounding boxå’Œç±»åˆ«ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/2.png)

Fig2ä¸­çš„PAFPNæŒ‡çš„å°±æ˜¯[PANet](http://shichaoxin.com/2023/12/28/è®ºæ–‡é˜…è¯»-Path-Aggregation-Network-for-Instance-Segmentation/)ã€‚ä¸‹é¢æ˜¯æ›´è¯¦ç»†çš„æ¡†æ¶å›¾ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/3.jpg)

## 3.2.Model Architecture

ğŸ‘‰**Basic building block.**

backboneä¸­å¤§çš„æœ‰æ•ˆçš„æ„Ÿå—é‡æœ‰åˆ©äºdense predictionçš„ä»»åŠ¡ï¼Œæ¯”å¦‚ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ï¼Œå› ä¸ºå®ƒæœ‰åŠ©äºæ›´å…¨é¢çš„æ•æ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„ç ”ç©¶ä¸ºäº†å¢å¤§æ„Ÿå—é‡é€šå¸¸ä¹Ÿä¼šå¸¦æ¥æ˜‚è´µçš„è®¡ç®—æˆæœ¬ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®æ—¶ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ·±åº¦å·ç§¯ï¼ˆdepth-wise convolutionï¼‰ï¼Œåœ¨åˆç†çš„è®¡ç®—æˆæœ¬å†…æœ‰æ•ˆçš„å¢å¤§æ„Ÿå—é‡ï¼Œå¦‚Fig3(b)æ‰€ç¤ºã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨¡å‹ç²¾åº¦ã€‚æˆ‘ä»¬å°†å½¢å¦‚Fig3(b)çš„ç»“æ„ç§°ä¸ºCSPNeXt Blockï¼ŒFig3(a)ç§°ä¸ºbasic blockã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/4.png)

ä¸€äº›å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œæ¯”å¦‚YOLOv6å’ŒPPYOLO-Eï¼Œä½¿ç”¨äº†é‡å‚æ•°åŒ–ï¼ˆre-parameterizedï¼‰çš„$3 \times 3$å·ç§¯ï¼ˆè§Fig3(c)å’ŒFig3(d)ï¼‰ï¼Œè¿™ä¸€æ“ä½œè™½ç„¶æé«˜äº†ç²¾åº¦ï¼Œä½†ä¹Ÿä½¿å¾—è®­ç»ƒé€Ÿåº¦å˜æ…¢ï¼Œè®­ç»ƒå ç”¨å†…å­˜å˜å¤šã€‚ä¸ä¹‹ç›¸æ¯”ï¼Œlarge-kernelï¼ˆä½œè€…ä½¿ç”¨$5 \times 5$å¤§å°çš„kernelï¼‰çš„depth-wiseå·ç§¯æ˜¯ä¸€ç§æ›´ç®€å•æœ‰æ•ˆçš„é€‰æ‹©ï¼Œå…¶è®­ç»ƒæˆæœ¬æ›´ä½ã€‚

æ¥ä¸‹æ¥è¯´ä¸‹å‡ ç§å·ç§¯æ–¹å¼çš„ä¸åŒï¼Œé¦–å…ˆæ˜¯å¸¸è§„çš„å·ç§¯æ“ä½œï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/5.png)

ç„¶åæ˜¯depth-wiseå·ç§¯ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/6.png)

depth-wiseå·ç§¯å®Œå…¨æ˜¯åœ¨äºŒç»´å¹³é¢å†…è¿›è¡Œçš„ï¼Œå·ç§¯æ ¸çš„æ•°é‡å’Œä¸Šä¸€å±‚çš„é€šé“æ•°ç›¸åŒï¼ˆé€šé“å’Œå·ç§¯æ ¸ä¸€ä¸€å¯¹åº”ï¼‰ã€‚æœ€åæ˜¯point-wiseå·ç§¯ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/7.png)

point-wiseå·ç§¯å°±æ˜¯$1 \times 1$å·ç§¯ï¼Œå®ƒçš„å·ç§¯æ ¸å°ºå¯¸ä¸º$1 \times 1 \times M$ï¼Œ$M$ä¸ºä¸Šä¸€å±‚çš„é€šé“æ•°ã€‚æ‰€ä»¥è¿™é‡Œçš„å·ç§¯è¿ç®—ä¼šå°†ä¸Šä¸€æ­¥çš„feature mapåœ¨æ·±åº¦æ–¹å‘ä¸Šè¿›è¡ŒåŠ æƒç»„åˆï¼Œç”Ÿæˆæ–°çš„feature mapã€‚æœ‰å‡ ä¸ªå·ç§¯æ ¸å°±æœ‰å‡ ä¸ªè¾“å‡ºfeature mapã€‚

ğŸ‘‰**Balance of model width and depth.**

ç›¸æ¯”basic blockï¼ŒCSPNeXt blockåœ¨depth-wiseå·ç§¯åå¢åŠ äº†é¢å¤–çš„point-wiseå·ç§¯ï¼Œè¿™ä½¿å¾—æ¯ä¸ªblockå†…çš„å±‚æ•°å¢åŠ äº†ï¼Œè¿™é˜»ç¢äº†æ¯ä¸€å±‚çš„å¹¶è¡Œè®¡ç®—ï¼Œä»è€Œé™ä½äº†æ¨ç†é€Ÿåº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¯¹äºbackboneä¸­çš„æ¯ä¸ªstageï¼Œæˆ‘ä»¬å‡å°‘äº†blockçš„æ•°é‡å¹¶é€‚å½“å¢åŠ äº†blockçš„widthï¼Œæœ€ç»ˆåœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„æƒ…å†µä¸‹æé«˜äº†æ¨ç†é€Ÿåº¦ã€‚

ğŸ‘‰**Balance of backbone and neck.**

å¤šå°ºåº¦çš„ç‰¹å¾é‡‘å­—å¡”æ˜¯æ£€æµ‹ä¸åŒå°ºåº¦ç›®æ ‡çš„å…³é”®ã€‚ä¸ºäº†å¢å¼ºå¤šå°ºåº¦çš„ç‰¹å¾ï¼ŒEfficientDetã€NASFPNç­‰å·¥ä½œåœ¨æ”¹è¿›neckæ—¶å¾€å¾€èšç„¦äºå¦‚ä½•ä¿®æ”¹ç‰¹å¾èåˆçš„æ–¹å¼ï¼Œä½†å…¶å¼•å…¥è¿‡å¤šçš„è¿æ¥ä¼šå¢åŠ æ£€æµ‹å™¨çš„å»¶æ—¶ï¼Œå¹¶å¢åŠ å†…å­˜å¼€é”€ã€‚æˆ‘ä»¬é€‰æ‹©ä¸å¼•å…¥é¢å¤–çš„è¿æ¥ï¼Œè€Œæ˜¯æ”¹å˜backboneä¸necké—´å‚æ•°é‡çš„é…æ¯”ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒå‘ç°ï¼Œå½“neckåœ¨æ•´ä¸ªæ¨¡å‹ä¸­çš„å‚æ•°é‡å æ¯”æ›´é«˜æ—¶ï¼Œå»¶æ—¶æ›´ä½ï¼Œä¸”å¯¹ç²¾åº¦çš„å½±å“å¾ˆå°ã€‚

ğŸ‘‰**Shared detection head.**

ä»ç¬¬3.1éƒ¨åˆ†çš„æ¡†æ¶å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨headéƒ¨åˆ†ï¼Œå€Ÿé‰´äº†[YOLOX](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)ä¸­è§£è€¦å¤´çš„è®¾è®¡ï¼Œå…¶ä¸­ï¼Œå·ç§¯å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼ˆBBoxåˆ†æ”¯å…±äº«ä¸€å¥—å‚æ•°ï¼ŒClsåˆ†æ”¯å…±äº«ä¸€å¥—å‚æ•°ï¼‰ï¼Œå³å›¾ä¸­çš„â€SharedConvâ€ï¼›ä½†[BN](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)çš„å‚æ•°æ˜¯ä¸å…±äº«çš„ï¼Œå³å›¾ä¸­çš„â€SepBNâ€ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œ[BN](http://shichaoxin.com/2021/11/02/è®ºæ–‡é˜…è¯»-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/)ç›´æ¥ä½¿ç”¨è®­ç»ƒé˜¶æ®µçš„ç»Ÿè®¡æ•°æ®ã€‚

## 3.3.Training Strategy

ğŸ‘‰**Label assignment and losses.**

æ­£è´Ÿæ ·æœ¬åŒ¹é…ç­–ç•¥æˆ–è€…ç§°ä¸ºæ ‡ç­¾åŒ¹é…ç­–ç•¥ï¼ˆLabel Assignmentï¼‰æ˜¯ç›®æ ‡æ£€æµ‹æ¨¡å‹è®­ç»ƒä¸­æœ€æ ¸å¿ƒçš„é—®é¢˜ä¹‹ä¸€ï¼Œæ›´å¥½çš„æ ‡ç­¾åŒ¹é…ç­–ç•¥å¾€å¾€èƒ½å¤Ÿä½¿å¾—ç½‘ç»œæ›´å¥½å­¦ä¹ åˆ°ç‰©ä½“çš„ç‰¹å¾ä»¥æé«˜æ£€æµ‹èƒ½åŠ›ã€‚

æ—©æœŸçš„æ ·æœ¬æ ‡ç­¾åŒ¹é…ç­–ç•¥ä¸€èˆ¬éƒ½æ˜¯åŸºäºç©ºé—´ä»¥åŠå°ºåº¦ä¿¡æ¯çš„å…ˆéªŒæ¥å†³å®šæ ·æœ¬çš„é€‰å–ã€‚å…¸å‹æ¡ˆä¾‹å¦‚ä¸‹ï¼š

* [FCOS](http://shichaoxin.com/2024/08/20/è®ºæ–‡é˜…è¯»-FCOS-Fully-Convolutional-One-Stage-Object-Detection/)ä¸­å…ˆé™å®šç½‘æ ¼ä¸­å¿ƒç‚¹åœ¨GTå†…ç­›é€‰åç„¶åå†é€šè¿‡ä¸åŒç‰¹å¾å±‚é™åˆ¶å°ºå¯¸æ¥å†³å®šæ­£è´Ÿæ ·æœ¬ã€‚
* [RetinaNet](http://shichaoxin.com/2024/02/22/è®ºæ–‡é˜…è¯»-Focal-Loss-for-Dense-Object-Detection/)åˆ™æ˜¯é€šè¿‡anchorä¸GTçš„æœ€å¤§IoUåŒ¹é…æ¥åˆ’åˆ†æ­£è´Ÿæ ·æœ¬ã€‚
* [YOLOv5](http://shichaoxin.com/2024/01/14/YOLOç³»åˆ—-YOLOv5/)çš„æ­£è´Ÿæ ·æœ¬åˆ™æ˜¯é€šè¿‡æ ·æœ¬çš„å®½é«˜æ¯”å…ˆç­›é€‰ä¸€éƒ¨åˆ†ï¼Œç„¶åé€šè¿‡ä½ç½®ä¿¡æ¯é€‰å–GTä¸­å¿ƒè½åœ¨çš„gridä»¥åŠä¸´è¿‘çš„ä¸¤ä¸ªä½œä¸ºæ­£æ ·æœ¬ã€‚

ä½†æ˜¯ä¸Šè¿°æ–¹æ³•éƒ½æ˜¯å±äºåŸºäºå…ˆéªŒçš„é™æ€åŒ¹é…ç­–ç•¥ï¼Œå°±æ˜¯æ ·æœ¬çš„é€‰å–æ–¹å¼æ˜¯æ ¹æ®äººçš„ç»éªŒè§„å®šçš„ã€‚ä¸ä¼šéšç€ç½‘ç»œçš„ä¼˜åŒ–è€Œè¿›è¡Œè‡ªåŠ¨ä¼˜åŒ–é€‰å–åˆ°æ›´å¥½çš„æ ·æœ¬ï¼Œè¿‘äº›å¹´æ¶Œç°äº†è®¸å¤šä¼˜ç§€çš„åŠ¨æ€æ ‡ç­¾åŒ¹é…ç­–ç•¥ï¼š

* OTAæå‡ºä½¿ç”¨Sinkhornè¿­ä»£æ±‚è§£åŒ¹é…ä¸­çš„æœ€ä¼˜ä¼ è¾“é—®é¢˜ã€‚
* [YOLOX](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)ä¸­ä½¿ç”¨OTAçš„è¿‘ä¼¼ç®—æ³•SimOTAï¼Œ[TOOD](http://shichaoxin.com/2024/08/29/è®ºæ–‡é˜…è¯»-TOOD-Task-aligned-One-stage-Object-Detection/)å°†åˆ†ç±»åˆ†æ•°ä»¥åŠIoUç›¸ä¹˜è®¡ç®—costçŸ©é˜µè¿›è¡Œæ ‡ç­¾åŒ¹é…ç­‰ç­‰ã€‚

è¿™äº›ç®—æ³•å°†é¢„æµ‹çš„Bboxesä¸GTçš„IoUå’Œåˆ†ç±»åˆ†æ•°æˆ–è€…æ˜¯å¯¹åº”åˆ†ç±»Losså’Œå›å½’Lossæ‹¿æ¥è®¡ç®—matching costçŸ©é˜µå†é€šè¿‡top-kçš„æ–¹å¼åŠ¨æ€å†³å®šæ ·æœ¬é€‰å–ä»¥åŠæ ·æœ¬ä¸ªæ•°ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œåœ¨ç½‘ç»œä¼˜åŒ–çš„è¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨é€‰å–å¯¹åˆ†ç±»æˆ–è€…å›å½’æ›´åŠ æ•æ„Ÿæœ‰æ•ˆçš„ä½ç½®çš„æ ·æœ¬ï¼Œå®ƒä¸å†åªä¾èµ–å…ˆéªŒçš„é™æ€çš„ä¿¡æ¯ï¼Œè€Œæ˜¯ä½¿ç”¨å½“å‰çš„é¢„æµ‹ç»“æœå»åŠ¨æ€å¯»æ‰¾æœ€ä¼˜çš„åŒ¹é…ï¼Œåªè¦æ¨¡å‹çš„é¢„æµ‹è¶Šå‡†ç¡®ï¼ŒåŒ¹é…ç®—æ³•æ±‚å¾—çš„ç»“æœä¹Ÿä¼šæ›´ä¼˜ç§€ã€‚ä½†æ˜¯åœ¨ç½‘ç»œè®­ç»ƒçš„åˆæœŸï¼Œç½‘ç»œçš„åˆ†ç±»ä»¥åŠå›å½’æ˜¯éšæœºåˆå§‹åŒ–ï¼Œè¿™ä¸ªæ—¶å€™è¿˜æ˜¯éœ€è¦å…ˆéªŒæ¥çº¦æŸï¼Œä»¥è¾¾åˆ°å†·å¯åŠ¨çš„æ•ˆæœã€‚

æœ€è¿‘çš„ä¸€äº›åŠ¨æ€æ ·æœ¬åŒ¹é…ç­–ç•¥ï¼Œæ¯”å¦‚[SimOTA](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)ï¼Œé€šå¸¸ä½¿ç”¨å’Œè®­ç»ƒlossä¸€è‡´çš„cost functionä½œä¸ºåŒ¹é…æ ‡å‡†ã€‚ä½†æˆ‘ä»¬å‘ç°å…¶å…·æœ‰ä¸€å®šçš„å±€é™æ€§ï¼Œå¹¶ä¸ä¸€å®šæ˜¯æœ€ä¼˜çš„ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäº[SimOTA](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)çš„åŠ¨æ€è½¯æ ‡ç­¾åˆ†é…ç­–ç•¥ï¼Œå…¶cost functionä¸ºï¼š

$$C = \lambda_1 C_{cls} + \lambda_2 C_{reg} + \lambda_3 C_{center} \tag{1}$$

å…¶ä¸­ï¼Œ$C_{cls}$ä¸ºclassification costï¼Œ$C_{center}$ä¸ºregion prior costï¼Œ$C_{reg}$ä¸ºregression costã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ$\lambda_1 = 1, \lambda_2 = 3, \lambda_3 = 1$ã€‚

å…ˆå‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨äºŒå€¼æ ‡ç­¾æ¥è®¡ç®—$C_{cls}$ï¼Œä½†è¿™å­˜åœ¨ä¸€å®šå±€é™æ€§ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†soft labelå¼•å…¥åˆ°$C_{cls}$è®¡ç®—ä¸­ï¼š

$$C_{cls} = CE (P, Y_{soft}) \times (Y_{soft} - P)^2 \tag{2}$$

å…¶ä¸­ï¼Œ$P$æ˜¯é¢„æµ‹çš„ç±»åˆ«ç»“æœï¼ˆæ¯”å¦‚softmaxçš„è¾“å‡ºï¼‰ï¼Œ$Y_{soft}$æ˜¯GT boxå’Œé¢„æµ‹çš„bounding boxçš„IoUï¼Œæˆ‘ä»¬å°†$Y_{soft}$è§†ä¸ºç±»åˆ«çš„soft labelã€‚è¿™éƒ¨åˆ†çš„æºç è§ä¸‹ï¼š

```python
# ç”Ÿæˆåˆ†ç±»æ ‡ç­¾
 gt_onehot_label = (
    F.one_hot(gt_labels.to(torch.int64),
              pred_scores.shape[-1]).float().unsqueeze(0).repeat(
                  num_valid, 1, 1))
valid_pred_scores = valid_pred_scores.unsqueeze(1).repeat(1, num_gt, 1)
# ä¸å•å•å°†åˆ†ç±»æ ‡ç­¾ä¸º01,è€Œæ˜¯æ¢æˆä¸ gt çš„ iou
soft_label = gt_onehot_label * pairwise_ious[..., None]
# ä½¿ç”¨ quality focal loss è®¡ç®—åˆ†ç±»æŸå¤± cost ,ä¸å®é™…çš„åˆ†ç±»æŸå¤±è®¡ç®—ä¿æŒä¸€è‡´
scale_factor = soft_label - valid_pred_scores.sigmoid()
soft_cls_cost = F.binary_cross_entropy_with_logits(
    valid_pred_scores, soft_label,
    reduction='none') * scale_factor.abs().pow(2.0)
soft_cls_cost = soft_cls_cost.sum(dim=-1)
```

æ¯”å¦‚ä¸€å…±æœ‰3ä¸ªç±»åˆ«ï¼Œbounding boxçš„ç±»åˆ«é¢„æµ‹ç»“æœ$P=[0.1,0.3,0.6]$ï¼Œç±»åˆ«GTçš„one-hotç¼–ç ä¸º$[0,0,1]$ï¼Œé¢„æµ‹çš„bounding boxå’ŒGT boxçš„IoUä¸º0.9ï¼Œé‚£ä¹ˆ$Y_{soft} = [0,0,1] * IoU = [0,0,0.9]$ã€‚å¦‚æœæˆ‘ä»¬å¯¹ç…§ç€ä¸Šè¿°ä»£ç çœ‹çš„è¯ï¼Œ`soft_label`å°±æ˜¯$[0.,0.,0.9]$ï¼Œ`valid_pred_scores`å°±æ˜¯$[0.1,0.3,0.6]$ï¼Œ`scale_factor`å°±æ˜¯å¼(2)ä¸­ç¬¬2é¡¹æ‹¬å·ä¸­çš„å†…å®¹ï¼Œæ³¨æ„è¿™é‡ŒæŠŠ`valid_pred_scores`è¿›è¡Œäº†sigmoidå¤„ç†ï¼Œå³é€šè¿‡å…¬å¼$\frac{1}{1+e^{-x}}$ï¼Œå¾—åˆ°`valid_pred_scores.sigmoid()`ä¸º$[0.5250, 0.5744, 0.6457]$ï¼Œå¾—åˆ°çš„`scale_factor`ä¸º$[-0.5250, -0.5744,  0.2543]$ï¼Œå…¶å¹³æ–¹æ˜¯å¯¹æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹ï¼Œæ‰€ä»¥`scale_factor.abs().pow(2.0)`ä¸º$[0.2756, 0.3300, 0.0647]$ï¼Œè¿™å°±æ˜¯å¼(2)ç¬¬äºŒé¡¹çš„è®¡ç®—ç»“æœã€‚ç¬¬ä¸€é¡¹CEçš„è®¡ç®—ç»“æœä¸º$[0.7444, 0.8544, 0.4975]$ï¼Œå’Œç¬¬äºŒé¡¹ç›¸ä¹˜ä¾¿å¯å¾—åˆ°$[0.2052, 0.2819, 0.0322]$ï¼Œå°†è¿™3ä¸ªæ•°ç›¸åŠ å¾—åˆ°æœ€ç»ˆçš„`soft_cls_cost`ï¼Œä¸º0.5193ã€‚

è½¯æ ‡ç­¾åˆ†ç±»æŸå¤±é¿å…äº†äºŒå€¼æ ‡ç­¾å¼•èµ·çš„å™ªå£°å’Œä¸ç¨³å®šåŒ¹é…ã€‚

$C_{reg}$çš„è®¡ç®—å¦‚ä¸‹ï¼š

$$C_{reg}=-\log (IoU) \tag{3}$$

è¿™éƒ¨åˆ†æºç è§ä¸‹ï¼š

```python
# è®¡ç®—å›å½’ bboxes å’Œ gts çš„ iou
pairwise_ious = self.iou_calculator(valid_decoded_bbox, gt_bboxes)
# iouè¶Šå°ï¼Œcostè¶Šå¤§
iou_cost = -torch.log(pairwise_ious + EPS) * 3
```

$C_{center}$çš„è®¡ç®—å¦‚ä¸‹ï¼š

$$C_{center} = \alpha ^{\lvert x_{pred} â€“ x_{gt} \rvert - \beta } \tag{4}$$

é»˜è®¤è¶…å‚æ•°$\alpha = 10, \beta=3$ã€‚

è¿™éƒ¨åˆ†çš„æºç è§ä¸‹ï¼š

```python
# valid_prior Tensor[N,4] è¡¨ç¤ºanchor point
# 4åˆ†åˆ«è¡¨ç¤º x, y, ä»¥åŠå¯¹åº”çš„ç‰¹å¾å±‚çš„ stride, stride
gt_center = (gt_bboxes[:, :2] + gt_bboxes[:, 2:]) / 2.0
valid_prior = priors[valid_mask]
strides = valid_prior[:, 2]
# è®¡ç®—gtä¸anchor pointçš„ä¸­å¿ƒè·ç¦»å¹¶è½¬æ¢åˆ°ç‰¹å¾å›¾å°ºåº¦
distance = (valid_prior[:, None, :2] - gt_center[None, :, :]
                    ).pow(2).sum(-1).sqrt() / strides[:, None]
# ä»¥10ä¸ºåº•è®¡ç®—ä½ç½®çš„è½¯åŒ–æŸå¤±,é™å®šåœ¨gtçš„6ä¸ªå•å…ƒæ ¼ä»¥å†…
soft_center_prior = torch.pow(10, distance - 3)
```

ä»æºç ä¸­å¯ä»¥çœ‹å‡ºï¼Œ$\lvert x_{pred} â€“ x_{gt} \rvert $æ˜¯GT boxä¸­å¿ƒç‚¹åˆ°é¢„æµ‹bounding boxä¸­å¿ƒç‚¹çš„è·ç¦»ã€‚

ä»¥ä¸Šæ˜¯SimOTAä¸­è®¡ç®—costæ‰€ç”¨çš„cost functionï¼Œæ¥ä¸‹æ¥è¯´ä¸‹æ¨¡å‹è®­ç»ƒæ‰€ç”¨çš„lossè®¾è®¡ã€‚è®­ç»ƒlossä¸€å…±åŒ…æ‹¬2éƒ¨åˆ†ï¼šcls losså’Œbbox lossã€‚æƒé‡æ¯”ä¾‹æ˜¯cls loss : bbox loss = 1 : 2ã€‚bbox lossä½¿ç”¨[GIoU loss](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ã€‚cls lossä½¿ç”¨[QFLï¼ˆQuality Focal Lossï¼‰](http://shichaoxin.com/2024/09/04/è®ºæ–‡é˜…è¯»-Generalized-Focal-Loss-Learning-Qualified-and-Distributed-Bounding-Boxes-for-Dense-Object-Detection/)ï¼Œæ¥ä¸‹æ¥è¯¦ç»†ä»‹ç»ä¸‹[QFL](http://shichaoxin.com/2024/09/04/è®ºæ–‡é˜…è¯»-Generalized-Focal-Loss-Learning-Qualified-and-Distributed-Bounding-Boxes-for-Dense-Object-Detection/)ã€‚[QFL](http://shichaoxin.com/2024/09/04/è®ºæ–‡é˜…è¯»-Generalized-Focal-Loss-Learning-Qualified-and-Distributed-Bounding-Boxes-for-Dense-Object-Detection/)å°†ç›®æ ‡çš„å®šä½è´¨é‡ï¼ˆæ¯”å¦‚é¢„æµ‹çš„bounding boxå’ŒGT boxçš„IoUï¼‰ç›´æ¥èåˆåˆ°åˆ†ç±»æŸå¤±ä¸­ï¼Œè§£å†³äº†ä¼ ç»Ÿç›®æ ‡æ£€æµ‹ä¸­åˆ†ç±»ä¸å®šä½ä»»åŠ¡ä¹‹é—´å­˜åœ¨çš„ä¸ä¸€è‡´é—®é¢˜ã€‚å…¶åŸºäº[focal loss](http://shichaoxin.com/2024/02/22/è®ºæ–‡é˜…è¯»-Focal-Loss-for-Dense-Object-Detection/)è¿›è¡Œä¼˜åŒ–ï¼š

$$\text{QFL}(\sigma) = - \lvert y - \sigma \rvert^{\beta} ((1-y)\log (1-\sigma) + y \log (\sigma))$$

å…¶ä¸­ï¼Œ$\beta \geqslant 0$ï¼Œ$\sigma$å°±æ˜¯é¢„æµ‹çš„ç±»åˆ«æ¦‚ç‡ï¼Œ$-((1-y)\log (1-\sigma) + y \log (\sigma))$å…¶å®å°±æ˜¯ä¸€ä¸ªCE lossï¼Œ$y$æ˜¯soft labelï¼Œå³é¢„æµ‹çš„bounding boxå’ŒGT boxçš„IoUï¼Œå¦‚æœæ˜¯è´Ÿæ ·æœ¬ï¼Œåˆ™$y=0$ã€‚

ğŸ‘‰**Cached Mosaic and MixUp.**

[MixUp](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)å’Œ[CutMix](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)è™½ç„¶å¥½ç”¨ï¼Œä½†æœ‰ä¸¤ä¸ªé—®é¢˜ã€‚ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨æ¯æ¬¡è¿­ä»£æ—¶ï¼Œæˆ‘ä»¬éƒ½éœ€è¦åŠ è½½å¤šå¼ å›¾ç‰‡æ¥ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œè¿™å°±å¼•å…¥äº†æ›´å¤šçš„æ•°æ®åŠ è½½æˆæœ¬ï¼Œå¹¶ä¸”ä¼šæ‹–æ…¢è®­ç»ƒé€Ÿåº¦ã€‚ç¬¬äºŒä¸ªé—®é¢˜ï¼Œç”Ÿæˆçš„è®­ç»ƒæ ·æœ¬æ˜¯æœ‰å™ªå£°çš„ï¼Œå¯èƒ½ä¸å±äºæ•°æ®é›†çš„çœŸå®åˆ†å¸ƒï¼Œè¿™å½±å“äº†æ¨¡å‹å­¦ä¹ ã€‚

[Mosaic](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)å’Œ[MixUp](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)æ¶‰åŠåˆ°å¤šå¼ å›¾ç‰‡çš„æ··åˆï¼Œå®ƒä»¬çš„è€—æ—¶ä¼šæ˜¯æ™®é€šæ•°æ®å¢å¼ºçš„$K$å€ï¼ˆ$K$ä¸ºæ··å…¥å›¾ç‰‡çš„æ•°é‡ï¼‰ã€‚å¦‚åœ¨[YOLOv5](http://shichaoxin.com/2024/01/14/YOLOç³»åˆ—-YOLOv5/)ä¸­ï¼Œæ¯æ¬¡åš[Mosaic](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)æ—¶ï¼Œ4å¼ å›¾ç‰‡çš„ä¿¡æ¯éƒ½éœ€è¦ä»ç¡¬ç›˜ä¸­é‡æ–°åŠ è½½ã€‚è€ŒRTMDetåªéœ€è¦é‡æ–°è½½å…¥å½“å‰çš„ä¸€å¼ å›¾ç‰‡ï¼Œå…¶ä½™å‚ä¸æ··åˆå¢å¼ºçš„å›¾ç‰‡åˆ™ä»ç¼“å­˜é˜Ÿåˆ—ä¸­è·å–ï¼Œé€šè¿‡ç‰ºç‰²ä¸€å®šå†…å­˜ç©ºé—´çš„æ–¹å¼å¤§å¹…æå‡äº†æ•ˆç‡ã€‚å¦å¤–é€šè¿‡è°ƒæ•´cacheçš„å¤§å°ä»¥åŠpopçš„æ–¹å¼ï¼Œä¹Ÿå¯ä»¥è°ƒæ•´å¢å¼ºçš„å¼ºåº¦ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/8.png)

å¦‚å›¾æ‰€ç¤ºï¼Œcacheé˜Ÿåˆ—ä¸­é¢„å…ˆå­˜å‚¨äº†$N$å¼ å·²åŠ è½½çš„å›¾åƒä¸æ ‡ç­¾æ•°æ®ï¼Œæ¯ä¸€ä¸ªè®­ç»ƒstepä¸­åªéœ€åŠ è½½ä¸€å¼ æ–°çš„å›¾ç‰‡åŠå…¶æ ‡ç­¾æ•°æ®å¹¶æ›´æ–°åˆ°cacheé˜Ÿåˆ—ä¸­ï¼ˆcacheé˜Ÿåˆ—ä¸­çš„å›¾åƒå¯é‡å¤ï¼Œå¦‚å›¾ä¸­å‡ºç°ä¸¤æ¬¡img3ï¼‰ï¼ŒåŒæ—¶å¦‚æœcacheé˜Ÿåˆ—é•¿åº¦è¶…è¿‡é¢„è®¾é•¿åº¦ï¼Œåˆ™éšæœºpopä¸€å¼ å›¾ï¼ˆä¸ºäº†Tinyæ¨¡å‹è®­ç»ƒæ›´ç¨³å®šï¼Œåœ¨Tinyæ¨¡å‹ä¸­ä¸é‡‡ç”¨éšæœºpopçš„æ–¹å¼ï¼Œè€Œæ˜¯ç§»é™¤æœ€å…ˆåŠ å…¥çš„å›¾ç‰‡ï¼‰ï¼Œå½“éœ€è¦è¿›è¡Œæ··åˆæ•°æ®å¢å¼ºæ—¶ï¼Œåªéœ€è¦ä»cacheä¸­éšæœºé€‰æ‹©éœ€è¦çš„å›¾åƒè¿›è¡Œæ‹¼æ¥ç­‰å¤„ç†ï¼Œè€Œä¸éœ€è¦å…¨éƒ¨ä»ç¡¬ç›˜ä¸­åŠ è½½ï¼ŒèŠ‚çœäº†å›¾åƒåŠ è½½çš„æ—¶é—´ã€‚

cacheé˜Ÿåˆ—çš„æœ€å¤§é•¿åº¦$N$ä¸ºå¯è°ƒæ•´å‚æ•°ï¼Œæ ¹æ®ç»éªŒæ€§çš„åŸåˆ™ï¼Œå½“ä¸ºæ¯ä¸€å¼ éœ€è¦æ··åˆçš„å›¾ç‰‡æä¾›åä¸ªç¼“å­˜æ—¶ï¼Œå¯ä»¥è®¤ä¸ºæä¾›äº†è¶³å¤Ÿçš„éšæœºæ€§ï¼Œè€Œ[Mosaic](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)å¢å¼ºæ˜¯å››å¼ å›¾æ··åˆï¼Œå› æ­¤cacheæ•°é‡é»˜è®¤$N=40$ï¼ŒåŒç†[MixUp](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)çš„cacheæ•°é‡é»˜è®¤ä¸º20ï¼ŒTinyæ¨¡å‹éœ€è¦æ›´ç¨³å®šçš„è®­ç»ƒæ¡ä»¶ï¼Œå› æ­¤å…¶cacheæ•°é‡ä¹Ÿä¸ºå…¶ä½™è§„æ ¼æ¨¡å‹çš„ä¸€åŠï¼ˆ[MixUp](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ä¸º10ï¼Œ[Mosaic](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ä¸º20ï¼‰ã€‚

ğŸ‘‰**Two-stage training.**

ä¸ºäº†é™ä½strongæ•°æ®å¢å¼ºæ‰€å¸¦æ¥çš„â€œå™ªå£°â€æ ·æœ¬çš„å‰¯ä½œç”¨ï¼Œ[YOLOX](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)æ¢ç´¢äº†ä¸€ç§two-stageçš„è®­ç»ƒç­–ç•¥ï¼Œåœ¨ç¬¬ä¸€ä¸ªstageä¸­ï¼Œä½¿ç”¨strongæ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬[Mosaic](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ã€[MixUp](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)ã€éšæœºæ—‹è½¬å’Œ[shear](http://shichaoxin.com/2023/07/03/è®ºæ–‡é˜…è¯»-FlowNet-Learning-Optical-Flow-with-Convolutional-Networks/#42flying-chairs)ï¼›åœ¨ç¬¬äºŒä¸ªstageä¸­ï¼Œä½¿ç”¨weakæ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬éšæœºresizeå’Œflipã€‚ä½†ç”±äºåœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µä½¿ç”¨äº†éšæœºæ—‹è½¬å’Œ[shear](http://shichaoxin.com/2023/07/03/è®ºæ–‡é˜…è¯»-FlowNet-Learning-Optical-Flow-with-Convolutional-Networks/#42flying-chairs)ï¼Œè¿™ä¼šå¯¼è‡´è¾“å…¥å’Œå˜æ¢åçš„æ ‡æ³¨æ¡†äº§ç”Ÿé”™ä½ï¼Œå› æ­¤[YOLOX](http://shichaoxin.com/2024/01/19/è®ºæ–‡é˜…è¯»-YOLOX-Exceeding-YOLO-Series-in-2021/)åœ¨ç¬¬äºŒä¸ªstageå¼•å…¥é¢å¤–çš„L1 lossæ¥çº æ­£regåˆ†æ”¯çš„æ€§èƒ½ã€‚ä¸ºäº†è§£è€¦æ•°æ®å¢å¼ºå’ŒæŸå¤±å‡½æ•°ï¼Œä½¿æ•°æ®å¢å¼ºç­–ç•¥æ›´å…·æœ‰é€šç”¨æ€§ï¼Œåœ¨ç¬¬ä¸€ä¸ªstageï¼ˆå…±280ä¸ªepochï¼‰ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨éšæœºæ—‹è½¬å’Œ[shear](http://shichaoxin.com/2023/07/03/è®ºæ–‡é˜…è¯»-FlowNet-Learning-Optical-Flow-with-Convolutional-Networks/#42flying-chairs)ï¼Œä½†æˆ‘ä»¬å°†æ··åˆçš„å›¾ç‰‡æ•°é‡å¢åŠ è‡³8å¼ ï¼Œä»¥è¡¥å¿æ•°æ®å¢å¼ºçš„å¼ºåº¦ã€‚åœ¨ç¬¬äºŒä¸ªstageï¼ˆå…±20ä¸ªepochï¼‰ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†Large Scale Jitteringï¼ˆLSJï¼‰ã€‚ä¸ºäº†è®­ç»ƒç¨³å®šæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨[AdamWä¼˜åŒ–å™¨](http://shichaoxin.com/2020/03/19/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¹è¯¾-Adamä¼˜åŒ–ç®—æ³•/)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/9.png)

Standard Scale Jitteringï¼ˆSSJï¼‰ä¼šå¯¹å›¾åƒè¿›è¡Œresizeå’Œcropæ“ä½œï¼Œå…¶resizeçš„æ¯”ä¾‹ä¸º0.8~1.25ã€‚è€ŒLSJå¯¹åŸå§‹å›¾åƒresizeçš„æ¯”ä¾‹èŒƒå›´ä¼šæ›´å¤§ï¼š0.1~2.0ã€‚å¦‚æœresizeåçš„å›¾åƒå°äºåŸå§‹å›¾åƒï¼Œåˆ™ä¼šç”¨ç°è‰²åƒç´ è¿›è¡Œpaddingã€‚ä¸¤ç§scale jitteringæ–¹å¼éƒ½ä¼šä½¿ç”¨æ°´å¹³ç¿»è½¬ã€‚

è¿™é‡Œé™„ä¸Šå®˜æ–¹ç»™å‡ºçš„æ•°æ®å¢å¼ºæµç¨‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/10.png)

ç‰¹æ®Šæ³¨æ„ï¼šå¤§æ¨¡å‹M\L\Xä½¿ç”¨çš„æ˜¯LSJï¼ˆresizeèŒƒå›´ä¸º$[0.1,2.0]$ï¼‰ï¼Œè€Œå°æ¨¡å‹S\Tinyä½¿ç”¨çš„æ˜¯SSJï¼ˆresizeèŒƒå›´ä¸º$[0.5,2.0]$ï¼‰ã€‚

## 3.4.Extending to other tasks

ğŸ‘‰**Instance segmentation.**

>è¿™éƒ¨åˆ†çš„å…·ä½“å®ç°æ²¡å¤ªæ˜ç™½ï¼ŒæŒ‰ç…§åŸæ–‡ç¿»è¯‘è¿‡æ¥ã€‚

RTMDeté€šè¿‡ç®€å•çš„ä¿®æ”¹å°±å¯ä»¥è¿›è¡Œå®ä¾‹åˆ†å‰²ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºRTMDet-Insã€‚å¦‚Fig4æ‰€ç¤ºï¼Œåœ¨RTMDetçš„åŸºç¡€ä¸Šï¼Œæ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„åˆ†æ”¯ï¼Œè¿™ä¸ªåˆ†æ”¯åŒ…å«ä¸€ä¸ªkernel prediction headå’Œä¸€ä¸ªmask feature headï¼Œè¿™ç±»ä¼¼äºCondInstã€‚mask feature headä½¿ç”¨4ä¸ªå·ç§¯å±‚ä»multi-level featuresä¸­æå– mask featuresï¼Œé€šé“æ•°éƒ½æ˜¯8ã€‚kernel prediction headå¯¹æ¯ä¸ªå®ä¾‹é¢„æµ‹å¾—åˆ°ä¸€ä¸ª169ç»´çš„å‘é‡ï¼Œè¿™ä¸ªå‘é‡ä¼šè¢«åˆ†æˆ3ä¸ªåŠ¨æ€å·ç§¯æ ¸ï¼ˆé•¿åº¦åˆ†åˆ«ä¸º88ã€72å’Œ9ï¼‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥åˆ©ç”¨maskæ ‡æ³¨ä¸­å›ºæœ‰çš„å…ˆéªŒä¿¡æ¯ï¼Œæˆ‘ä»¬åœ¨è®¡ç®—åŠ¨æ€æ ‡ç­¾åˆ†é…æ—¶ä½¿ç”¨maskçš„è´¨å¿ƒï¼Œè€Œä¸æ˜¯boxçš„ä¸­å¿ƒã€‚ä½¿ç”¨[dice loss](http://shichaoxin.com/2023/08/01/è®ºæ–‡é˜…è¯»-V-Net-Fully-Convolutional-Neural-Networks-for-Volumetric-Medical-Image-Segmentation/#3dice-loss-layer)ã€‚

>CondInstï¼šZhi Tian, Chunhua Shen, and Hao Chen. Conditional convolutions for instance segmentation. In European conference on computer vision, pages 282â€“298. Springer, 2020.ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/11.png)

ğŸ‘‰**Rotated object detection.**

ç”±äºæ—‹è½¬ç›®æ ‡æ£€æµ‹å’Œå¸¸è§„ï¼ˆæ°´å¹³ï¼‰ç›®æ ‡æ£€æµ‹ä¹‹é—´å›ºæœ‰çš„ç›¸ä¼¼æ€§ï¼Œå°†RTMDeté€‚é…ä¸ºæ—‹è½¬ç›®æ ‡æ£€æµ‹å™¨ï¼ˆå³RTMDet-Rï¼‰åªéœ€è¦3æ­¥ï¼š

1. åœ¨regåˆ†æ”¯ä¸­æ·»åŠ $1 \times 1$å·ç§¯ç”¨äºé¢„æµ‹æ—‹è½¬è§’åº¦ã€‚
2. ä¿®æ”¹bounding box coderä»¥æ”¯æŒæ—‹è½¬boxã€‚
3. æŠŠ[GIoU loss](http://shichaoxin.com/2024/01/04/è®ºæ–‡é˜…è¯»-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection/)æ›¿æ¢ä¸ºæ—‹è½¬IoU lossã€‚

RTMDet-Rå…±äº«äº†RTMDetçš„å¤§éƒ¨åˆ†å‚æ•°ï¼Œå› æ­¤åœ¨é€šç”¨æ£€æµ‹æ•°æ®é›†ï¼ˆä¾‹å¦‚COCOæ•°æ®é›†ï¼‰ä¸Šé¢„è®­ç»ƒçš„RTMDetæ¨¡å‹æƒé‡å¯ä»¥ä½œä¸ºRTMDet-Rçš„åˆå§‹åŒ–ã€‚

# 4.Experiments

## 4.1.Implementation Details

ğŸ‘‰**Object detection and instance segmentation.**

æˆ‘ä»¬åœ¨COCOæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œè¯¥æ•°æ®é›†çš„train2017åŒ…å«118Kå¼ å›¾ç‰‡ï¼Œval2017åŒ…å«5Kå¼ å›¾ç‰‡ã€‚æˆ‘ä»¬åœ¨train2017ä¸Šè®­ç»ƒäº†300ä¸ªepochï¼Œåœ¨val2017ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚è¶…å‚è®¾ç½®è§è¡¨1ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/12.png)

æˆ‘ä»¬æ‰€æœ‰ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²çš„æ¨¡å‹éƒ½ä½¿ç”¨äº†8å—NVIDIA A100 GPUã€‚ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ä½¿ç”¨bbox APï¼Œå®ä¾‹åˆ†å‰²ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ä½¿ç”¨mask APã€‚

Flat-Cosineå°±æ˜¯åœ¨è®­ç»ƒçš„å‰åŠæ®µå…ˆä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œåœ¨è®­ç»ƒçš„ååŠæ®µå¼€å§‹æ‰§è¡Œ[cosine learning rate decay](http://shichaoxin.com/2022/09/22/è®ºæ–‡é˜…è¯»-AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE/#6b11fine-tuning)ã€‚

åœ¨ç›®æ ‡æ£€æµ‹çš„æµ‹è¯•é˜¶æ®µï¼Œæˆ‘ä»¬ç”¨0.001çš„é˜ˆå€¼ç­›é€‰bounding boxç”¨äºNMSï¼Œä¿ç•™æœ€é«˜çš„300ä¸ªboxç”¨äºéªŒè¯ã€‚è¿™å’Œ[YOLOv5](http://shichaoxin.com/2024/01/14/YOLOç³»åˆ—-YOLOv5/)ã€YOLOv6ã€YOLOv7æ˜¯ä¸€è‡´çš„ã€‚ä½†ä¸ºäº†åŠ å¿«æ¶ˆèå®éªŒï¼Œæˆ‘ä»¬æŠŠé˜ˆå€¼æé«˜åˆ°0.05ï¼Œåªä¿ç•™æœ€é«˜çš„100ä¸ªboxï¼Œè¿™å¯¼è‡´APä¸‹é™çº¦0.3%ã€‚

ğŸ‘‰**Rotated object detection.**

æˆ‘ä»¬åœ¨DOTAæ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬2.8Kå¼ èˆªç©ºå›¾åƒï¼Œå…±188Kä¸ªå®ä¾‹ï¼Œè¿™äº›å›¾åƒæ˜¯é€šè¿‡å…·æœ‰å¤šä¸ªåˆ†è¾¨ç‡çš„ä¸åŒä¼ æ„Ÿå™¨è·å¾—çš„ã€‚è¶…å‚æ•°è§è¡¨1ã€‚å¯¹äºsingle-scaleçš„è®­ç»ƒå’Œæµ‹è¯•ï¼Œæˆ‘ä»¬å°†åŸå§‹å›¾åƒè£å‰ªä¸º$1024 \times 1024$å¤§å°çš„patchï¼Œpatchä¹‹é—´ä¼šæœ‰256ä¸ªåƒç´ çš„é‡å ã€‚å¯¹äºmulti-scaleçš„è®­ç»ƒå’Œæµ‹è¯•ï¼ŒåŸå§‹å›¾åƒä¼šè¢«åˆ†åˆ«resizeåˆ°åŸæ¥çš„0.5ã€1.0å’Œ1.5å€ï¼Œç„¶åå†è£å‰ªä¸º$1024 \times 1024$çš„patchï¼Œpatchä¹‹é—´ä¼šæœ‰500ä¸ªåƒç´ çš„é‡å ã€‚å¤§éƒ¨åˆ†çš„æ—‹è½¬ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨ä¸€å—NVIDIA V100 GPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œåªæœ‰å¤§æ¨¡å‹ä½¿ç”¨äº†2å—NVIDIA V100 GPUã€‚å¯¹äºè¯„ä¼°æŒ‡æ ‡ï¼Œæˆ‘ä»¬é‡‡ç”¨å’ŒPASCAL VOC2007ä¸€æ ·çš„mAPè®¡ç®—ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜ä½¿ç”¨äº†æ—‹è½¬IoUè®¡ç®—ã€‚

ğŸ‘‰**Benchmark settings.**

æ‰€æœ‰æ¨¡å‹çš„latencyæµ‹è¯•éƒ½åŸºäºåŠæµ®ç‚¹ç²¾åº¦ï¼ˆFP16ï¼‰ã€ä¸€å—NVIDIA 3090 GPUã€TensorRT 8.4.3ã€cuDNN 8.2.0ã€‚æ¨ç†çš„batch sizeä¸º1ã€‚

## 4.2.Benchmark Results

**Object detection.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/13.png)

**Instance segmentation.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/14.png)

**Rotated object detection.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/15.png)

## 4.3.Ablation Study of Model Arhitecture

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/16.png)

ğŸ‘‰**Large kernel matters.**

å¯¹CSPNeXtBlockä¸­çš„kernelå¤§å°è¿›è¡Œæ¶ˆèå®éªŒï¼Œç»“æœè§Fig5(a)ã€‚

ğŸ‘‰**Balance of multiple feature scales.**

å¯¹backboneçš„stage1-4ä¸­çš„blockæ•°é‡è¿›è¡Œæ¶ˆèå®éªŒï¼Œç»“æœè§Fig5(b)ã€‚ä½¿ç”¨depth-wiseå·ç§¯å¢åŠ äº†ç½‘ç»œæ·±åº¦ï¼Œé™ä½äº†æ¨ç†é€Ÿåº¦ã€‚å› æ­¤æˆ‘ä»¬æŠŠblockæ•°ä»3-9-9-3é™åˆ°3-6-6-3ï¼Œè¿™ä¸€ä¿®æ”¹ä½¿latencyé™ä½äº†20%ï¼Œä½†è¿™ä¹Ÿå¯¼è‡´APä¸‹é™äº†0.5%ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡CAï¼ˆChannel Attentionï¼‰è¿›è¡Œäº†è¡¥å¿ã€‚è¿™æ ·ä¸‹æ¥ï¼Œç›¸æ¯”3-9-9-3ï¼Œ3-6-6-3 w/CAåªé™ä½äº†0.1%çš„APï¼Œä½†latencyæœ‰äº†7%çš„æå‡ã€‚

CAæ¨¡å—ä¸º1å±‚`AdaptiveAvgPool2d`+1å±‚$1 \times 1$çš„`Conv2d`+`Hardsigmoid`æ¿€æ´»å‡½æ•°ã€‚

`Hardsigmoid`æ¿€æ´»å‡½æ•°çš„å®šä¹‰å’Œå›¾åƒï¼š

$$\text{Hardsigmoid}(x) = \begin{cases} 0 & \text{if}\  x \leqslant -3, \\ 1 &  \text{if}\  x \geqslant +3, \\ \frac{x}{6} + \frac{1}{2} & \text{otherwise} \end{cases}$$

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/17.png)

>ä¸ªäººç†è§£ï¼šå‡è®¾CAçš„è¾“å…¥ç»´åº¦ä¸º$w\times h \times channel$ã€‚`AdaptiveAvgPool2d`çš„output\_size=1ï¼Œè¿™å°±ç›¸å½“äº`AdaptiveAvgPool2d`è¾“å‡ºçš„å¤§å°ä¸º$1\times 1 \times channel$ï¼Œç»è¿‡åé¢çš„`Conv2d`å’Œ`Hardsigmoid`ä¹‹åç»´åº¦ä¾æ—§æ˜¯$1 \times 1 \times channel$ï¼Œç„¶åå’ŒCAçš„è¾“å…¥ç›¸ä¹˜ï¼Œä½¿å¾—CAçš„è¾“å‡ºå¤§å°è¿˜æ˜¯$w\times h \times channel$ã€‚

ğŸ‘‰**Balance of backbone and neck.**

backboneå’Œneckçš„å‚æ•°å æ¯”çš„æ¶ˆèå®éªŒè§Fig5(c)ã€‚

ğŸ‘‰**Detection head.**

å¯¹äºheadï¼Œæˆ‘ä»¬æµ‹è¯•äº†ä¸åŒçš„å‚æ•°å…±äº«ç­–ç•¥ï¼Œè§Fig5(d)ã€‚

## 4.4.Ablation Study of Training Strategy

ğŸ‘‰**Label assignment.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/18.png)

ğŸ‘‰**Data augmentation.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/19.png)

è¡¨7(a)ä¸­ï¼Œ1st stageè¡¨ç¤ºå‰280ä¸ªepochï¼Œ2nd stageè¡¨ç¤ºå20ä¸ªepochã€‚

ğŸ‘‰**Optimization strategy.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/20.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/21.png)

æœ€åä¸€æ¡çš„é¢„è®­ç»ƒä½¿ç”¨ImageNetã€‚

## 4.5.Step-by-step Results

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/22.png)

# 5.Conclusion

RTMDetåœ¨å·¥ä¸šçº§åº”ç”¨ä¸­å±•ç¤ºäº†ç²¾åº¦å’Œé€Ÿåº¦ä¹‹é—´çš„ä¼˜è¶Šå¹³è¡¡ã€‚

# 6.A.Appendix

## 6.1.A.1.Benchmark Results

ğŸ‘‰**Comparison with PPYOLOE-R.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/23.png)

RTMDet-Rçš„ä»£ç å’Œæ¨¡å‹å¯è§MMRotateã€‚

>MMRotateï¼šYue Zhou, Xue Yang, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang, Xingzhao Liu, Junchi Yan, Chengqi Lyu, Wenwei Zhang, and Kai Chen. Mmrotate: A rotated object detection benchmark using pytorch. In Proceedings of the 30th ACM International Conference on Multimedia, page 7331â€“7334, 2022.ã€‚

ğŸ‘‰**Results on DOTA-v1.5.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/24.png)

ğŸ‘‰**Results on HRSC2016.**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RTMDet/25.png)

# 7.åŸæ–‡é“¾æ¥

ğŸ‘½[RTMDetï¼šAn Empirical Study of Designing Real-Time Object Detectors](https://github.com/x-jeff/AI_Papers/blob/master/RTMDetï¼šAn%20Empirical%20Study%20of%20Designing%20Real-Time%20Object%20Detectors.pdf)

# 8.å‚è€ƒèµ„æ–™

1. [æ·±åº¦å¯åˆ†ç¦»å·ç§¯](https://zhuanlan.zhihu.com/p/92134485)
2. [ã€OpenMMLab 2.0 ç³»åˆ—ç›´æ’­ã€‘RTMDet](https://www.bilibili.com/video/BV1e841147GD/?vd_source=896374db59ca8f208a0bb9f453a24c25)