---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘Fast R-CNN
subtitle:   Fast R-CNN
date:       2022-03-07
author:     x-jeff
header-img: blogimg/20220307.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

æœ€è¿‘ï¼Œæ·±åº¦å·ç§¯ç½‘ç»œæ˜¾è‘—æå‡äº†å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å‡†ç¡®åº¦ã€‚ç›¸æ¯”å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œç›®æ ‡æ£€æµ‹ä»»åŠ¡æ›´å…·æŒ‘æˆ˜æ€§ä¸”è§£å†³åŠæ³•æ›´ä¸ºå¤æ‚ã€‚å› æ­¤ï¼Œç›®å‰multi-stageçš„æ–¹æ³•é€Ÿåº¦éƒ½å¾ˆæ…¢å¹¶ä¸”æ¨¡å‹ä¸ç®€æ´ã€‚

æ–¹æ³•å¤æ‚æ˜¯å› ä¸ºè¦æ±‚ç²¾å‡†å®šä½ç›®æ ‡ï¼Œè¿™é‡Œå­˜åœ¨ä¸¤ä¸ªä¸»è¦çš„æŒ‘æˆ˜ã€‚ä¸€ï¼Œæœ‰å¤§é‡çš„å¤‡é€‰åŒºåŸŸï¼ˆproposalsï¼‰éœ€è¦å¤„ç†ã€‚äºŒï¼Œè¿™äº›proposalsåªæ˜¯ä¸€ä¸ªç²—ç•¥çš„å®šä½ï¼Œæƒ³å¾—åˆ°ç²¾å‡†çš„å®šä½è¿˜éœ€è¿›ä¸€æ­¥refineã€‚å¾ˆéš¾åŒæ—¶é¡¾å…¨é€Ÿåº¦ã€å‡†ç¡®åº¦ã€æ¨¡å‹ç®€æ´ç¨‹åº¦ã€‚

æˆ‘ä»¬æå‡ºä¸€ç§single-stageçš„è®­ç»ƒç®—æ³•æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚

>è¿™é‡Œçš„stageæŒ‡çš„æ˜¯è®­ç»ƒè¿‡ç¨‹ã€‚

æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è®­ç»ƒææ·±çš„æ£€æµ‹ç½‘ç»œï¼Œæ¯”[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)å¿«9å€ï¼Œæ¯”[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)å¿«3å€ã€‚æ¨ç†ä¸€å¼ å›¾åƒä»…éœ€è¦0.3sï¼ˆåŸºäºNvidia K40 GPU/875MHzï¼Œä¸åŒ…æ‹¬äº§ç”Ÿobject proposalçš„æ—¶é—´ï¼‰ï¼Œå¹¶ä¸”åœ¨PASCAL VOC 2012å¾—åˆ°äº†å¾ˆé«˜çš„å‡†ç¡®ç‡mAP=66%ï¼Œå‡»è´¥äº†[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)çš„62%ã€‚

## 1.1.RCNN and SPPnet

è™½ç„¶[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å–å¾—äº†ä¸é”™çš„å‡†ç¡®ç‡ï¼Œä½†å…¶ä»æœ‰ä¸€äº›æ˜æ˜¾çš„ç¼ºç‚¹ï¼š

1. multi-stageçš„è®­ç»ƒæµç¨‹ã€‚[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)çš„è®­ç»ƒä¸€å…±åˆ†ä¸ºä¸‰ä¸ªstageï¼š1ï¼‰fine-tuneå·ç§¯ç½‘ç»œéƒ¨åˆ†ï¼›2ï¼‰SVMåˆ†ç±»å™¨çš„è®­ç»ƒï¼›3ï¼‰bounding-boxå›å½’ã€‚
2. è®­ç»ƒæˆæœ¬é«˜ï¼ˆå æ®å¤§é‡ç©ºé—´å’Œæ—¶é—´ï¼‰ã€‚å¯¹äºSVMå’ŒBBå›å½’çš„è®­ç»ƒï¼Œéœ€è¦é€šè¿‡å·ç§¯ç½‘ç»œè®¡ç®—æ¯å¹…å›¾åƒä¸­æ¯ä¸ªobject proposalçš„featureï¼Œå¹¶å†™å…¥diskã€‚å¦‚æœå·ç§¯ç½‘ç»œéƒ¨åˆ†ä½¿ç”¨[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œåˆ™åœ¨VOC07è®­ç»ƒéªŒè¯é›†ï¼ˆ5kå¼ å›¾åƒï¼‰ä¸Šè®­ç»ƒéœ€è¦2.5å¤©ï¼ˆ2.5 GPU-daysï¼‰ã€‚è¿™äº›featureéœ€è¦æ•°ç™¾GBçš„å­˜å‚¨ç©ºé—´ã€‚
3. æ¨ç†é€Ÿåº¦æ…¢ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œéœ€è¦è®¡ç®—æ¯å¼ æµ‹è¯•å›¾åƒä¸­æ¯ä¸ªobject proposalçš„featureã€‚åœ¨GPUä¸Šï¼Œå¦‚æœå·ç§¯ç½‘ç»œéƒ¨åˆ†ä½¿ç”¨[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œåˆ™æ£€æµ‹ä¸€å¼ å›¾åƒéœ€è¦47ç§’ã€‚

[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)æ…¢ä¸»è¦æ˜¯å› ä¸ºå¯¹æ¯ä¸ªobject proposaléƒ½è¦è·‘ä¸€éç½‘ç»œã€‚[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)æ”¹è¿›äº†è¿™ä¸€é—®é¢˜ï¼Œç›¸æ¯”[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)ï¼Œå…¶å°†æ¨ç†è€—æ—¶é™ä½äº†10åˆ°100å€ï¼Œè®­ç»ƒè€—æ—¶ä¹Ÿé™ä½äº†3å€ã€‚ä½†æ˜¯[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)å’Œ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)çš„è®­ç»ƒæµç¨‹ä¸€æ ·ï¼Œåªä¸è¿‡[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)åªfine-tuneäº†FCå±‚ã€‚æ­¤å¤–ï¼Œå›ºå®šçš„å·ç§¯å±‚å±‚æ•°ä¹Ÿé™åˆ¶äº†æ¨¡å‹æ€§èƒ½çš„è¿›ä¸€æ­¥æå‡ã€‚

## 1.2.Contributions

æˆ‘ä»¬æå‡ºä¸€ç§æ–°çš„**è®­ç»ƒ**ç®—æ³•ä»¥è§£å†³[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)çš„ç¼ºç‚¹ï¼Œä¸ä½†å¯ä»¥æå‡é€Ÿåº¦ï¼Œä¹Ÿå¯ä»¥æå‡ç²¾åº¦ã€‚æˆ‘ä»¬å°†è¿™ç§æ–¹æ³•ç§°ä¸ºFast R-CNNï¼Œå¯ä»¥æ›´å¿«çš„è®­ç»ƒä»¥åŠæ¨ç†ã€‚Fast R-CNNæœ‰ä»¥ä¸‹å‡ ç‚¹ä¼˜åŠ¿ï¼š

1. æ¯”[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)æ›´é«˜çš„ç²¾åº¦ï¼ˆå³mAPï¼‰ã€‚
2. single-stageçš„è®­ç»ƒï¼Œä½¿ç”¨multi-task lossã€‚
3. è®­ç»ƒå¯æ›´æ–°ç½‘ç»œçš„æ‰€æœ‰å±‚ã€‚
4. ä¸éœ€è¦å†…å­˜æ¥å­˜å‚¨featureã€‚

Fast R-CNN githubåœ°å€ï¼š[https://github.com/rbgirshick/fast-rcnn](https://github.com/rbgirshick/fast-rcnn)ã€‚

# 2.Fast R-CNN architecture and training

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/1.png)

Fast R-CNNçš„ç»“æ„è§Fig1ã€‚è¾“å…¥æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯å…¨å›¾ï¼Œå¦ä¸€ä¸ªæ˜¯ä¸€ç»„object proposalã€‚é¦–å…ˆï¼Œå…¨å›¾ç»è¿‡å·ç§¯ç½‘ç»œå¾—åˆ°feature mapã€‚ç„¶åï¼Œæ˜ å°„å¾—åˆ°object proposalåœ¨è¯¥feature mapä¸Šå¯¹åº”çš„åŒºåŸŸï¼Œå³RoIã€‚ç„¶åä»…å°†RoIé€šè¿‡RoI pooling layerå¾—åˆ°ä¸€ä¸ªå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œè¯¥ç‰¹å¾å‘é‡é€šè¿‡å‡ ä¸ªFCå±‚åæµå‘ä¸¤ä¸ªè¾“å‡ºåˆ†æ”¯ï¼šä¸€ä¸ªå°±æ˜¯softmaxå‡½æ•°ï¼Œä¸€å…±æœ‰K+1ï¼ˆèƒŒæ™¯ï¼‰ä¸ªç±»åˆ«ï¼›å¦ä¸€ä¸ªåˆ†æ”¯è¾“å‡º4Kä¸ªæ•°å€¼ï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”4ä¸ªæ•°å€¼ï¼Œè¿™4ä¸ªæ•°å€¼ç”¨äºå¹³ç§»å’Œç¼©æ”¾bounding boxã€‚

## 2.1.The RoI pooling layer

RoI pooling layeré€šè¿‡max poolingå°†RoIç»Ÿä¸€å˜ä¸º$H \times W$ï¼ˆä¾‹å¦‚$7\times 7$ï¼‰ï¼ŒHå’ŒWä¸ºè¶…å‚æ•°ã€‚å¯¹äºä»»ä½•RoIæ¥è¯´ï¼ŒHå’ŒWæ˜¯ç‹¬ç«‹çš„ã€‚å¯¹äºæ¯ä¸ªRoIï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ç»„tuple $(r,c,h,w)$ï¼Œ$(r,c)$ä¸ºå·¦ä¸Šè§’ï¼Œ$(h,w)$ä¸ºé«˜å’Œå®½ã€‚

å…¶å®RoI pooling layerå°±æ˜¯[spatial pyramid pooling layer](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)çš„ç®€åŒ–ç‰ˆã€‚

## 2.2.Initializing from pretrained networks

æˆ‘ä»¬å®éªŒäº†3ä¸ªä½¿ç”¨ImageNeté¢„è®­ç»ƒè¿‡çš„ç½‘ç»œï¼Œæ¯ä¸ªç½‘ç»œéƒ½æœ‰5ä¸ªmax poolingå±‚+5~13ä¸ªå·ç§¯å±‚ï¼ˆè¯¦è§ç¬¬4.1éƒ¨åˆ†ï¼‰ã€‚æŒ‰ç…§ä»¥ä¸‹ä¸‰æ­¥å°†é¢„è®­ç»ƒå¥½çš„ç½‘ç»œè½¬å˜æˆFast R-CNNã€‚

ç¬¬ä¸€æ­¥ï¼šå°†æœ€åä¸€ä¸ªmax pooling layeræ›¿æ¢ä¸ºRoI pooling layerï¼Œå¹¶è®¾ç½®å¥½Hå’ŒWï¼ˆæ¯”å¦‚å¯¹äº[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œæˆ‘ä»¬è®¾ç½®$H=W=7$ï¼‰ã€‚

ç¬¬äºŒæ­¥ï¼šå°†æœ€åä¸€ä¸ªFCå±‚å’Œsoftmaxè¾“å‡ºå±‚æ›¿æ¢ä¸ºä¹‹å‰æåˆ°çš„ä¸¤ä¸ªè¾“å‡ºåˆ†æ”¯ç»“æ„ã€‚

ç¬¬ä¸‰æ­¥ï¼šå°†ç½‘ç»œçš„è¾“å…¥æ”¹ä¸ºä¸¤éƒ¨åˆ†ï¼šä¸€ç»„å›¾åƒå’Œè¿™äº›å›¾åƒå¯¹åº”çš„ä¸€ç»„RoIã€‚

## 2.3.Fine-tuning for detection

åœ¨[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)è®­ç»ƒçš„fine-tuneè¿™ä¸€æ­¥ï¼ˆ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ä½¿ç”¨å’Œ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)ä¸€æ ·çš„fine-tuneç­–ç•¥ï¼‰ï¼Œmini-batch size=128ï¼Œè¿™128ä¸ªç»è¿‡warpåçš„region proposalå¯èƒ½æ¥è‡ªå¤šå¼ ä¸åŒçš„å›¾åƒï¼Œç”šè‡³æ¥è‡ª128å¼ ä¸åŒçš„å›¾åƒã€‚è€ŒFast R-CNNç›¸å½“äºæ¯æ¬¡é€‰æ‹©Nå¼ å›¾åƒï¼Œæ¯ä¸ªå›¾åƒå†é€‰æ‹©R/Nä¸ªRoIï¼ˆç›¸å½“äºmini-batch size=Rï¼‰ã€‚ä¾‹å¦‚è®¾ç½®N=2,R=128ï¼Œè¿™ç›¸å½“äºæ˜¯åŠ é€Ÿäº†64å€ã€‚è¿™æ ·åšè™½ç„¶å¤§é‡RoIæ¥è‡ªä¸€å¼ å›¾åƒï¼Œä½†æ˜¯å¹¶æ²¡æœ‰é™ä½è®­ç»ƒæ”¶æ•›é€Ÿåº¦ã€‚

>ä¸ªäººç†è§£ï¼šFast R-CNNè¿™æ ·åšèƒ½åŠ é€Ÿè®­ç»ƒçš„åŸå› åœ¨äºæœ‰R/Nä¸ªRoIå¯ä»¥å…±äº«å‰å‘ä¼ æ’­çš„è®¡ç®—ã€‚ä¹Ÿå°±æ˜¯è¯´æå–feature mapçš„å·ç§¯ç½‘ç»œéƒ¨åˆ†ï¼ŒåŒä¸€å›¾åƒçš„R/Nä¸ªRoIå…±ç”¨ä¸€å¼ feature mapå³å¯ï¼Œåªç”¨ç®—ä¸€éã€‚è€Œå¯¹äº[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)æ¥è¯´ï¼Œæ¯ä¸ªregion proposalåœ¨å‰å‘ä¼ æ’­æ—¶éƒ½éœ€è¦è®¡ç®—ä¸€éfeature mapã€‚

æ­¤å¤–ï¼ŒFast R-CNNå¯ä»¥æŠŠ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)çš„3ä¸ªè®­ç»ƒé˜¶æ®µæ”¾åœ¨ä¸€å—ä¸€èµ·fine-tuneã€‚

**Multi-task loss.**

Fast R-CNNæœ‰ä¸¤ä¸ªsibling output layersã€‚ç¬¬ä¸€ä¸ªoutputæ˜¯softmaxå‡½æ•°ï¼Œä¸ºæ¯ä¸ªRoIå½’å±äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼š$p=(p_0,â€¦,p_K)$ã€‚ç¬¬äºŒä¸ªoutputæ˜¯bounding-boxçš„offsetï¼Œé’ˆå¯¹æ¯ä¸ªç±»åˆ«éƒ½ä¼šæœ‰ä¸ªoffsetï¼š$t^k=(t_x^k,t_y^k,t_w^k,t_h^k)$ã€‚$t^k$çš„å®šä¹‰å’Œ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)ä¸­ä¿æŒä¸€è‡´ã€‚

æ¯ä¸ªRoIéƒ½æœ‰ä¸€ä¸ªGTç±»åˆ«$u$å’ŒGT bounding-box $v$ã€‚æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªmulti-taskçš„loss $L$ï¼Œç»“åˆç±»åˆ«åˆ†ç±»å’Œbounding-boxå›å½’ï¼š

$$L(p,u,t^u,v)=L_{cls}(p,u) + \lambda [u \geqslant 1] L_{loc} (t^u,v) \tag{1}$$

ç¬¬ä¸€ä¸ªtaskçš„lossï¼š

$$L_{cls}(p,u)=-\log p_u$$

å¯¹äºç¬¬äºŒä¸ªtaskçš„lossï¼š$L_{loc}$ã€‚$v$æ˜¯GT bounding boxï¼š$v=(v_x,v_y,v_w,v_h)$ï¼Œé¢„æµ‹çš„bounding boxï¼š$t^u=(t^u_x,t^u_y,t^u_w,t^u_h)$ã€‚å½“$u â‰¥ 1$æ—¶ï¼Œ$[ u â‰¥ 1]=1$ï¼Œå¦åˆ™$[ u â‰¥ 1]=0$ã€‚å› ä¸º$u=0$æ—¶å…¶ç±»åˆ«ä¸ºèƒŒæ™¯ï¼Œæ­¤æ—¶ï¼Œ$L_{loc}$å¯ä»¥å¿½ç•¥ã€‚$L_{loc}$è®¡ç®—è§ä¸‹ï¼š

$$L_{loc} (t^u,v)=\sum_{i \in \{x,y,w,h\}} smooth_{L_1}(t^u_i-v_i) \tag{2}$$

å…¶ä¸­ï¼Œ

$$smooth_{L_1}(x) = \begin{cases} 0.5x^2, & if \  \lvert x \rvert < 1 \\ \lvert x \rvert-0.5, & otherwise \end{cases} \tag{3}$$

å¼ï¼ˆ1ï¼‰å¼•å…¥äº†è¶…å‚æ•°$\lambda$æ¥å¹³è¡¡ä¸¤ä¸ªlossã€‚æˆ‘ä»¬å°†$v_i$å½’ä¸€åŒ–è‡³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚æ‰€æœ‰çš„å®éªŒéƒ½ä½¿ç”¨$\lambda = 1$ã€‚

**Mini-batch sampling.**

ä¸€ä¸ªbatché‡Œæœ‰128ä¸ªRoIï¼Œå…¶ä¸­32ä¸ªä¸ºæ­£æ ·æœ¬ï¼ˆå’ŒGTçš„IoUå¤§äºç­‰äº0.5ï¼‰ï¼Œ96ä¸ªä¸ºè´Ÿæ ·æœ¬ï¼ˆå’ŒGTçš„IoUæ»¡è¶³$[0.1,0.5)$ï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå›¾åƒæœ‰50%çš„å‡ ç‡è¢«æ°´å¹³ç¿»è½¬ã€‚æ²¡æœ‰ä½¿ç”¨å…¶ä»–çš„æ•°æ®æ‰©å±•ã€‚

**Back-propagation through RoI pooling layers.**

RoI pooling layersçš„åå‘ä¼ æ’­è®¡ç®—æ–¹å¼ï¼Œåœ¨æ­¤ä¸å†èµ˜è¿°ã€‚

**SGD hyper-parameters.**

ç”¨äºsoftmaxåˆ†ç±»çš„FCå±‚ä½¿ç”¨å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º0.01çš„é«˜æ–¯åˆ†å¸ƒæ¥åˆå§‹åŒ–æƒå€¼ï¼›ç”¨äºbounding-boxå›å½’çš„FCå±‚ä½¿ç”¨å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º0.001çš„é«˜æ–¯åˆ†å¸ƒæ¥åˆå§‹åŒ–æƒå€¼ã€‚åç½®é¡¹å‡è¢«åˆå§‹åŒ–ä¸º0ã€‚å…¨å±€å­¦ä¹ ç‡ä¸º0.001ã€‚åœ¨VOC07å’ŒVOC12çš„trainvalæ•°æ®é›†ä¸Šè®­ç»ƒäº†30kæ¬¡çš„mini-batchè¿­ä»£ï¼Œç„¶åå°†å­¦ä¹ ç‡é™ä¸º0.0001ï¼Œå†è®­ç»ƒ10kæ¬¡è¿­ä»£ã€‚å¦‚æœåœ¨æ›´å¤§çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œæˆ‘ä»¬ä¼šè¿­ä»£æ›´å¤šæ¬¡æ•°ã€‚[momentum](http://shichaoxin.com/2020/03/05/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸ƒè¯¾-Momentumæ¢¯åº¦ä¸‹é™æ³•/)=0.9ï¼Œ[decay](http://shichaoxin.com/2020/02/01/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬åä¸€è¯¾-æ­£åˆ™åŒ–/#314l1æ­£åˆ™åŒ–å’Œl2æ­£åˆ™åŒ–çš„åŒºåˆ«)=0.0005ã€‚

## 2.4.Scale invariance

ä½¿ç”¨å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ä¸€æ ·çš„single-size trainingå’Œmulti-size trainingã€‚

# 3.Fast R-CNN detection

æ¨ç†è¿‡ç¨‹ç›¸å½“äºæ˜¯ä¸€æ¬¡å‰å‘ä¼ æ’­çš„è¿‡ç¨‹ã€‚è¾“å…¥ä¸ºä¸€å¼ å›¾åƒ+Rä¸ªobject proposalã€‚æ¨ç†é˜¶æ®µï¼ŒRå¤§çº¦æ˜¯2000ï¼Œå°½ç®¡æˆ‘ä»¬ä¹Ÿå¯èƒ½å°è¯•æ›´å¤§çš„å€¼ï¼ˆæ¯”å¦‚R=45kï¼‰ã€‚å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ä¸€æ ·ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨image pyramidæ—¶ï¼Œæˆ‘ä»¬ä¼šå°†å›¾åƒç¼©æ”¾åˆ°æŸä¸€ç‰¹å®šæ¯”ä¾‹ä½¿å¾—RoIçš„å¤§å°æ¥è¿‘äº$224 \times 224$ã€‚
å’Œ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)ä¸€æ ·ï¼Œå¯¹å¾—åˆ°çš„ç»“æœè¿›è¡Œ[NMS](http://shichaoxin.com/2020/09/06/æ·±åº¦å­¦ä¹ åŸºç¡€-ç¬¬ä¸‰åå››è¯¾-YOLOç®—æ³•/#3éæå¤§å€¼æŠ‘åˆ¶)ã€‚

## 3.1.Truncated SVD for faster detection

å¯¹äºå›¾åƒåˆ†ç±»ä»»åŠ¡æ¥è¯´ï¼ŒFCå±‚çš„è®¡ç®—é‡è¿œå°äºå·ç§¯å±‚ã€‚ä½†æ˜¯å¯¹äºæ£€æµ‹ä»»åŠ¡æ¥è¯´ï¼Œè®¡ç®—å¤§é‡çš„RoIä½¿å¾—FCå±‚çš„è®¡ç®—å æ®äº†æ¨ç†æ—¶é—´çš„ä¸€åŠå·¦å³ï¼Œè§Fig2ã€‚

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/2.png)

ä½¿ç”¨truncated SVDå¯ä»¥å¾ˆå®¹æ˜“çš„åŠ é€Ÿå¤§å‹FCå±‚ã€‚å‡è®¾æƒé‡çŸ©é˜µå¤§å°ä¸º$u\times v$ï¼Œå¯¹å…¶è¿›è¡Œæˆªæ–­å¥‡å¼‚å€¼åˆ†è§£ï¼š

$$W \approx U \Sigma_t V^T \tag{5}$$

å…¶ä¸­ï¼Œ$U$ä¸º$u\times t$çš„çŸ©é˜µï¼Œ$\Sigma_t$ä¸º$t\times t$çš„çŸ©é˜µï¼Œ$V^T$ä¸º$v\times t$çš„çŸ©é˜µã€‚

>å¥‡å¼‚å€¼åˆ†è§£è¯·è§ï¼š[ã€æ•°å­¦åŸºç¡€ã€‘ç¬¬åä¸ƒè¯¾ï¼šå¥‡å¼‚å€¼åˆ†è§£](http://shichaoxin.com/2020/11/24/æ•°å­¦åŸºç¡€-ç¬¬åä¸ƒè¯¾-å¥‡å¼‚å€¼åˆ†è§£/)ã€‚truncated SVDç”¨æœ€å¤§çš„$t$ä¸ªå¥‡å¼‚å€¼å’Œå¯¹åº”çš„å·¦å³å¥‡å¼‚å‘é‡æ¥è¿‘ä¼¼æè¿°çŸ©é˜µ$W$ã€‚

åˆ†è§£å‰çš„$W$çš„å‚æ•°æ•°é‡ä¸º$uv$ï¼Œåˆ†è§£åä¸‰ä¸ªçŸ©é˜µåŠ èµ·æ¥çš„å‚æ•°æ•°é‡ä¸º$t(u+v)$ã€‚åªè¦$t$å°äº$min(u,v)$ï¼Œé€šè¿‡truncated SVDå°±èƒ½å®ç°å‚æ•°çš„å‡å°‘ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†æƒé‡çŸ©é˜µä¸º$W$çš„FCå±‚æ‹†æˆä¸¤ä¸ªç›¸è¿çš„FCå±‚ï¼Œè¿™ä¸¤å±‚ä¹‹é—´ä¸ä½¿ç”¨éçº¿æ€§å…³ç³»ã€‚å…¶ä¸­ï¼Œç¬¬ä¸€å±‚çš„æƒé‡çŸ©é˜µä¸º$\Sigma_t V^T$ï¼ˆä¸ä½¿ç”¨åç½®é¡¹ï¼‰ï¼Œç¬¬äºŒå±‚çš„æƒé‡çŸ©é˜µä¸º$U$ï¼ˆç»§æ‰¿æ‹†åˆ†å‰çš„åç½®é¡¹ï¼‰ï¼Œç¤ºæ„å›¾è§ä¸‹ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/3.png)

è¿™ä¸ªå‹ç¼©æ–¹æ³•å¾ˆå¥½çš„æå‡äº†æ£€æµ‹é€Ÿåº¦ã€‚

>ä¸ªäººç†è§£ï¼šè¿™ä¸ªæ€æƒ³ç±»ä¼¼äº[Inceptionæ¨¡å—](http://shichaoxin.com/2021/06/01/è®ºæ–‡é˜…è¯»-Going-deeper-with-convolutions/)ä¸­å¯¹$1\times 1$å·ç§¯çš„ä½¿ç”¨ã€‚

# 4.Main results

ä¸‰ä¸ªä¸»è¦çš„æˆæœï¼š

1. åœ¨VOC07,2010,2012ä¸Šå–å¾—SOTAçš„mAPã€‚
2. ç›¸æ¯”[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ï¼Œæ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†ã€‚
3. ä½¿ç”¨[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)å¹¶å¯¹å·ç§¯å±‚è¿›è¡Œfine-tuneæå‡äº†mAPã€‚

## 4.1.Experimental setup

æˆ‘ä»¬åœ¨çº¿ä¸Šè·å–äº†3ä¸ªå·²ç»ä½¿ç”¨ImageNeté¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆè·å–åœ°å€ï¼š[https://github.com/BVLC/caffe/wiki/Model-Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)ï¼‰ã€‚ç¬¬ä¸€ä¸ªæ˜¯CaffeNetï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºSï¼ˆè¯‘ä¸ºsmallï¼‰ã€‚ç¬¬äºŒä¸ªæ˜¯VGG_CNN_M_1024ï¼Œå’Œæ¨¡å‹Sæ·±åº¦ä¸€æ ·ï¼Œä½†æ˜¯æ›´å®½ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºMï¼ˆè¯‘ä¸ºmediumï¼‰ã€‚ç¬¬ä¸‰ä¸ªæ˜¯[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºLï¼ˆè¯‘ä¸ºlargestï¼‰ã€‚è¿™ä¸€éƒ¨åˆ†æ‰€æœ‰çš„å®éªŒéƒ½ä½¿ç”¨single-scale traing and testingï¼ˆs=600ï¼Œè¯¦è§ç¬¬5.2éƒ¨åˆ†ï¼‰ã€‚

## 4.2.VOC 2010 and 2012 results

Fast R-CNNï¼ˆç®€ç§°ä¸ºFRCNï¼‰å’Œå…¶ä»–ä¼˜ç§€æ–¹æ³•çš„æ¯”è¾ƒè§è¡¨2ã€è¡¨3ï¼ˆæ•°æ®æ¥æºï¼š[http://host.robots.ox.ac.uk:8080/leaderboard](http://host.robots.ox.ac.uk:8080/leaderboard)ï¼‰ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/4.png)

## 4.3.VOC 2007 results

ç»“æœæ¯”è¾ƒè§è¡¨1ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/5.png)

è¡¨1ä¸­æ‰€æœ‰çš„æ–¹æ³•éƒ½ä½¿ç”¨ä¸€æ ·çš„ç»è¿‡é¢„è®­ç»ƒçš„[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼Œå¹¶ä¸”éƒ½ç”¨äº†bounding boxå›å½’ã€‚

## 4.4.Training and testing time

æ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ˜¯æˆ‘ä»¬ç¬¬äºŒä¸ªä¸»è¦æˆæœã€‚è¡¨4æ¯”è¾ƒäº†ä¸åŒæ–¹æ³•çš„è®­ç»ƒæ—¶é—´ï¼ˆå°æ—¶ï¼‰ã€æ¨ç†é€Ÿåº¦ï¼ˆæ¯å¼ å›¾åƒç”¨æ—¶å¤šå°‘ç§’ï¼‰ä»¥åŠåœ¨VOC07ä¸Šçš„mAPã€‚æ­¤å¤–ï¼ŒFast R-CNNå†…å­˜å ç”¨æ›´å°‘ï¼Œå› ä¸ºä¸å†éœ€è¦ç¼“å­˜featureã€‚

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/6.png)

truncated SVDä½¿æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä»…ç‰ºç‰²0.3%mAPçš„æƒ…å†µä¸‹ï¼Œé€Ÿåº¦æå‡äº†30%ï¼ˆè§Fig2ï¼‰ã€‚

## 4.5.Which layers to fine-tune?

[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)åªå¯¹FCå±‚è¿›è¡Œäº†fine-tuneï¼Œè¿™å¯èƒ½å¯¹è¾ƒæµ…çš„ç½‘ç»œæœ‰ç”¨ã€‚å¯¹äºè¾ƒæ·±çš„ç½‘ç»œï¼Œæˆ‘ä»¬è®¤ä¸ºfine-tuneå·ç§¯å±‚æ˜¯å¾ˆæœ‰å¿…è¦çš„ã€‚æˆ‘ä»¬ä»¥åŸºäº[VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)çš„Fast R-CNNä¸ºä¾‹ï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/7.png)

ä»è¡¨5ä¸­å¯ä»¥çœ‹å‡ºï¼Œfine-tuneå·ç§¯å±‚å¾ˆæ˜æ˜¾æå‡äº†mAPã€‚ä½†è¿™å¹¶ä¸æ„å‘³ç€æ‰€æœ‰çš„å·ç§¯å±‚éƒ½éœ€è¦è¢«fine-tuneã€‚å¯¹äºæ¨¡å‹Så’Œæ¨¡å‹Mï¼Œæˆ‘ä»¬å‘ç°fine-tune conv1å¹¶æ²¡æœ‰ä»€ä¹ˆç”¨ã€‚å¯¹äºè¡¨5ä¸­çš„æ¨¡å‹Lï¼Œæˆ‘ä»¬è®¤ä¸ºä»conv3\_1å¼€å§‹fine-tuneæ›´æœ‰æ„ä¹‰ï¼ˆå³fine-tuneäº†13ä¸ªå·ç§¯å±‚ä¸­çš„9ä¸ªï¼‰ï¼Œè™½ç„¶ä»conv2\_1å¼€å§‹fine-tuneçš„mAPæ›´é«˜ï¼Œä½†ä¸ºäº†0.3% mAPçš„æå‡å´æŸå¤±äº†è®­ç»ƒé€Ÿåº¦ï¼ˆ12.5h vs. 9.5hï¼‰ã€‚å› æ­¤ï¼Œæœ¬æ–‡ä¸­æ‰€æœ‰æ¨¡å‹Lçš„fine-tuneéƒ½æ˜¯ä»conv3\_1å¼€å§‹çš„ï¼Œè€Œæ¨¡å‹Så’Œæ¨¡å‹Mçš„fine-tuneåˆ™æ˜¯ä»conv2å¼€å§‹çš„ã€‚

# 5.Design evaluation

æˆ‘ä»¬åœ¨PASCAL VOC07æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

## 5.1.Does multi-task training help?

multi-taskä¸ä½†æ–¹ä¾¿ï¼ˆç»“æ„ç®€æ´ï¼‰ï¼Œè€Œä¸”ä¸¤ä¸ªtaskä¹‹é—´äº’ç›¸å½±å“ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥æå‡ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®ç‡ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€ç»“è®ºï¼Œæˆ‘ä»¬åšäº†å¦‚ä¸‹å®éªŒã€‚

ç»“æœè§è¡¨6ã€‚æ¨¡å‹S,M,Lä¸­çš„ç¬¬ä¸€åˆ—æˆ‘ä»¬åªä½¿ç”¨äº†åˆ†ç±»ä»£ä»·$L_{cls}$ï¼ˆå³$\lambda = 0$ï¼‰ï¼Œå¹¶ä¸”æ²¡æœ‰ä½¿ç”¨bounding boxå›å½’ã€‚ç¬¬äºŒåˆ—æˆ‘ä»¬ä½¿ç”¨äº†multi-task lossï¼ˆ$\lambda = 1$ï¼‰ï¼Œä½†æ˜¯åœ¨æ¨ç†é˜¶æ®µæ²¡æœ‰ä½¿ç”¨bounding boxå›å½’ï¼Œè¿™æ ·èƒ½æ›´å…¬å¹³çš„æ¯”è¾ƒç¬¬ä¸€åˆ—å’Œç¬¬äºŒåˆ—çš„åŒºåˆ«ã€‚

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/8.png)

é€šè¿‡æ¯”è¾ƒè¡¨6ä¸­æ¯ä¸ªæ¨¡å‹çš„ç¬¬ä¸€åˆ—å’Œç¬¬äºŒåˆ—å¯ä»¥çœ‹å‡ºï¼Œmulti-task lossçš„ä½¿ç”¨å°†mAPæå‡äº†0.8åˆ°1.1ä¸ç­‰ã€‚

è¡¨6ä¸­çš„stage-wise trainingæŒ‡çš„æ˜¯å…ˆåªç”¨$L_{cls}$ï¼ˆå³$\lambda = 0$ï¼‰è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œç„¶åä½¿ç”¨$L_{loc}$åªè®­ç»ƒbounding-box regression layerï¼ˆå…¶ä»–å±‚å‚æ•°å›ºå®šï¼Œä¸å†å˜åŒ–ï¼‰ã€‚test-time bbox regæŒ‡çš„æ˜¯æ¨ç†é˜¶æ®µæ˜¯å¦ä½¿ç”¨bounding boxå›å½’ã€‚ä»è¡¨6ä¸­å¯ä»¥çœ‹å‡ºï¼Œstage-wise trainingçš„æ•ˆæœä¸å¦‚multi-task trainingã€‚

## 5.2.Scale invariance: to brute force or finesse?

æˆ‘ä»¬å®šä¹‰å›¾åƒçŸ­è¾¹ä¸º$s$ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†single-scale learningå’Œmulti-scale learningã€‚

å¯¹äºsingle-scale learningï¼Œæˆ‘ä»¬è®¾$s=600$ã€‚ç­‰æ¯”ä¾‹ç¼©æ”¾ä½¿$s=600$åï¼Œæ­¤æ—¶é™åˆ¶é•¿è¾¹éœ€å°äº1000ï¼ˆGPUå†…å­˜é™åˆ¶ï¼‰ã€‚å¯¹äºmulti-scale learningï¼Œæˆ‘ä»¬è®¾$s=\\{ 480,576,688,864,1200 \\}$ï¼Œé™åˆ¶é•¿è¾¹éœ€å°äº2000ï¼ˆåŒæ ·æ˜¯GPUå†…å­˜é™åˆ¶ï¼‰ã€‚

è¡¨7ä¸­çš„æ¨¡å‹Så’Œæ¨¡å‹Mè®­ç»ƒå’Œæ¨ç†éƒ½ä½¿ç”¨single-scaleæˆ–éƒ½ä½¿ç”¨multi-scaleã€‚ä»è¡¨7ä¸­å¯ä»¥å‘ç°ï¼Œmulti-scaleåªå¸¦æ¥äº†ä¸€ç‚¹ç‚¹mAPçš„æå‡ï¼Œå´å¢åŠ äº†å¤§é‡æ¨ç†è€—æ—¶ã€‚

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/9.png)

æ‰€ä»¥ï¼Œæˆ‘ä»¬è®¤ä¸ºsingle-scaleæ€§ä»·æ¯”æ›´é«˜ï¼Œå°¤å…¶æ˜¯å¯¹äºè¾ƒæ·±çš„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨æ‰€æœ‰çš„å®éªŒä¸­è®­ç»ƒå’Œæµ‹è¯•éƒ½ä½¿ç”¨single-scaleä¸”è®¾$s=600$ã€‚

## 5.3.Do we need more training data?

ä¸€ä¸ªå¥½çš„object detectorçš„æ€§èƒ½åº”è¯¥éšç€è®­ç»ƒé›†çš„å¢å¤§è€Œæå‡ã€‚ä»è¡¨1ä¸­å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•éšç€è®­ç»ƒé›†çš„æ‰©å……ï¼ŒmAPä»66.9%å¢åŠ åˆ°70.0%ï¼ˆè¿­ä»£æ¬¡æ•°ä¹Ÿä»40kå¢åŠ è‡³60kï¼‰ã€‚ä½œè€…è¿˜åœ¨VOC10å’ŒVOC12ä¸Šåšäº†ç±»ä¼¼çš„å®éªŒï¼Œç»“è®ºæ˜¯ä¸€è‡´çš„ï¼Œä¸å†èµ˜è¿°ã€‚

## 5.4.Do SVMs outperform softmax?

Fast R-CNNä½¿ç”¨äº†softmaxï¼Œè€Œ[R-CNN](http://shichaoxin.com/2021/09/20/è®ºæ–‡é˜…è¯»-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)å’Œ[SPPnet](http://shichaoxin.com/2022/02/22/è®ºæ–‡é˜…è¯»-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ä½¿ç”¨äº†[ä¸€å¯¹å…¶ä½™](http://shichaoxin.com/2019/12/05/æœºå™¨å­¦ä¹ åŸºç¡€-ç¬¬ä¹è¯¾-å¤šåˆ†ç±»å­¦ä¹ /#3ovr)çš„çº¿æ€§SVMåˆ†ç±»å™¨ã€‚ä¸ºäº†æ¢ç©¶å“ªç§æ›´ä¼˜ï¼Œæˆ‘ä»¬åšäº†å¦‚ä¸‹å®éªŒï¼š

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/10.png)

å¯¹äºFRCNæ¥è¯´ï¼Œæ— è®ºæ¨¡å‹Sã€Mè¿˜æ˜¯Lï¼Œsoftmaxéƒ½è¦ä¼˜äºSVMã€‚

## 5.5.Are more proposals always better?

object detectorså¤§è‡´å¯åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼š1ï¼‰ä½¿ç”¨object proposalçš„ä¸€ä¸ªsparse setï¼ˆä¾‹å¦‚[selective search](http://shichaoxin.com/2021/10/16/è®ºæ–‡é˜…è¯»-Selective-Search-for-Object-Recognition/)ï¼‰ï¼›2ï¼‰ä½¿ç”¨ä¸€ä¸ªdense setï¼ˆä¾‹å¦‚DPMï¼‰ã€‚

>DPMåŸæ–‡ï¼šP. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. TPAMI, 2010.

![](https://github.com/x-jeff/BlogImage/raw/master/AIPapers/FastRCNN/11.png)

æˆ‘ä»¬è¯„ä¼°äº†æ¯å¹…å›¾åƒä½¿ç”¨1kåˆ°10kä¸ªproposalçš„ç»“æœï¼ˆåŸºäºæ¨¡å‹Mï¼Œæ¯æ¬¡éƒ½ä¼šre-trainingå’Œre-testingï¼‰ï¼Œç»“æœè§Fig3è“è‰²å®çº¿ï¼Œå½“proposalçš„æ•°é‡è¿‡å¤šæ—¶ï¼ŒmAPæœ‰è½»å¾®çš„ä¸‹é™ã€‚åœ¨SSï¼ˆå³[selective search](http://shichaoxin.com/2021/10/16/è®ºæ–‡é˜…è¯»-Selective-Search-for-Object-Recognition/)ï¼‰çš„åŸºç¡€ï¼ˆ2kä¸ªproposalï¼‰ä¸Šï¼Œæ¯å¹…å›¾åƒå†åŠ ä¸Š$1000 \times \\{ 2,4,6,8,10,32,45 \\}$ä¸ªdense boxï¼Œç»“æœè§Fig3è“è‰²è™šçº¿ã€‚Fig3ä¸­ï¼Œè“è‰²ä¸‰è§’æŒ‡çš„æ˜¯æ¯å¹…å›¾åƒç”Ÿæˆ45kä¸ªdense boxï¼Œç„¶åå°†2kä¸ªç”±SSç”Ÿæˆçš„proposalè½¬æ¢æˆè·ç¦»æœ€è¿‘çš„dense boxå¾—åˆ°çš„ç»“æœï¼ˆå³æœ€åæ¯å¹…å›¾åƒç”¨äº†2kä¸ªdense boxï¼‰ï¼ŒmAPä¸‹é™äº†1%ï¼Œä¸º57.7%ã€‚è“è‰²è±å½¢æŒ‡çš„æ˜¯ä»…ä½¿ç”¨45kä¸ªdense box+softmaxçš„ç»“æœï¼ŒmAP=52.9%ã€‚è“è‰²åœ†å½¢æŒ‡çš„æ˜¯ä»…ä½¿ç”¨45kä¸ªdense box+SVMçš„ç»“æœï¼ŒmAP=49.3%ã€‚

æˆ‘ä»¬è®¤ä¸ºsparse object proposalæ›´èƒ½æå‡æ¨¡å‹æ€§èƒ½ã€‚

## 5.6.Preliminary MS COCO results

æˆ‘ä»¬è¿˜åœ¨COCOæ•°æ®é›†ä¸Šæµ‹è¯•äº†Fast R-CNNï¼ˆwith [VGG16](http://shichaoxin.com/2021/02/24/è®ºæ–‡é˜…è¯»-VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION/)ï¼‰ï¼Œæœ¬åšæ–‡ä¸å†è¯¦è¿°è¿™éƒ¨åˆ†ã€‚

# 6.Conclusion

å…¨æ–‡æ€»ç»“ï¼Œä¸å†è¯¦è¿°ã€‚

# 7.åŸæ–‡é“¾æ¥

ğŸ‘½[Fast R-CNN](https://github.com/x-jeff/AI_Papers/blob/master/Fast%20R-CNN.pdf)