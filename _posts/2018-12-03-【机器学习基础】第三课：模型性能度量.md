---
layout:     post
title:      【机器学习基础】第三课：模型性能度量
subtitle:   查全率，查准率，F值，P-R曲线，ROC，AUC，代价敏感错误率，代价曲线
date:       2018-12-03
author:     x-jeff
header-img: blogimg/20181203.jpg
catalog: true
tags:
    - Machine Learning
    - Element Knowledge
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.均方误差
使用不同的性能度量往往会导致不同的评判结果。

例如，$f(x)$为预测结果，$y$为真实标记。

回归问题中，最常用的性能度量为“均方误差”：

$$E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2$$

更一般的，对于数据分布$D$和概率密度函数$p(\cdot)$，均方误差可描述为：

$$E(f;D)=\int_{x\sim D}(f(x)-y)^2 p(x)dx$$

# 2.错误率与精度
更一般的，对于数据分布$D$和概率密度函数$p(\cdot)$

* 错误率：$E(f;D)=\int_{x\sim D}\Pi (f(x)\neq y)p(x)dx$
* 精度：$acc(f;D)=\int_{x\sim D}\Pi (f(x)=y)p(x)dx=1-E(f;D)$

$\Pi (\cdot)$：指示函数，在$\cdot$为真和假时分别取值为1，0。

# 3.查准率、查全率与$F_1$
* 查准率，亦称“准确率”：*precision*
* 查全率，亦称“召回率”：*recall*

**混淆矩阵：**
![](https://ws1.sinaimg.cn/large/006tNbRwly1fxv0u6annjj30i807oabo.jpg)

**查准率**：$P=\frac{TP}{TP+FP}$

**查全率**：$R=\frac{TP}{TP+FN}$

一般情况下，查全率和查准率是一对矛盾的度量，一个高一个底。  
通常只有在一些简单任务中，才可能使查全率和查准率都很高。

## 3.1.“P-R曲线”
根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。

举例解释一下：例如一个二分类问题，按照预测为正例的概率从大到小进行排序：
![](https://ws2.sinaimg.cn/large/006tNbRwly1fxv1yj6aunj307g0dmmxj.jpg)

绘制“P-R”曲线的步骤：

1. 预测为正例的概率从大到小排列。
2. 构建二维直角坐标系，横轴为查全率，纵轴为查准率。
3. 阈值在`(0)`处时，有$TP=FP=0$，即分类器预测全为负例，此时$P=R=0$，得到“P-R曲线”的第一个点(0,0)。
4. 阈值在`(1)`处时，大于该阈值的样本被预测为正例，小于该阈值的样本被预测为负例，结合样本的真实标记构建混淆矩阵，从而计算查准率和查全率，得到第二个点的坐标。
5. 其余点以此类推。
6. 阈值在`(n)`时，得到最后一个点，分类器预测全为正例，$FN=TN=0$，此时查全率为1，查准率实际为数据集中正例所占的比例（如果数据集为平衡数据，$P\approx 0.5$，此时最后一个点的坐标为(1,0.5)）。

因此，根据上述步骤，将得到的多个点连接起来，得到“P-R曲线”（或者叫“P-R图”）。

⚠️为绘图方便和美观，“P-R曲线”通常绘制成单调平滑曲线，但现实任务中的“P-R曲线”常是非单调、不平滑的，在很多局部有上下波动。

### 3.1.1.通过“P-R曲线”评价模型性能的优劣
“P-R曲线”与平衡点示意图：
![](https://ws3.sinaimg.cn/large/006tNbRwly1fxw5x9wnrdj30jm0g2443.jpg)

若一个学习器的“P-R曲线”被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，如上图中学习器A的性能优于学习器B。

如果两个学习器的“P-R曲线”发生了交叉，例如A和B，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率下进行比较。

常用的比较方法有以下三种：

1. 曲线下面积。
2. 平衡点（*Break-Event Point*，简称*BEP*），它是“查准率=查全率”时的取值。如C的$BEP=0.64$，A优于B（因为A的BEP>B的BEP）等。
3. BEP还是过于简单，引入F值。

## 3.2.F值

$$F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2 \times P)+R}$$

其中$\beta (\beta >0)$度量了查全率对查准率的相对重要性。

* $\beta =1$时，即$F_1$，查全率和查准率的重要性相当。
* $\beta >1$时，查全率有更大影响。
* $\beta <1$时，查准率有更大影响。

$F_1$是基于查准率和查全率的调和平均，定义为：$\frac{1}{F_1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})$

$F_\beta$则是加权调和平均，$\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})$

*tips*：与算数平均$(\frac{P+R}{2})$和几何平均$(\sqrt{P\times R})$相比，调和平均更重视较小值（更适合评价不平衡数据的分类问题）。

>相关知识补充：
>
>常见的三种平均数：算数平均数、几何平均数、调和平均数。
>
>这里主要介绍一下调和平均数。
>
>**调和平均数（harmonic mean）**又称倒数平均数，是各种统计变量倒数的算数平均数的倒数。主要分为两种类型：**简单调和平均数**和**加权调和平均数**。
>
>简单调和平均数：
>
>$$H_n=\frac{1}{\frac{1}{n}\sum_{i=1}^n\frac{1}{x_i}}=\frac{n}{\sum_{i=1}^n\frac{1}{x_i}}$$
>
>加权调和平均数：
>
>$$\begin{align} H_n & = \frac{1}{\frac{1}{m_1+m_2+\cdots +m_n}(\frac{1}{x_1}m_1+\frac{1}{x_2}m_2+\cdots +\frac{1}{x_n}m_n)} \\&= \frac{\sum_{i=1}^n m_i}{\sum_{i=1}^n \frac{m_i}{x_i}} \end{align}$$

### 3.2.1.宏$F_1$和微$F_1$
