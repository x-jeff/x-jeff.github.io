---
layout:     post
title:      【机器学习基础】第三课：模型性能度量
subtitle:   查全率，查准率，F值，P-R曲线，ROC，AUC，代价敏感错误率，代价曲线
date:       2018-12-03
author:     x-jeff
header-img: blogimg/20181203.jpg
catalog: true
tags:
    - Machine Learning
    - Element Knowledge
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.均方误差
使用不同的性能度量往往会导致不同的评判结果。

例如，$f(x)$为预测结果，$y$为真实标记。

回归问题中，最常用的性能度量为“均方误差”：

$$E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2$$

更一般的，对于数据分布$D$和概率密度函数$p(\cdot)$，均方误差可描述为：

$$E(f;D)=\int_{x\sim D}(f(x)-y)^2 p(x)dx$$

# 2.错误率与精度
更一般的，对于数据分布$D$和概率密度函数$p(\cdot)$

* 错误率：$E(f;D)=\int_{x\sim D}\Pi (f(x)\neq y)p(x)dx$
* 精度：$acc(f;D)=\int_{x\sim D}\Pi (f(x)=y)p(x)dx=1-E(f;D)$

$\Pi (\cdot)$：指示函数，在$\cdot$为真和假时分别取值为1，0。

# 3.查准率、查全率与$F_1$
* 查准率，亦称“准确率”：*precision*
* 查全率，亦称“召回率”：*recall*

**混淆矩阵：**
![](https://ws1.sinaimg.cn/large/006tNbRwly1fxv0u6annjj30i807oabo.jpg)

**查准率**：$P=\frac{TP}{TP+FP}$

**查全率**：$R=\frac{TP}{TP+FN}$

一般情况下，查全率和查准率是一对矛盾的度量，一个高一个底。  
通常只有在一些简单任务中，才可能使查全率和查准率都很高。

## 3.1.“P-R曲线”
根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。

举例解释一下：例如一个二分类问题，按照预测为正例的概率从大到小进行排序：
![](https://ws2.sinaimg.cn/large/006tNbRwly1fxv1yj6aunj307g0dmmxj.jpg)

绘制“P-R”曲线的步骤：

1. 预测为正例的概率从大到小排列。
2. 构建二维直角坐标系，横轴为查全率，纵轴为查准率。
3. 阈值在`(0)`处时，有$TP=FP=0$，即分类器预测全为负例，此时$P=R=0$，得到“P-R曲线”的第一个点(0,0)。
4. 阈值在`(1)`处时，大于该阈值的样本被预测为正例，小于该阈值的样本被预测为负例，结合样本的真实标记构建混淆矩阵，从而计算查准率和查全率，得到第二个点的坐标。
5. 其余点以此类推。
6. 阈值在`(n)`时，得到最后一个点，分类器预测全为正例，$FN=TN=0$，此时查全率为1，查准率实际为数据集中正例所占的比例（如果数据集为平衡数据，$P\approx 0.5$，此时最后一个点的坐标为(1,0.5)）。