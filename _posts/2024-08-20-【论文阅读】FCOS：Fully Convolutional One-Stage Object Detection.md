---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘FCOSï¼šFully Convolutional One-Stage Object Detection
subtitle:   FCOS
date:       2024-08-20
author:     x-jeff
header-img: blogimg/20191226.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>ä»£ç ï¼š[FCOS](https://github.com/tianzhi0549/FCOS/)ã€‚

anchor-basedæ£€æµ‹å™¨æœ‰ä»¥ä¸‹ä¸€äº›ç¼ºç‚¹ï¼š

1. æ£€æµ‹æ€§èƒ½å¯¹anchor boxçš„å¤§å°ã€é•¿å®½æ¯”ä»¥åŠæ•°é‡å¾ˆæ•æ„Ÿã€‚
2. å³ä½¿anchor boxç»è¿‡äº†ç²¾å¿ƒè®¾è®¡ï¼Œä½†ç”±äºanchor boxçš„å¤§å°å’Œé•¿å®½æ¯”æ˜¯ä¿æŒä¸å˜çš„ï¼Œæ‰€ä»¥åœ¨å¤„ç†å½¢çŠ¶å˜åŒ–è¾ƒå¤§çš„ç›®æ ‡æ—¶ä¹Ÿä¼šé‡åˆ°å›°éš¾ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°ç›®æ ‡ã€‚æ­¤å¤–ï¼Œé¢„è®¾çš„anchor boxä¹Ÿé˜»ç¢äº†æ£€æµ‹å™¨çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. ä¸ºäº†è·å¾—æ›´é«˜çš„recall rateï¼Œanchor boxéœ€è¦è¢«å¯†é›†çš„æ”¾ç½®åœ¨è¾“å…¥å›¾åƒä¸Šï¼ˆæ¯”å¦‚åœ¨[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)ä¸­ï¼Œå°†è¾“å…¥å›¾åƒçš„çŸ­è¾¹ç¼©æ”¾åˆ°800ï¼Œå¯¹äºä¸€å¼ è¾“å…¥å›¾åƒï¼Œæˆ‘ä»¬éœ€è¦è¶…è¿‡180Kä¸ªanchor boxï¼‰ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œå¤§å¤šæ•°anchor boxéƒ½è¢«æ ‡è®°ä¸ºè´Ÿæ ·æœ¬ã€‚è¿‡å¤šçš„è´Ÿæ ·æœ¬åŠ å‰§äº†è®­ç»ƒä¸­æ­£è´Ÿæ ·æœ¬çš„ä¸å¹³è¡¡ã€‚
4. anchor boxè¿˜æ¶‰åŠå¤æ‚çš„è®¡ç®—ï¼Œæ¯”å¦‚IoUçš„è®¡ç®—ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡è¯æ˜äº†ï¼Œæ›´ç®€å•çš„åŸºäº[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)çš„æ£€æµ‹å™¨æ¯”åŸºäºanchorçš„æ£€æµ‹å™¨å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚

>ä¸ªäººæ³¨è§£ï¼šFCOSæ˜¯anchor-freeçš„ã€‚

# 2.Related Work

ä¸å†èµ˜è¿°ã€‚

# 3.Our Approach

## 3.1.Fully Convolutional One-Stage Object Detector

å°†CNN backboneç¬¬$i$å±‚çš„feature mapè®°ä¸º$F_i \in \mathbb{R}^{H \times W \times C}$ï¼Œ$s$ä¸ºåˆ°è¿™ä¸€å±‚ç´¯ç§¯çš„æ€»æ­¥é•¿ã€‚å°†ä¸€å¼ è¾“å…¥å›¾åƒçš„GT boxè®°ä¸º$\\{B_i \\}$ï¼Œå…¶ä¸­ï¼Œ$B_i = (x_0^{(i)},y_0^{(i)},x_1^{(i)},y_1^{(i)},c^{(i)}) \in \mathbb{R}^4 \times \\{ 1,2,...,C \\}$ã€‚$(x_0^{(i)},y_0^{(i)})$å’Œ$(x_1^{(i)},y_1^{(i)})$åˆ†åˆ«æ˜¯bboxå·¦ä¸Šè§’ç‚¹å’Œå³ä¸‹è§’ç‚¹çš„åæ ‡ã€‚$c^{(i)}$æ˜¯bboxå†…ç›®æ ‡çš„æ‰€å±ç±»åˆ«ã€‚$C$æ˜¯æ€»çš„ç±»åˆ«æ•°ç›®ï¼Œå¯¹äºMS-COCOæ•°æ®é›†æ¥è¯´ï¼Œ$C=80$ã€‚

å¯¹äº$F_i$ä¸­çš„ä»»æ„ä¸€ç‚¹$(x,y)$ï¼Œå…¶åœ¨è¾“å…¥å›¾åƒä¸­å¯¹åº”çš„æ„Ÿå—é‡çš„ä¸­å¿ƒåæ ‡è¿‘ä¼¼ä¸º$(\lfloor \frac{s}{2} \rfloor+xs,\lfloor \frac{s}{2} \rfloor+ys)$ã€‚åŸºäºanchorçš„æ–¹æ³•å°†è¾“å…¥å›¾åƒä¸Šçš„ä½ç½®ï¼ˆlocationï¼Œä¸ªäººæ³¨è§£ï¼šå³åƒç´ ç‚¹ï¼‰è§†ä¸ºï¼ˆå¤šä¸ªï¼‰anchor boxçš„ä¸­å¿ƒï¼Œå¹¶ä¸”å‚è€ƒè¿™äº›anchor boxæ¥å›å½’ç›®æ ‡bboxï¼Œè€Œæˆ‘ä»¬ç›´æ¥åœ¨è¯¥ä½ç½®ä¸Šå›å½’ç›®æ ‡bboxã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„æ£€æµ‹å™¨ç›´æ¥å°†ä½ç½®è§†ä¸ºè®­ç»ƒæ ·æœ¬ï¼Œè€Œä¸æ˜¯åƒåŸºäºanchoræ–¹æ³•é‚£æ ·å°†anchor boxè§†ä¸ºè®­ç»ƒæ ·æœ¬ï¼Œè¿™ä¸è¯­ä¹‰åˆ†å‰²ä¸­çš„[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)ç›¸åŒã€‚

å…·ä½“æ¥è¯´ï¼Œå¦‚æœä½ç½®$(x,y)$è½åœ¨ä»»æ„ä¸€ä¸ªGT boxå†…ï¼Œå®ƒå°±æ˜¯æ­£æ ·æœ¬ï¼Œå…¶ç±»åˆ«æ ‡ç­¾$c^\*$å°±æ˜¯GT boxçš„ç±»åˆ«ã€‚å¦åˆ™å°±æ˜¯è´Ÿæ ·æœ¬ï¼Œåˆ™$c^\*=0$ï¼ˆèƒŒæ™¯ç±»åˆ«ï¼‰ã€‚é™¤äº†ç±»åˆ«æ ‡ç­¾ï¼Œè¿˜æœ‰ä¸€ä¸ªå››ç»´å‘é‡$\mathbf{t}^\*=(l^\*,t^\*,r^\*,b^\*)$ä½œä¸ºbboxçš„å›å½’ç›®æ ‡ã€‚å…¶ä¸­ï¼Œ$l^\*,t^\*,r^\*,b^\*$ä¸ºè¯¥ä½ç½®åˆ°bboxå››ä¸ªè¾¹ç•Œçš„è·ç¦»ï¼Œå¦‚Fig1å·¦æ‰€ç¤ºã€‚å¦‚æœä¸€ä¸ªä½ç½®è½å…¥å¤šä¸ªbboxå†…ï¼Œåˆ™è§†ä¸ºæ¨¡ç³Šæ ·æœ¬ï¼ˆambiguous sampleï¼‰ã€‚å¯¹äºè¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬ç®€å•çš„é€‰æ‹©é¢ç§¯æœ€å°çš„bboxä½œä¸ºå›å½’ç›®æ ‡ã€‚åœ¨ä¸‹ä¸€ä¸ªç« èŠ‚ï¼Œæˆ‘ä»¬å°†å±•ç¤ºé€šè¿‡å¤šå±‚çº§é¢„æµ‹ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘æ¨¡ç³Šæ ·æœ¬çš„æ•°é‡ï¼Œä»è€Œå‡ ä¹ä¸å½±å“æ£€æµ‹æ€§èƒ½ã€‚å¦‚æœä½ç½®$(x,y)$åŒ¹é…ä¸Šäº†bbox $B_i$ï¼Œåˆ™è®­ç»ƒæ—¶çš„å›å½’ç›®æ ‡ä¸ºï¼š

$$l^* = x-x_0^{(i)}, \  t^*=y-y_0^{(i)} \\ r^* = x_1^{(i)}-x, \  b^* = y_1^{(i)}-y \tag{1}$$

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒFCOSå¯ä»¥åˆ©ç”¨å°½å¯èƒ½å¤šçš„å‰æ™¯æ ·æœ¬æ¥è®­ç»ƒå›å½’å™¨ã€‚è¿™ä¸åŸºäºanchorçš„æ–¹æ³•ä¸åŒï¼Œåè€…åªå°†ä¸GT boxæœ‰è¶³å¤Ÿé«˜IoUçš„anchor boxè§†ä¸ºæ­£æ ·æœ¬ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™å¯èƒ½æ˜¯FCOSä¼˜äºåŸºäºanchoræ£€æµ‹å™¨çš„åŸå› ä¹‹ä¸€ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/1.png)

ğŸ‘‰**Network Outputs.**

ç½‘ç»œçš„æœ€åä¸€å±‚è¾“å‡ºä¸€ä¸ª80Dçš„å‘é‡$\mathbf{p}$ç”¨äºé¢„æµ‹ç±»åˆ«æ ‡ç­¾ï¼Œå’Œä¸€ä¸ª4Dçš„å‘é‡$\mathbf{t} = (l,t,r,b)$ç”¨äºé¢„æµ‹bboxã€‚æˆ‘ä»¬æ²¡æœ‰è®­ç»ƒä¸€ä¸ªå¤šç±»åˆ«åˆ†ç±»å™¨ï¼Œè€Œæ˜¯è®­ç»ƒäº†$C$ä¸ªäºŒåˆ†ç±»å™¨ã€‚å’Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ç±»ä¼¼ï¼Œåˆ†ç±»åˆ†æ”¯å’Œå›å½’åˆ†æ”¯éƒ½åŒ…å«4ä¸ªå·ç§¯å±‚ã€‚æ­¤å¤–ï¼Œç”±äºå›å½’ç›®æ ‡æ€»æ˜¯æ­£çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨$\exp (x)$å°†æ•°æ˜ å°„åˆ°$(0,\infty)$ã€‚ç›¸æ¯”æµè¡Œçš„åŸºäºanchorçš„æ–¹æ³•ï¼Œæ¯”å¦‚[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)å’Œ[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ï¼ˆæ¯ä¸ªä½ç½®ä½¿ç”¨9ä¸ªanchor boxï¼‰ï¼ŒFCOSè¾“å‡ºçš„å˜é‡å°‘äº†9å€ã€‚

ğŸ‘‰**Loss Function.**

$$L(\{\mathbf{p}_{x,y}\},\{\mathbf{t}_{x,y}\})=\frac{1}{N_{pos}}\sum_{x,y}L_{cls}(\mathbf{p}_{x,y},c^*_{x,y})+\frac{\lambda}{N_{pos}}\sum_{x,y}\mathbb{I}_{\{c^*_{x,y}>0\}}L_{reg}(\mathbf{t}_{x,y},\mathbf{t}^*_{x,y})\tag{2}$$

å…¶ä¸­ï¼Œ$L_{cls}$ä½¿ç”¨[focal loss](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ï¼Œ$L_{reg}$ä½¿ç”¨[IoU loss](https://shichaoxin.com/2024/08/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-UnitBox-An-Advanced-Object-Detection-Network/)ã€‚$N_{pos}$è¡¨ç¤ºé˜³æ€§æ ·æœ¬çš„æ•°é‡ï¼Œ$\lambda$æ˜¯å¹³è¡¡æƒé‡ï¼Œæœ¬æ–‡è®¾ä¸º1ã€‚æ±‚å’Œä¼šè®¡ç®—$F_i$ä¸Šçš„æ‰€æœ‰ä½ç½®ã€‚å¦‚æœ$c^\*\_i>0$ï¼Œåˆ™$\mathbb{I}\_{\{c^\*_i>0\}}$ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚

ğŸ‘‰**Inference.**

ç»™å®šä¸€ä¸ªè¾“å…¥å›¾åƒï¼Œç½‘ç»œè¾“å‡º$F_i$ä¸Šæ¯ä¸ªä½ç½®å¯¹åº”çš„åˆ†ç±»åˆ†æ•°$\mathbf{p}\_{x,y}$å’Œå›å½’é¢„æµ‹$\mathbf{t}\_{x,y}$ã€‚æˆ‘ä»¬å°†$\mathbf{p}\_{x,y}>0.05$çš„è§†ä¸ºé˜³æ€§æ ·æœ¬ã€‚

## 3.2.Multi-level Prediction with FPN for FCOS

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ä½¿ç”¨å¸¦æœ‰[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)çš„å¤šå±‚çº§é¢„æµ‹æ¥è§£å†³FCOSå¯èƒ½å­˜åœ¨çš„ä¸¤ä¸ªé—®é¢˜ï¼š

1. æœ€ç»ˆfeature mapçš„è¾ƒå¤§æ­¥é•¿ï¼ˆæ¯”å¦‚$16\times$ï¼Œä¸ªäººæ³¨è§£ï¼šä¸‹é‡‡æ ·å€æ•°ï¼‰ä¼šå¯¼è‡´è¾ƒä½çš„BPRï¼ˆbest possible recallï¼Œå³æ£€æµ‹å™¨æ‰€èƒ½è¾¾åˆ°çš„recall rateä¸Šé™ï¼‰ã€‚å¯¹äºåŸºäºanchorçš„æ£€æµ‹å™¨ï¼Œç”±äºè¾ƒå¤§æ­¥é•¿å¯¼è‡´çš„ä½recall rateï¼Œå¯ä»¥é€šè¿‡é™ä½åˆ¤å®šæ­£æ ·æœ¬anchor boxæ‰€éœ€çš„IoUé˜ˆå€¼æ¥è¿›è¡Œä¸€å®šç¨‹åº¦ä¸Šçš„è¡¥å¿ã€‚è€Œæˆ‘ä»¬é€šè¿‡å®éªŒè¯æ˜ï¼Œå³ä½¿ä½¿ç”¨è¾ƒå¤§çš„æ­¥é•¿ï¼ŒåŸºäº[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)çš„FCOSä»ç„¶å¯ä»¥è·å¾—å¥½çš„BPRï¼Œç”šè‡³ä¼˜äºå®˜æ–¹å®ç°Detectronä¸­çš„åŸºäºanchorçš„æ£€æµ‹å™¨[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)çš„BPRï¼ˆè§è¡¨1ï¼‰ã€‚å› æ­¤ï¼Œå¯¹FCOSæ¥è¯´ï¼ŒBPRä¸æ˜¯é—®é¢˜ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨å¤šå±‚çº§[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)é¢„æµ‹ï¼ŒBPRå¯ä»¥è¿›ä¸€æ­¥æé«˜ï¼Œè¾¾åˆ°ä¸[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)æ‰€èƒ½å®ç°çš„æœ€ä½³BPRç›¸å½“çš„æ°´å¹³ã€‚
2. GT boxä¹‹é—´çš„é‡å å¯èƒ½ä¼šå¯¼è‡´æ¨¡ç³Šæ€§ï¼Œå³åœ¨é‡å åŒºåŸŸå†…ï¼ŒæŸä¸ªä½ç½®åº”è¯¥å±äºå“ªä¸ªGT boxï¼Ÿè¿™ç§æ¨¡ç³Šæ€§ä¼šå¯¼è‡´åŸºäº[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)æ£€æµ‹å™¨æ€§èƒ½ä¸‹é™ã€‚åœ¨æœ¬æ–‡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™ç§æ¨¡ç³Šæ€§å¯ä»¥é€šè¿‡å¤šå±‚çº§é¢„æµ‹å¤§å¤§ç¼“è§£ï¼ŒåŸºäº[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)çš„æ£€æµ‹å™¨åœ¨æ€§èƒ½ä¸Šå¯ä»¥ä¸åŸºäºanchorçš„æ£€æµ‹å™¨ç›¸å½“ï¼Œç”šè‡³æ›´å¥½ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/2.png)

FCOSçš„æ¡†æ¶å¦‚Fig2æ‰€ç¤ºã€‚åˆ†åˆ«åœ¨$C3,C4,C5$åæ¥ä¸€ä¸ª$1\times 1$å·ç§¯å¾—åˆ°$P3,P4,P5$ã€‚åœ¨$P5$çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨ä¸€ä¸ªæ­¥é•¿ä¸º2çš„å·ç§¯å±‚å¾—åˆ°$P6$ï¼ŒåŸºäº$P6$ï¼Œå†ä½¿ç”¨ä¸€ä¸ªæ­¥é•¿ä¸º2çš„å·ç§¯å±‚å¾—åˆ°$P7$ã€‚$P3,P4,P5,P6,P7$çš„æ­¥é•¿åˆ†åˆ«ä¸º$8,16,32,64,128$ã€‚å¯¹äºæ‰€æœ‰ç‰¹å¾å±‚çº§ä¸­çš„æ¯ä¸€ä¸ªä½ç½®ï¼Œæˆ‘ä»¬å…ˆè®¡ç®—å›å½’ç›®æ ‡$l^\*,t^\*,r^\*,b^\*$ã€‚å¦‚æœæ»¡è¶³$\max (l^\*,t^\*,r^\*,b^\*)>m_i$æˆ–$\max (l^\*,t^\*,r^\*,b^\*)<m_{i-1}$ï¼Œåˆ™è¯¥ä½ç½®è§†ä¸ºè´Ÿæ ·æœ¬ï¼Œä¸å†éœ€è¦å›å½’bboxã€‚$m_i$æ˜¯ç¬¬$i$ä¸ªç‰¹å¾å±‚çº§éœ€è¦å›å½’çš„æœ€å¤§è·ç¦»ã€‚æœ¬æ–‡ä¸­ï¼Œ$m_2,m_3,m_4,m_5,m_6,m_7$åˆ†åˆ«è®¾ç½®ä¸º$0,64,128,256,512,\infty$ã€‚ç”±äºä¸åŒå°ºå¯¸çš„ç›®æ ‡è¢«åˆ†é…åˆ°ä¸åŒçš„ç‰¹å¾å±‚çº§ï¼Œè€Œå¤§éƒ¨åˆ†çš„é‡å å‘ç”Ÿåœ¨å°ºå¯¸å·®å¼‚è¾ƒå¤§çš„ç›®æ ‡ä¹‹é—´ã€‚å¦‚æœä¸€ä¸ªä½ç½®ï¼Œå³ä½¿ä½¿ç”¨äº†å¤šå±‚çº§é¢„æµ‹ï¼Œä»ç„¶è¢«åˆ†é…å¤šä¸ªGT boxï¼Œæˆ‘ä»¬ä¼šç®€å•çš„é€‰æ‹©é¢ç§¯æœ€å°çš„GT boxã€‚

headåœ¨ä¸åŒç‰¹å¾å±‚çº§ä¹‹é—´æ˜¯å…±äº«çš„ï¼Œè¿™ä¸ä»…æå‡äº†æ£€æµ‹æ•ˆç‡ï¼Œè¿˜æé«˜äº†æ£€æµ‹ç²¾åº¦ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å‘ç°ä¸åŒçš„ç‰¹å¾å±‚çº§éœ€è¦å›å½’ä¸åŒçš„å°ºå¯¸èŒƒå›´ï¼ˆæ¯”å¦‚$P3$çš„å°ºå¯¸èŒƒå›´æ˜¯$[0,64]$ï¼Œ$P4$çš„å°ºå¯¸èŒƒå›´æ˜¯$[64,128]$ï¼‰ï¼Œå› æ­¤ï¼Œå¯¹ä¸åŒç‰¹å¾å±‚çº§ç›´æ¥ä½¿ç”¨å®Œå…¨ä¸€æ ·çš„headæ˜¯ä¸åˆç†çš„ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å°†æ ‡å‡†çš„$\exp(x)$æ›¿æ¢ä¸ºäº†$\exp(s_ix)$ï¼Œå¯¹æ¯ä¸ª$P_i$éƒ½æœ‰ä¸€ä¸ªå¯å­¦ä¹ çš„å‚æ•°$s_i$ç”¨äºè‡ªåŠ¨è°ƒæ•´ï¼Œè¿™ä¸€æ”¹åŠ¨ä¹Ÿç•¥å¾®æå‡äº†æ£€æµ‹æ€§èƒ½ã€‚

## 3.3.Center-ness for FCOS

åœ¨ä½¿ç”¨äº†å¤šå±‚çº§é¢„æµ‹ä¹‹åï¼ŒFCOSä»ç„¶å’ŒåŸºäºanchorçš„æ£€æµ‹å™¨æœ‰å·®è·ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°è¿™æ˜¯ç”±äºåœ¨è¿œç¦»ç›®æ ‡ä¸­å¿ƒçš„ä½ç½®äº§ç”Ÿäº†å¾ˆå¤šä½è´¨é‡çš„é¢„æµ‹bboxã€‚

æˆ‘ä»¬åœ¨ä¸å¼•å…¥ä»»ä½•è¶…å‚æ•°çš„æƒ…å†µä¸‹ï¼Œé‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„ç­–ç•¥æ¥æŠ‘åˆ¶è¿™äº›ä½è´¨é‡çš„æ£€æµ‹æ¡†ã€‚å¦‚Fig2æ‰€ç¤ºï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªcenter-nessåˆ†æ”¯ï¼Œç”¨äºé¢„æµ‹ä½ç½®çš„â€œcenter-nessâ€ã€‚center-nessè¡¨ç¤ºè¯¥ä½ç½®åˆ°å¯¹åº”ç›®æ ‡ä¸­å¿ƒä½ç½®çš„å½’ä¸€åŒ–è·ç¦»ï¼Œå¦‚Fig7æ‰€ç¤ºã€‚center-nessçš„è®¡ç®—ä¸ºï¼š

$$\text{centerness}^*=\sqrt{\frac{\min (l^*,r^*)}{\max (l^*,r^*)} \times \frac{\min (t^*,b^*)}{\max (t^*,b^*)}} \tag{3}$$

>è®ºæ–‡æäº¤åï¼Œä½œè€…åœ¨åç»­å®éªŒä¸­å‘ç°ï¼Œåœ¨MS-COCOæ•°æ®é›†ä¸Šï¼Œå¦‚æœæŠŠcenter-nessåˆ†æ”¯ç§»åˆ°å’Œå›å½’åˆ†æ”¯å¹¶è¡Œçš„ä½ç½®ä¸Šï¼ŒAPå¯ä»¥è¿›ä¸€æ­¥æå‡ã€‚
>
>ä¸ªäººæ³¨è§£ï¼šå¼(3)æ˜¯è®­ç»ƒæ—¶ç”¨æ¥è®¡ç®—lossçš„ï¼Œåœ¨æ¨ç†é˜¶æ®µï¼Œcenter-nessçš„å€¼å¯ç›´æ¥ä»center-nessåˆ†æ”¯è·å¾—ï¼Œæœ¬æ–‡ç¬¬4.1.2éƒ¨åˆ†çš„å®éªŒç»“æœä¹Ÿè¯æ˜äº†è¿™ç§æ–¹å¼çš„æ€§èƒ½æ˜¯æœ€å¥½çš„ã€‚

æˆ‘ä»¬ä½¿ç”¨$\text{sqrt}$æ¥é™ä½center-nessçš„è¡°å‡é€Ÿåº¦ã€‚center-nessçš„èŒƒå›´ä»0åˆ°1ï¼Œä½¿ç”¨[BCE loss](https://shichaoxin.com/2024/01/14/YOLO%E7%B3%BB%E5%88%97-YOLOv5/#51compute-losses)è®­ç»ƒã€‚å…¶lossè¢«åŠ åœ¨å¼(2)ä¸­ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæœ€ç»ˆçš„åˆ†æ•°ï¼ˆå³ç”¨æ¥å¯¹æ£€æµ‹æ¡†æ’åºçš„åˆ†æ•°ï¼‰ä¸ºé¢„æµ‹çš„center-nessä¹˜ä¸Šå¯¹åº”çš„åˆ†ç±»åˆ†æ•°ï¼ˆä¸ªäººæ³¨è§£ï¼šè¿™ä¸ªæ€è·¯å’Œ[IoU aware loss](https://shichaoxin.com/2024/08/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-IoU-aware-Single-stage-Object-Detector-for-Accurate-Localization/)ä¸€æ ·ï¼‰ã€‚ä»è€Œï¼Œcenter-nesså¯ä»¥é™ä½è¿œç¦»ç›®æ ‡ä¸­å¿ƒçš„bboxçš„åˆ†æ•°ã€‚è¿™æ ·ï¼Œé«˜åˆ†ç±»åˆ†æ•°ä½†ä½è´¨é‡çš„bboxå°±ä¼šåœ¨æœ€ç»ˆçš„NMSè¿‡ç¨‹ä¸­è¢«è¿‡æ»¤æ‰ï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ£€æµ‹æ€§èƒ½ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/4.png)

å¦‚Fig3çš„çƒ­å›¾æ‰€ç¤ºï¼Œè¶Šé è¿‘bboxä¸­å¿ƒï¼Œé¢œè‰²è¶Šçº¢ï¼Œcenter-nessè¶Šæ¥è¿‘1ï¼›è¶Šé è¿‘bboxè¾¹ç¼˜ï¼Œé¢œè‰²è¶Šè“ï¼Œcenter-nessè¶Šæ¥è¿‘0ã€‚

é™¤äº†center-nessï¼Œè¿˜æœ‰å¦å¤–ä¸€ç§å¯é€‰çš„æ–¹æ³•ï¼Œå°±æ˜¯åªæŠŠGT boxä¸­å¿ƒéƒ¨åˆ†æ‰€åœ¨ä½ç½®è§†ä¸ºæ­£æ ·æœ¬ã€‚åœ¨è®ºæ–‡æäº¤åï¼Œåœ¨åç»­ç ”ç©¶[FCOS\_PLUS](https://github.com/yqyao/FCOS_PLUS)ä¸­ï¼Œæˆ‘ä»¬å‘ç°ç»“åˆè¿™ä¸¤ç§æ–¹æ³•å¯ä»¥è¾¾åˆ°æ›´å¥½çš„æ€§èƒ½ã€‚å®éªŒç»“æœè§è¡¨3ã€‚

# 4.Experiments

å®éªŒåœ¨COCOæ•°æ®é›†ä¸Šè¿›è¡Œã€‚è®­ç»ƒé›†ä¸ºCOCO trainval35kï¼ˆ115Kå¼ å›¾åƒï¼‰ï¼ŒéªŒè¯é›†ä¸ºminivalï¼ˆ5Kå¼ å›¾åƒï¼Œç”¨äºæ¶ˆèå®éªŒï¼‰ã€‚æµ‹è¯•é›†ä¸ºtest-devï¼ˆ20Kå¼ å›¾åƒï¼‰ã€‚

ğŸ‘‰**Training Details.**

é™¤éç‰¹æ®Šè¯´æ˜ï¼Œå‡ä½¿ç”¨[ResNet-50](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä½œä¸ºbackboneï¼Œä½¿ç”¨å’Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä¸€æ ·çš„è¶…å‚æ•°ã€‚ä½¿ç”¨SGDè®­ç»ƒäº†90Kæ¬¡è¿­ä»£ï¼Œåˆå§‹å­¦ä¹ ç‡ä¸º0.01ï¼Œminibatch size=16ã€‚åœ¨ç¬¬60Kå’Œç¬¬80Kæ¬¡è¿­ä»£æ—¶ï¼Œå­¦ä¹ ç‡é™¤ä»¥10ã€‚weight decay=0.0001ï¼Œmomentum=0.9ã€‚backboneåœ¨ImageNetä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚æ–°æ·»åŠ å±‚çš„åˆå§‹åŒ–åŒ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ã€‚é™¤éç‰¹æ®Šè¯´æ˜ï¼Œå°†è¾“å…¥å›¾åƒçš„çŸ­è¾¹resizeåˆ°800ä¸ªåƒç´ ï¼Œé•¿è¾¹å°äºæˆ–ç­‰äº1333ä¸ªåƒç´ ã€‚

ğŸ‘‰**Inference Details.**

æˆ‘ä»¬é¦–å…ˆå°†è¾“å…¥å›¾åƒå–‚ç»™ç½‘ç»œï¼Œå¾—åˆ°é¢„æµ‹çš„bboxåŠå…¶å¯¹åº”çš„é¢„æµ‹ç±»åˆ«ã€‚é™¤éç‰¹æ®Šè¯´æ˜ï¼Œæ¥ä¸‹æ¥çš„åå¤„ç†ä»¥åŠæ‰€ç”¨çš„è¶…å‚æ•°éƒ½å’Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä¿æŒä¸€è‡´ã€‚æ¨ç†æ‰€ç”¨çš„è¾“å…¥å›¾åƒå¤§å°å’Œè®­ç»ƒæ‰€ç”¨çš„ä¸€æ ·ã€‚å½“ç„¶ï¼Œå¦‚æœæˆ‘ä»¬ä»”ç»†çš„è°ƒæ•´è¿™äº›è¶…å‚æ•°ï¼Œæ¨¡å‹çš„æ€§èƒ½å¯èƒ½ä¼šè¿›ä¸€æ­¥æé«˜ã€‚

## 4.1.Ablation Study

### 4.1.1.Multi-level Prediction with FPN

é’ˆå¯¹ç¬¬3.2éƒ¨åˆ†æåˆ°çš„ä¸¤ä¸ªå¯èƒ½é—®é¢˜çš„æ¶ˆèå®éªŒã€‚

ğŸ‘‰**Best Possible Recalls.**

BPRçš„å®šä¹‰ä¸ºæ£€æµ‹å™¨æœ€å¤šèƒ½recallåˆ°çš„GT boxæ•°é‡å’Œæ‰€æœ‰GT boxæ•°é‡çš„æ¯”å€¼ã€‚å¦‚æœåœ¨è®­ç»ƒé˜¶æ®µï¼ŒGT boxè‡³å°‘è¢«åˆ†é…ç»™ä¸€ä¸ªæ ·æœ¬ï¼ˆåœ¨FCOSä¸­ï¼Œæ ·æœ¬æŒ‡çš„æ˜¯åƒç´ ç‚¹ä½ç½®ï¼›åœ¨anchor-basedæ–¹æ³•ä¸­ï¼Œæ ·æœ¬æŒ‡çš„æ˜¯anchorï¼‰ï¼Œåˆ™è®¤ä¸ºè¯¥boxè¢«recallåˆ°äº†ã€‚å¦‚è¡¨1æ‰€ç¤ºï¼Œåªæœ‰ç‰¹å¾å±‚çº§$P4$ï¼ˆæ­¥é•¿ä¸º16ï¼‰çš„è¯ï¼ˆå³ä¸ä½¿ç”¨[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)ï¼‰ï¼ŒFCOSçš„BPRä¸º95.55%ã€‚è€ŒDetectronå®˜æ–¹å®ç°çš„[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)çš„BPRåªæœ‰90.92%ï¼Œä¸”$\text{IOU} \geqslant 0.4$æ‰è®¤ä¸ºanchorå’ŒGT boxåŒ¹é…æˆåŠŸã€‚å¦‚æœå–æ¶ˆIoUé˜ˆå€¼çš„é™åˆ¶ï¼Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)çš„BPRè¾¾åˆ°äº†99.23%ã€‚åœ¨[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)çš„å¸®åŠ©ä¸‹ï¼ŒFCOSçš„BPRä¹Ÿè¾¾åˆ°äº†ç›¸å½“çš„æ°´å¹³ï¼Œä¸º98.40%ã€‚ç”±äºå½“å‰æ£€æµ‹å™¨å®é™…çš„æœ€ä¼˜recallè¿œä½äº90%ï¼Œæ‰€ä»¥FCOSå’Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)åœ¨BPRä¸Šçš„è¿™ç‚¹ç»†å°å·®è·ä¸ä¼šå½±å“åˆ°æ£€æµ‹å™¨æ€§èƒ½ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/3.png)

>ä¸ªäººæ³¨è§£ï¼šå› ä¸ºä¸‹é‡‡æ ·æˆ–è€…anchorå’ŒGT boxçš„åŒ¹é…æœºåˆ¶ï¼Œæœ‰å¯èƒ½å¯¼è‡´æŸäº›GT boxæ— æ³•åˆ†é…åˆ°ä»»ä½•ä¸€ä¸ªæ ·æœ¬ä¸Šã€‚ä»¥FCOSä¸ºä¾‹ï¼Œå¦‚æœæœ‰ä¸€ä¸ªGT boxï¼Œfeature mapä¸Šçš„ä»»æ„ä¸€ç‚¹è¿˜åŸåˆ°è¾“å…¥å›¾åƒä¸Šéƒ½æ— æ³•è½åœ¨è¿™ä¸ªGT boxå†…ï¼Œåˆ™è¿™ä¸ªGT boxå°±æ— æ³•åˆ†é…ç»™ä»»ä½•ä¸€ä¸ªæ ·æœ¬äº†ï¼Œè¿™ä¹Ÿå°±å¯¼è‡´äº†BPRä¸æ˜¯100%ã€‚ä»¥[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä¸ºä¾‹ï¼Œå¦‚æœæœ‰ä¸€ä¸ªGT boxï¼Œåœ¨ä¸€å®šçš„IoUé˜ˆå€¼ä¸‹ï¼Œæ²¡æœ‰ä»»ä½•ä¸€ä¸ªanchorå¯ä»¥ä¸ä¹‹åŒ¹é…ï¼Œåˆ™è¿™ä¸ªGT boxå°±æ— æ³•åˆ†é…ç»™ä»»ä½•ä¸€ä¸ªæ ·æœ¬äº†ã€‚è¡¨1ä¸­ç¬¬ä¸€è¡Œçš„â€œNoneâ€è¡¨ç¤ºä¸è€ƒè™‘ä½è´¨é‡çš„åŒ¹é…ï¼Œå³æ­¤æ—¶çš„IoUé˜ˆå€¼è‚¯å®šæ˜¯å¤§äº0.4çš„ï¼Œåœ¨[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä¸­ï¼Œæ­£æ ·æœ¬çš„IoUé˜ˆå€¼ä¸º0.5ã€‚

ğŸ‘‰**Ambiguous Samples.**

æ¨¡ç³Šæ ·æœ¬çš„ç¤ºæ„è§Fig1å³ï¼Œå³ä¸€ä¸ªæ ·æœ¬è¢«åˆ†é…å¤šä¸ªGT boxã€‚åœ¨è¡¨2ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨minivalæ•°æ®é›†ä¸Šï¼Œæ‰€æœ‰æ­£æ ·æœ¬ä¸­æ¨¡ç³Šæ ·æœ¬çš„æ¯”ä¾‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¤ä¸ºå¦‚æœä¸€ä¸ªæ ·æœ¬è¢«åˆ†é…çš„å¤šä¸ªGT boxå±äºåŒä¸€ç±»åˆ«ï¼Œåˆ™è¿™æ ·çš„æ¨¡ç³Šæ ·æœ¬æ˜¯ä¸é‡è¦çš„ã€‚å› ä¸ºæ— è®ºè¿™ç§æ ·æœ¬é¢„æµ‹å“ªä¸ªGT boxï¼Œé¢„æµ‹éƒ½ç®—æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºç±»åˆ«éƒ½æ˜¯ä¸€æ ·çš„ã€‚è€Œè¢«é—æ¼çš„å…¶ä»–GT boxåªèƒ½é€šè¿‡åˆ«çš„æ ·æœ¬æ¥é¢„æµ‹ã€‚å› æ­¤åœ¨è¡¨2ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿç»Ÿè®¡äº†å»é™¤è¿™ç§æ¨¡ç³Šæ ·æœ¬åçš„æ¯”ä¾‹ï¼ˆè§â€œ(diff.)â€åˆ—ï¼‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥è¯æ˜GT boxçš„é‡å å¯¹äºFCOSæ¥è¯´å¹¶ä¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç»Ÿè®¡äº†åœ¨æ¨ç†é˜¶æ®µæœ‰å¤šå°‘æ£€æµ‹æ¡†æ˜¯æ¥è‡ªæ¨¡ç³Šä½ç½®çš„ã€‚æˆ‘ä»¬å‘ç°ä»…æœ‰2.3%çš„æ£€æµ‹æ¡†æ¥è‡ªæ¨¡ç³Šä½ç½®ã€‚å¦‚æœåªè€ƒè™‘ä¸åŒç±»åˆ«çš„é‡å ï¼Œåˆ™è¿™ä¸€æ¯”ä¾‹é™ä½è‡³1.5%ã€‚ä½†è¿™å¹¶ä¸æ„å‘³ç€FCOSåœ¨è¿™1.5%çš„æ¨¡ç³Šä½ç½®ä¸Šæ˜¯ä¸èƒ½å·¥ä½œçš„ã€‚å¦‚ä¹‹å‰æåˆ°çš„ï¼Œè¿™äº›ä½ç½®ä¼šè¢«åˆ†é…ç»™é¢ç§¯æœ€å°çš„GT boxã€‚å› æ­¤ï¼Œå¯¹äºè¿™äº›ä½ç½®æ¥è¯´ï¼Œåªæ˜¯å­˜åœ¨é—æ¼ä¸€äº›è¾ƒå¤§ç›®æ ‡çš„é£é™©ã€‚å¦‚æ¥ä¸‹æ¥çš„å®éªŒæ‰€ç¤ºï¼Œå®ƒä»¬å¹¶æ²¡æœ‰ä½¿FCOSå˜å¾—ä¸å¦‚anchor-basedæ£€æµ‹å™¨ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/5.png)

### 4.1.2.With or Without Center-ness

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/6.png)

åœ¨è¡¨4ä¸­ï¼Œç»“æœåŸºäºminivalæ•°æ®é›†ã€‚ç¬¬ä¸€è¡Œè¡¨ç¤ºä¸ä½¿ç”¨center-nessã€‚ç¬¬äºŒè¡Œè¡¨ç¤ºä½¿ç”¨é¢„æµ‹çš„å›å½’å‘é‡è®¡ç®—center-nessï¼ˆä¸å¼•å…¥é¢å¤–çš„center-nessåˆ†æ”¯ï¼‰ã€‚ç¬¬ä¸‰è¡Œè¡¨ç¤ºç›´æ¥ä½¿ç”¨center-nessåˆ†æ”¯é¢„æµ‹center-nessçš„å€¼ã€‚[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä½¿ç”¨ä¸¤ä¸ªIoUé˜ˆå€¼æ¥åˆ’åˆ†æ­£è´Ÿæ ·æœ¬ï¼Œè¿™ä¹Ÿèƒ½å‡å°‘ä½è´¨é‡çš„é¢„æµ‹ã€‚center-nessçš„æ–¹å¼å°±å¯ä»¥çœå»è¿™ä¸¤ä¸ªIoUé˜ˆå€¼çš„è¶…å‚æ•°ã€‚ä½†åœ¨è®ºæ–‡æäº¤ä¹‹åï¼Œæˆ‘ä»¬å‘ç°ç»“åˆcenter-nesså’ŒIoUé˜ˆå€¼å¯ä»¥å¾—åˆ°æ›´å¥½çš„ç»“æœï¼Œåœ¨è¡¨3ä¸­æˆ‘ä»¬ç”¨â€œ+ ctr. samplingâ€è¡¨ç¤ºã€‚

### 4.1.3.FCOS vs. Anchor-based Detectors

ä¸Šè¿°FCOSå’Œæ ‡å‡†çš„[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)æœ‰ä¸¤ä¸ªç»†å¾®çš„å·®åˆ«ã€‚1ï¼‰åœ¨æ–°åŠ çš„å·ç§¯å±‚ä¸­ï¼Œé™¤äº†æœ€åçš„é¢„æµ‹å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†[GNï¼ˆGroup Normalizationï¼‰](http://shichaoxin.com/2024/08/20/è®ºæ–‡é˜…è¯»-Group-Normalization/)ï¼Œè¿™è®©è®­ç»ƒæ›´åŠ ç¨³å®šã€‚2ï¼‰æˆ‘ä»¬ä½¿ç”¨$P5$ç”Ÿæˆ$P6,P7$ï¼Œè€Œæ²¡æœ‰åƒ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)é‚£æ ·ä½¿ç”¨$C5$ã€‚æˆ‘ä»¬å‘ç°ä½¿ç”¨$P5$å¯ä»¥ç¨å¾®æå‡äº›æ€§èƒ½ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/7.png)

â€œ+ ctr. on reg.â€è¡¨ç¤ºå°†center-nessåˆ†æ”¯ç§»åˆ°å›å½’åˆ†æ”¯ã€‚â€œNormalizationâ€è¡¨ç¤ºç”¨[FPN](https://shichaoxin.com/2023/12/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Feature-Pyramid-Networks-for-Object-Detection/)å±‚çº§çš„æ­¥é•¿å¯¹å¼(1)è¿›è¡Œå½’ä¸€åŒ–ã€‚

## 4.2.Comparison with State-of-the-art Detectors

åŸºäºMS-COCO test-devæ•°æ®é›†ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†FCOSå’Œå…¶ä»–SOTAçš„ç›®æ ‡æ£€æµ‹å™¨ã€‚å¯¹äºè¿™äº›å®éªŒï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°†è¾“å…¥å›¾åƒçš„çŸ­è¾¹éšæœºç¼©æ”¾åˆ°640åˆ°800ä¹‹é—´ï¼Œå¹¶ä¸”å°†è¿­ä»£æ¬¡æ•°åŠ å€åˆ°180Kæ¬¡ï¼ˆå­¦ä¹ ç‡å˜åŒ–çš„æ—¶é—´ç‚¹ä¹Ÿå¯¹åº”åŠ å€ï¼‰ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/8.png)

æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€æ¬¡ä¸€ä¸ªæ²¡æœ‰ä»»ä½•èŠ±å“¨æŠ€å·§çš„anchor-freeæ£€æµ‹å™¨ï¼Œå…¶æ€§èƒ½è¿œè¿œä¼˜äºanchor-basedæ£€æµ‹å™¨ã€‚

# 5.Extensions on Region Proposal Networks

ä½¿ç”¨FCOSä»£æ›¿[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ä¸­çš„RPNéƒ¨åˆ†æ¥ç”Ÿæˆproposalã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/9.png)

# 6.Conclusion

æˆ‘ä»¬æå‡ºäº†ä¸€ç§anchor-freeä¸”proposal-freeçš„å•é˜¶æ®µæ£€æµ‹å™¨FCOSã€‚æ¥ä¸‹æ¥æ˜¯é™„å½•éƒ¨åˆ†ã€‚

# 7.Class-agnostic Precision-recall Curves

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/10.png)

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/11.png)

Fig4-6æ˜¯åœ¨minivalæ•°æ®é›†ä¸Šï¼Œä¸åŒIoUé˜ˆå€¼ä¸‹çš„ä¸ç±»åˆ«æ— å…³çš„[PRæ›²çº¿](https://shichaoxin.com/2018/12/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E7%AC%AC%E4%B8%89%E8%AF%BE-%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F/#31p-r%E6%9B%B2%E7%BA%BF)ã€‚3ä¸ªæ›²çº¿å¯¹åº”çš„APè§è¡¨7ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/12.png)

# 8.Visualization for Center-ness

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/13.png)

# 9.Qualitative

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/14.png)

# 10.More discussions

ğŸ‘‰**Center-ness vs. IoUNet:**

å’ŒIoUNetçš„æ¯”è¾ƒï¼Œä¸å†è¯¦è¿°ã€‚

>IoUNetï¼šAcquisition of Localization Confidence for Accurate Object Detectionã€‚

ğŸ‘‰**BPR in Section 4.1 and ambiguity analysis:**

ä¸å†è¯¦è¿°ã€‚

ğŸ‘‰**Additional ablation study:**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/FCOS/15.png)

ğŸ‘‰**RetinaNet with Center-ness:**

center-nessä¸èƒ½ç›´æ¥ç”¨äº[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ï¼Œå› ä¸ºfeature mapä¸Šçš„ä¸€ä¸ªä½ç½®å¯¹åº”ä¸€ä¸ªcenter-nessï¼Œè€Œ[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ä¸­ï¼Œfeature mapä¸Šçš„ä¸€ä¸ªä½ç½®å¯¹åº”å¤šä¸ªanchor boxï¼Œæ¯ä¸ªanchor boxéœ€è¦ä¸åŒçš„center-nesså€¼ã€‚

å¯¹äº[RetinaNet](https://shichaoxin.com/2024/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Focal-Loss-for-Dense-Object-Detection/)ï¼Œanchor boxä¸GT boxä¹‹é—´çš„IoUåˆ†æ•°å¯èƒ½å¯ä»¥ä½œä¸ºcenter-nessçš„æ›¿ä»£æ–¹æ¡ˆã€‚

ğŸ‘‰**Positive samples overlap with RetinaNet:**

æˆ‘ä»¬æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œcenter-nessåªæœ‰åœ¨æ¨ç†é˜¶æ®µæ‰å‘æŒ¥ä½œç”¨ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ‰€æœ‰è½å…¥GT boxå†…çš„åƒç´ ç‚¹ä½ç½®éƒ½ä¼šè¢«æ ‡è®°ä¸ºæ­£æ ·æœ¬ã€‚å› æ­¤ï¼ŒFCOSå¯ä»¥ä½¿ç”¨æ›´å¤šçš„å‰æ™¯ä½ç½®æ¥è®­ç»ƒå›å½’å™¨ï¼Œä»è€Œäº§ç”Ÿæ›´å‡†ç¡®çš„è¾¹ç•Œæ¡†ã€‚

# 11.åŸæ–‡é“¾æ¥

ğŸ‘½[FCOSï¼šFully Convolutional One-Stage Object Detection](https://github.com/x-jeff/AI_Papers/blob/master/2024/FCOSï¼šFully%20Convolutional%20One-Stage%20Object%20Detection.pdf)