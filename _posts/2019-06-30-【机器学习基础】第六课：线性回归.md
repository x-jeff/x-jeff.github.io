---
layout:     post
title:      【机器学习基础】第六课：线性回归
subtitle:   线性模型，线性回归，最小二乘法，广义线性模型，距离的定义，多变量线性回归
date:       2019-06-30
author:     x-jeff
header-img: blogimg/20190630.jpg
catalog: true
tags:
    - Machine Learning Series
---
>【机器学习基础】系列博客为参考周志华老师的《机器学习》一书，自己所做的读书笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.线性模型基本形式

给定由$d$个属性描述的示例$x=(x_1;x_2;...;x_d)$，那么线性模型的基本形式可写为：

$$f(x)=w_1x_1+w_2x_2+w_3x_3+...+w_dx_d+b$$

一般用向量形式写成：

$$f(x)=w^Tx+b$$

其中，$w=(w_1;w_2;...;w_d)$。

把矩阵展开写，即为：

$$\begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}  =\begin{pmatrix} x_{11} & x_{12} & \cdots & x_{1d} \\ x_{21} & x_{22} & \cdots & x_{2d} \\ \vdots & \vdots & \ddots & \vdots \\ x_{n1} & x_{n2} & \cdots & x_{nd} \end{pmatrix} \cdot \begin{pmatrix} w_1 \\ w_2 \\ \vdots \\ w_d \end{pmatrix} + \begin{pmatrix} b \\ b \\ \vdots \\ d \end{pmatrix}$$

(矩阵维数：$n\times 1=(n\times d)\cdot (d\times 1)+(n\times 1)$)

其中，$n$为数据条数，$d$为属性个数。

# 2.线性回归

