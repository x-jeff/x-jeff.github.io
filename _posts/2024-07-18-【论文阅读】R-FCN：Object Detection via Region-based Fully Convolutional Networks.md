---
layout:     post
title:      ã€è®ºæ–‡é˜…è¯»ã€‘R-FCNï¼šObject Detection via Region-based Fully Convolutional Networks
subtitle:   R-FCNï¼ŒOHEM
date:       2024-07-18
author:     x-jeff
header-img: blogimg/20221002.jpg
catalog: true
tags:
    - AI Papers
---  
>æœ¬æ–‡ä¸ºåŸåˆ›æ–‡ç« ï¼Œæœªç»æœ¬äººå…è®¸ï¼Œç¦æ­¢è½¬è½½ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚

# 1.Introduction

>æºç åœ°å€ï¼š[R-FCN](https://github.com/daijifeng001/r-fcn)ã€‚

[SPP-net](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ã€[Fast R-CNN](https://shichaoxin.com/2022/03/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fast-R-CNN/)ã€[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ç­‰ä¸€ç³»åˆ—ç›®æ ‡æ£€æµ‹æ¡†æ¶å¯é€šè¿‡RoI poolingå±‚åˆ’åˆ†ä¸ºä¸¤ä¸ªå­ç½‘ç»œï¼š1ï¼‰RoI poolingå±‚ä¹‹å‰ï¼Œæ˜¯å’ŒRoIæ— å…³çš„ã€å…±äº«çš„å…¨å·ç§¯å­ç½‘ç»œï¼›2ï¼‰RoI poolingå±‚ä¹‹åï¼Œæ˜¯åŸºäºRoIçš„å­ç½‘ç»œï¼Œä¹‹é—´äº’ä¸å…±äº«ã€‚ä»¥[SPP-net](https://shichaoxin.com/2022/02/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Spatial-Pyramid-Pooling-in-Deep-Convolutional-Networks-for-Visual-Recognition/)ä¸ºä¾‹ï¼Œç¬¬ä¸€ä¸ªå­ç½‘ç»œæ˜¯ä¸€ä¸ªä»¥spatial pooling layerä¸ºç»“æŸçš„å·ç§¯ç½‘ç»œï¼Œç¬¬äºŒä¸ªå­ç½‘ç»œæ˜¯å¤šä¸ªfcå±‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨åˆ†ç±»ç½‘ç»œä¸­çš„æœ€åä¸€ä¸ªspatial pooling layerä½œä¸ºç›®æ ‡æ£€æµ‹ç½‘ç»œä¸­çš„RoI poolingå±‚ã€‚

ä½†æ˜¯æœ€è¿‘ä¸€äº›SOTAçš„å›¾åƒåˆ†ç±»ç½‘ç»œï¼Œæ¯”å¦‚[ResNet](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)å’ŒGoogLeNetï¼ˆ[Inception-v1](https://shichaoxin.com/2021/06/01/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Going-deeper-with-convolutions/)ã€[Inception-v2/v3](https://shichaoxin.com/2021/11/29/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Rethinking-the-Inception-Architecture-for-Computer-Vision/)ï¼‰ï¼Œéƒ½è¢«è®¾è®¡æˆå…¨å·ç§¯ï¼ˆåªæœ‰æœ€åä¸€å±‚æ˜¯å…¨è¿æ¥ï¼Œåœ¨è¿ç§»åˆ°ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šæ—¶ä¼šè¢«ç§»é™¤ï¼‰ã€‚å¾ˆè‡ªç„¶çš„å°±ä¼šæƒ³åˆ°ï¼Œåœ¨ç›®æ ‡æ£€æµ‹æ¡†æ¶ä¸­ä½¿ç”¨æ‰€æœ‰çš„å·ç§¯å±‚ä½œä¸ºå…±äº«çš„å·ç§¯å­ç½‘ç»œï¼Œè€ŒåŸºäºRoIçš„å­ç½‘ç»œåˆ™æ²¡æœ‰éšè—å±‚ã€‚ä½†è¿™ç§æ–¹æ¡ˆçš„æ£€æµ‹ç²¾åº¦éå¸¸ä½ï¼Œå’Œå¾ˆé«˜çš„åˆ†ç±»ç²¾åº¦ä¸ç¬¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåœ¨[ResNetè®ºæ–‡](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä¸­ï¼Œ[Faster R-CNNæ£€æµ‹å™¨](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)çš„RoI poolingå±‚è¢«ä¸è‡ªç„¶çš„æ’å…¥åˆ°ä¸¤ç»„å·ç§¯å±‚ä¹‹é—´â€”â€”è¿™åˆ›å»ºäº†ä¸€ä¸ªæ›´æ·±çš„RoIå­ç½‘ç»œï¼Œæé«˜äº†ç²¾åº¦ï¼Œä½†ç”±äºæ¯ä¸ªRoIçš„è®¡ç®—æ˜¯éå…±äº«çš„ï¼Œå› æ­¤é€Ÿåº¦è¾ƒæ…¢ã€‚

æˆ‘ä»¬è®¤ä¸ºä¸Šè¿°ä¸è‡ªç„¶çš„è®¾è®¡æ˜¯ç”±äºå¢åŠ å›¾åƒåˆ†ç±»çš„å¹³ç§»ä¸å˜æ€§ä¸æ»¡è¶³ç›®æ ‡æ£€æµ‹çš„å¹³ç§»å˜åŒ–æ€§ä¹‹é—´çš„çŸ›ç›¾é€ æˆçš„ã€‚ä¸€æ–¹é¢ï¼Œå›¾åƒåˆ†ç±»ä»»åŠ¡æ›´å€¾å‘äºå¹³ç§»ä¸å˜æ€§â€”â€”å³ä¸ä¼šå…³å¿ƒå’Œè¯†åˆ«ç›®æ ‡åœ¨å›¾åƒä¸­çš„ç§»åŠ¨ï¼Œå› æ­¤ï¼Œå…·æœ‰å¹³ç§»ä¸å˜æ€§çš„æ·±å±‚å…¨å·ç§¯ç½‘ç»œæ˜¯é¦–é€‰ã€‚å¦ä¸€æ–¹é¢ï¼Œç›®æ ‡æ£€æµ‹ä»»åŠ¡åˆ™éœ€è¦å¯¹ç§»åŠ¨çš„ç›®æ ‡è¿›è¡Œå®šä½ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬éœ€è¦å¯¹ç§»åŠ¨çš„ç›®æ ‡åšå‡ºæœ‰æ„ä¹‰çš„å“åº”ï¼Œå³ç”Ÿæˆç›¸åº”çš„bboxã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œé’ˆå¯¹ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬æå‡ºäº†R-FCNï¼ˆRegion-based Fully Convolutional Networkï¼‰ã€‚æˆ‘ä»¬çš„ç½‘ç»œç”±å…±äº«çš„ã€å…¨å·ç§¯æ¡†æ¶ç»„æˆï¼Œå°±åƒ[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)ä¸€æ ·ã€‚æ ¸å¿ƒæ€è·¯è§Fig1ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/1.png)

åœ¨Fig1ä¸­ï¼Œè¾“å…¥å›¾åƒé¦–å…ˆè¿›å…¥ä¸€ä¸ªå…¨å·ç§¯ç½‘ç»œï¼Œç„¶åé€šè¿‡ä¸€ä¸ªä¸“é—¨çš„å·ç§¯å¾—åˆ°position-sensitive score mapã€‚æ¥ç€åŸºäºposition-sensitive score mapè¿›è¡ŒRoI poolingã€‚

åŸºäºregionçš„æ£€æµ‹å™¨ä¹‹é—´çš„æ¯”è¾ƒè§è¡¨1ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/2.png)

# 2.Our approach

ğŸ‘‰**Overview.**

éµå¾ª[R-CNN](https://shichaoxin.com/2021/09/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/)ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†two-stageçš„ç›®æ ‡æ£€æµ‹ç­–ç•¥ï¼š1ï¼‰region proposalï¼›2ï¼‰region classificationã€‚æˆ‘ä»¬ä½¿ç”¨[RPN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/#31region-proposal-networks)ç”Ÿæˆå€™é€‰regionã€‚[RPN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/#31region-proposal-networks)å’ŒR-FCNä¹‹é—´å…±äº«ç‰¹å¾ã€‚æ•´ä½“æ¡†æ¶è§Fig2ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/3.png)

ç»™å®šproposal regionï¼ˆå³RoIï¼‰ï¼ŒR-FCNä¼šé¢„æµ‹è¿™ä¸ªRoIçš„ç±»åˆ«ï¼ˆç›®æ ‡ç±»åˆ«æˆ–èƒŒæ™¯ï¼‰ã€‚åœ¨R-FCNä¸­ï¼Œæ‰€æœ‰å¯å­¦ä¹ çš„æƒé‡å±‚éƒ½æ˜¯å·ç§¯çš„ï¼Œå¹¶ä¸”æ˜¯åœ¨æ•´ä¸ªå›¾åƒä¸Šè®¡ç®—çš„ã€‚æœ€åä¸€ä¸ªå·ç§¯å±‚é’ˆå¯¹æ¯ä¸ªç±»åˆ«è¾“å‡º$k^2$ä¸ªposition-sensitive score mapï¼Œç®—ä¸ŠèƒŒæ™¯ï¼Œä¸€å…±æ˜¯$C+1$ä¸ªç±»åˆ«ï¼Œæ‰€ä»¥æœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°ä¸º$k^2(C+1)$ã€‚

ğŸ‘‰**Backbone architecture.**

R-FCNçš„backboneä½¿ç”¨[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ã€‚æˆ‘ä»¬åªä½¿ç”¨[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)çš„å·ç§¯å±‚ï¼ˆå…±100ä¸ªå·ç§¯å±‚ï¼‰æ¥è®¡ç®—feature mapï¼Œå»é™¤äº†[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä¸­çš„å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œ1000ç±»åˆ«çš„fcå±‚ã€‚[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)åœ¨ImageNetä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒã€‚[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)æœ€åä¸€ä¸ªå·ç§¯blockçš„è¾“å‡ºç»´åº¦æ˜¯2048-dï¼Œæˆ‘ä»¬é¢å¤–æ·»åŠ äº†ä¸€ä¸ª1024-dçš„$1\times 1$å·ç§¯ç”¨äºé™ä½ç»´åº¦ã€‚åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªé€šé“æ•°ä¸º$k^2(C+1)$çš„å·ç§¯å±‚æ¥ç”Ÿæˆscore mapã€‚

ğŸ‘‰**Position-sensitive score maps & Position-sensitive RoI pooling.**

æˆ‘ä»¬å°†æ¯ä¸ªRoIåˆ’åˆ†ä¸º$k \times k$ä¸ªbinã€‚å¦‚æœRoIçš„å¤§å°ä¸º$w \times h$ï¼Œé‚£ä¹ˆæ¯ä¸ªbinçš„å¤§å°çº¦ä¸º$\frac{w}{k} \times \frac{h}{k}$ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œæœ€åä¸€ä¸ªå·ç§¯å±‚ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆäº†$k^2$ä¸ªscore mapï¼ˆä¸ªäººæ³¨è§£ï¼šæ¯ä¸ªç±»åˆ«çš„æ¯ä¸ªbinéƒ½å¯¹åº”ä¸€ä¸ªscore mapï¼‰ã€‚é‚£ä¹ˆå¯¹äºç¬¬$(i,j)$ä¸ªbinï¼ˆ$0 \leqslant i,j \leqslant k-1$ï¼‰ï¼ŒåŸºäºscore mapçš„RoI poolingå¯è¡¨ç¤ºä¸ºï¼š

$$r_c(i,j \mid \Theta) = \sum_{(x,y)\in \text{bin}(i,j)} z_{i,j,c} (x+x_0, y+y_0 \mid \Theta) / n \tag{1}$$

$r_c(i,j)$æ˜¯åœ¨ç¬¬$c$ä¸ªç±»åˆ«ä¸Šï¼Œç¬¬$(i,j)$ä¸ªbinç»è¿‡æ± åŒ–åå¾—åˆ°çš„å€¼ã€‚$z_{i,j,c}$æ˜¯$k^2(C+1)$ä¸ªscore mapä¸­çš„ä¸€ä¸ªã€‚$(x_0,y_0)$æ˜¯RoIå·¦ä¸Šè§’çš„åæ ‡ã€‚$n$æ˜¯è¿™ä¸ªbiné‡Œçš„åƒç´ ç‚¹æ•°é‡ã€‚$\Theta$è¡¨ç¤ºè¿™ä¸ªç½‘ç»œä¸­æ‰€æœ‰å¯å­¦ä¹ çš„å‚æ•°ã€‚ç¬¬$(i,j)$ä¸ªbinçš„èŒƒå›´ï¼š

$$\lfloor i \frac{w}{k} \rfloor \leqslant x < \lceil (i+1)\frac{w}{k} \rceil$$

$$\lfloor j \frac{h}{k} \rfloor \leqslant y < \lceil (j+1) \frac{h}{k} \rceil$$

å¦‚Fig1æ‰€ç¤ºï¼Œæ¯ä¸ªé¢œè‰²ä»£è¡¨ä¸€ä¸ªbinã€‚å¼(1)æ‰§è¡Œçš„æ˜¯å¹³å‡æ± åŒ–ï¼Œå¦‚æœæƒ³æ‰§è¡Œmax poolingä¹Ÿæ˜¯å¯ä»¥çš„ã€‚

å¯¹æ¯ä¸ªç±»åˆ«ï¼ˆå³é€šé“ï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°äº†$k^2$ä¸ªposition-sensitive scoreï¼Œæˆ‘ä»¬å°†è¿™äº›åˆ†æ•°æ±‚å¹³å‡ï¼Œå¯¹æ¯ä¸ªRoIæ¥è¯´ï¼Œæœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ª$(C+1)$ç»´çš„å‘é‡ï¼š

$$r_c(\Theta) = \sum_{i,j} r_c (i,j \mid \Theta)$$

>ä¸ªäººæ³¨è§£ï¼šæ±‚å¹³å‡åº”è¯¥å†é™¤ä¸ª$k^2$ã€‚

ç„¶åè®¡ç®—softmaxï¼š

$$s_c(\Theta) = e^{r_c(\Theta)} / \sum_{c'=0}^C e^{r_{c'}(\Theta)}$$

è¿™æ ·å°±èƒ½å¾—åˆ°è¯¥RoIå±äºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡äº†ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæ­¤å¤„ä½¿ç”¨äº¤å‰ç†µæŸå¤±ã€‚

é¢„æµ‹bboxçš„æ–¹å¼å’Œä¸Šè¿°ä¸€æ ·ï¼Œåœ¨backboneåå†æ·»åŠ ä¸€ä¸ªå¹¶è¡Œçš„åˆ†æ”¯ï¼ˆä¸ªäººæ³¨è§£ï¼šæ­¤æ—¶ï¼Œç›¸å½“äºä¸€å…±æœ‰3ä¸ªå¹¶è¡Œçš„åˆ†æ”¯ï¼šRPNã€ç±»åˆ«é¢„æµ‹åˆ†æ”¯ã€bboxé¢„æµ‹åˆ†æ”¯ï¼‰ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/4.png)

position-sensitive score mapçš„ä¸ªæ•°å˜ä¸º$4k^2$ã€‚å’Œé¢„æµ‹ç±»åˆ«åˆ†æ”¯çš„æ“ä½œä¸€æ ·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ª4ç»´å‘é‡ï¼Œç”¨äºè¡¨ç¤ºbboxï¼ˆå‚æ•°å«ä¹‰åŒ[Fast R-CNN](https://shichaoxin.com/2022/03/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fast-R-CNN/)ï¼‰ï¼š

$$t= (t_x,t_y,t_w,t_h)$$

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„bboxé¢„æµ‹åˆ†æ”¯æ˜¯ä¸è€ƒè™‘ç±»åˆ«çš„ï¼Œå³ç±»åˆ«æ— å…³çš„ã€‚ä½†å¦‚æœæƒ³é’ˆå¯¹æ¯ä¸ªç±»åˆ«éƒ½é¢„æµ‹ä¸€ä¸ªbboxä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œè¿™æ ·çš„è¯ï¼Œposition-sensitive score mapçš„æ•°é‡å°±æ˜¯$4k^2 C$ã€‚

åœ¨RoIå±‚ä¹‹åå°±æ²¡æœ‰è¦å­¦ä¹ çš„å±‚äº†ï¼Œè¿™ä½¿å¾—åŸºäºregionçš„è®¡ç®—å‡ ä¹æ˜¯æ— æˆæœ¬çš„ï¼Œè¿™åŠ å¿«äº†è®­ç»ƒå’Œæ¨ç†çš„é€Ÿåº¦ã€‚

ğŸ‘‰**Training.**

æœ‰äº†é¢„å…ˆè®¡ç®—çš„region proposalï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„å¯¹R-FCNè¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒã€‚æŸå¤±å‡½æ•°çš„å®šä¹‰å’Œ[Fast R-CNN](https://shichaoxin.com/2022/03/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fast-R-CNN/#23fine-tuning-for-detection)ä¸€æ ·ã€‚å’ŒGT boxçš„IoUå¤§äº0.5çš„RoIè¢«è§†ä¸ºæ­£æ ·æœ¬ï¼Œå¦åˆ™ä¸ºè´Ÿæ ·æœ¬ã€‚

æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥å¾ˆå®¹æ˜“çš„åº”ç”¨OHEMï¼ˆonline hard example miningï¼‰ã€‚æˆ‘ä»¬å¯¹æ¯ä¸ªRoIçš„è®¡ç®—é‡å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå› æ­¤example miningå‡ ä¹æ˜¯æ— æˆæœ¬ã€‚å‡è®¾æ¯å¼ å›¾ç‰‡æœ‰$N$ä¸ªproposalï¼Œåœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œæˆ‘ä»¬ä¼šè®¡ç®—æ¯ä¸ªproposalçš„lossã€‚ç„¶åï¼Œæˆ‘ä»¬æŒ‰ç…§losså¤§å°å¯¹æ‰€æœ‰çš„RoIè¿›è¡Œæ’åºï¼Œé€‰æ‹©lossæœ€å¤§çš„$B$ä¸ªRoIã€‚åå‘ä¼ æ’­åŸºäºè¿™$B$ä¸ªRoIè¿›è¡Œã€‚ç”±äºæˆ‘ä»¬å¯¹æ¯ä¸ªRoIçš„è®¡ç®—é‡å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå› æ­¤å‰å‘ä¼ æ’­çš„æ—¶é—´å‡ ä¹ä¸å—$N$çš„å½±å“ï¼Œä¸æ­¤ç›¸åï¼ŒOHEM Fast R-CNNçš„è®­ç»ƒæ—¶é—´å¯èƒ½ä¼šå¢åŠ ä¸€å€ã€‚

>ä¸ªäººæ³¨è§£ï¼š
>
>ç®€å•ä»‹ç»ä¸‹OHEMï¼Œå…¶å‡ºè‡ªè®ºæ–‡â€œA. Shrivastava, A. Gupta, and R. Girshick. Training region-based object detectors with online hard example mining. In CVPR, 2016.â€ã€‚OHEMæ˜¯ä¸€ç§ç”¨äºæå‡æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ•ˆæœçš„æŠ€æœ¯ï¼Œå°¤å…¶åœ¨è®¡ç®—æœºè§†è§‰å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å¸¸ç”¨ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åŠ¨æ€é€‰æ‹©è®­ç»ƒè¿‡ç¨‹ä¸­æœ€éš¾çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ‰€æœ‰æ ·æœ¬ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯æé«˜æ¨¡å‹å¯¹éš¾ä»¥è¯†åˆ«çš„æ ·æœ¬çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
>
>èƒŒæ™¯ï¼š
>
>åœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶ï¼Œæ•°æ®é›†ä¸­é€šå¸¸åŒ…å«å¤§é‡å®¹æ˜“åˆ†ç±»çš„æ ·æœ¬ä»¥åŠå°‘é‡éš¾ä»¥åˆ†ç±»çš„æ ·æœ¬ã€‚ä½¿ç”¨æ‰€æœ‰æ ·æœ¬è¿›è¡Œè®­ç»ƒå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ›´å…³æ³¨å®¹æ˜“åˆ†ç±»çš„æ ·æœ¬ï¼Œä»è€Œå¿½è§†äº†é‚£äº›éš¾ä»¥åˆ†ç±»çš„æ ·æœ¬ã€‚è¿™ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ€§èƒ½è‰¯å¥½ï¼Œä½†åœ¨æµ‹è¯•é›†æˆ–å®é™…åº”ç”¨ä¸­è¡¨ç°ä¸ä½³ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†éš¾ä»¥åˆ†ç±»çš„æ ·æœ¬æ—¶ã€‚
>
>æ ¸å¿ƒæ€æƒ³ï¼š
>
>OHEMçš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡åœ¨çº¿æ–¹å¼ï¼ˆå³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼‰é€‰æ‹©é‚£äº›å¯¹å½“å‰æ¨¡å‹æ¥è¯´è¾ƒéš¾åˆ†ç±»çš„æ ·æœ¬ï¼Œä¼˜å…ˆå¯¹è¿™äº›æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
>
>å®ç°æ­¥éª¤ï¼š
>
>1. å‰å‘ä¼ æ’­ï¼šåœ¨æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­ï¼Œé¦–å…ˆé€šè¿‡å½“å‰æ¨¡å‹å¯¹æ‰€æœ‰æ ·æœ¬è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—å‡ºé¢„æµ‹ç»“æœå’ŒæŸå¤±å€¼ã€‚
>2. æ ·æœ¬é€‰æ‹©ï¼šæ ¹æ®æŸå¤±å€¼å¯¹æ ·æœ¬è¿›è¡Œæ’åºï¼Œé€‰æ‹©æŸå¤±å€¼è¾ƒå¤§çš„éƒ¨åˆ†æ ·æœ¬ä½œä¸ºâ€œå›°éš¾æ ·æœ¬â€ã€‚é€šå¸¸ï¼Œä¼šé€‰æ‹©æŸå¤±å€¼æ’åå‰$k$çš„æ ·æœ¬ï¼Œ$k$æ˜¯ä¸€ä¸ªé¢„å…ˆå®šä¹‰çš„è¶…å‚æ•°ï¼Œå†³å®šäº†æ¯ä¸ªæ‰¹æ¬¡ä¸­é€‰æ‹©å¤šå°‘æ¯”ä¾‹çš„å›°éš¾æ ·æœ¬ã€‚
>3. åå‘ä¼ æ’­ï¼šå¯¹é€‰å®šçš„å›°éš¾æ ·æœ¬è¿›è¡Œåå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ã€‚
>4. é‡å¤ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°å®Œæˆæ‰€æœ‰è®­ç»ƒè¿­ä»£ã€‚

weight decayä¸º0.0005ï¼Œmomentumä¸º0.9ã€‚ä½¿ç”¨å•å°ºåº¦è®­ç»ƒï¼šå°†å›¾ç‰‡çš„çŸ­è¾¹resizeåˆ°600ä¸ªåƒç´ ã€‚æ¯å—GPUå¤„ç†ä¸€å¼ å›¾åƒï¼Œè®¾ç½®$B=128$ã€‚è®­ç»ƒä½¿ç”¨äº†8å—GPUã€‚fine-tune R-FCNä½¿ç”¨çš„å­¦ä¹ ç‡ä¸º0.001ï¼ˆ20kä¸ªmini-batchï¼‰å’Œ0.0001ï¼ˆ10kä¸ªmini-batchï¼‰ï¼ŒåŸºäºVOCæ•°æ®é›†ã€‚å¯¹äºRPNï¼Œæˆ‘ä»¬é‡‡ç”¨äº†[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/#32sharing-features-for-rpn-and-fast-r-cnn)ä¸­çš„4æ­¥è®­ç»ƒæ³•ã€‚

ğŸ‘‰**Inference.**

å¦‚Fig2æ‰€ç¤ºï¼Œé¦–å…ˆè®¡ç®—RPNå’ŒR-FCNå…±äº«éƒ¨åˆ†çš„feature mapã€‚ç„¶åRPNç”ŸæˆRoIï¼Œæ¥ç€R-FCNåŸºäºRoIè®¡ç®—ç±»åˆ«æ¦‚ç‡å’Œbboxã€‚ä¸ºäº†å’Œ[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)å…¬å¹³æ¯”è¾ƒï¼Œåœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬è¯„ä¼°äº†300ä¸ªRoIã€‚åå¤„ç†ä½¿ç”¨äº†NMSï¼ˆIoUé˜ˆå€¼ä¸º0.3ï¼‰ã€‚

ğŸ‘‰**Ã€ trous and stride.**

å¾—ç›Šäº[FCN](https://shichaoxin.com/2022/01/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fully-Convolutional-Networks-for-Semantic-Segmentation/)ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¿®æ”¹åä¹Ÿå¯ç”¨äºè¯­ä¹‰åˆ†å‰²ã€‚æˆ‘ä»¬å°†[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)çš„32å€ä¸‹é‡‡æ ·é™ä½åˆ°äº†16å€ä¸‹é‡‡æ ·ï¼Œä»¥å¢åŠ score mapçš„åˆ†è¾¨ç‡ã€‚é€šè¿‡æŠŠconv5_1çš„æ­¥é•¿æ”¹ä¸º1å®ç°16å€ä¸‹é‡‡æ ·ï¼Œå¹¶åœ¨conv5é˜¶æ®µä½¿ç”¨ç©ºæ´å·ç§¯æ¥å¼¥è¡¥é™ä½çš„æ­¥é•¿ã€‚ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼ŒRPNçš„è®¡ç®—åŸºäºconv1~conv4ï¼ˆå³è¿™éƒ¨åˆ†å’ŒR-FCNå…±äº«ï¼‰ï¼Œè¿™æ ·RPNå°±ä¸å—ç©ºæ´å·ç§¯çš„å½±å“äº†ã€‚ä¸‹è¡¨æ˜¯ä¸€ä¸ªç›¸å…³çš„æ¶ˆèå®éªŒï¼Œå…¶ä¸­$k\times k = 7 \times 7$ï¼Œæ²¡æœ‰ä½¿ç”¨OHEMï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/5.png)

>Ã  trousè¡¨ç¤ºä½¿ç”¨äº†ç©ºæ´å·ç§¯ã€‚

ğŸ‘‰**Visualization.**

åœ¨Fig3å’ŒFig4ä¸­ï¼Œæˆ‘ä»¬å¯è§†åŒ–äº†R-FCNå­¦åˆ°çš„position-sensitive score mapï¼ˆ$k \times k = 3 \times 3$ï¼‰ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/6.png)

# 3.Related Work

ä¸å†èµ˜è¿°ã€‚

# 4.Experiments

## 4.1.Experiments on PASCAL VOC

æˆ‘ä»¬åœ¨æœ‰20ä¸ªç›®æ ‡ç±»åˆ«çš„PASCAL VOCä¸Šè¿›è¡Œäº†å®éªŒã€‚æˆ‘ä»¬åœ¨VOC 2007 trainvalå’ŒVOC 2012 trainvalï¼ˆå³â€œ07+12â€ï¼‰ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œåœ¨VOC 2007 testä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç›®æ ‡æ£€æµ‹ç²¾åº¦ä½¿ç”¨mAPï¼ˆmean Average Precisionï¼‰è¿›è¡Œè¯„ä¼°ã€‚

ğŸ‘‰**Comparisons with Other Fully Convolutional Strategies**

æˆ‘ä»¬ä½¿ç”¨[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä½œä¸ºbackboneæµ‹è¯•äº†ä»¥ä¸‹å…¨å·ç§¯ç­–ç•¥ï¼ˆæˆ–â€œå‡ ä¹â€å…¨å·ç§¯ç­–ç•¥ï¼Œæ¯ä¸ªRoIåªæœ‰ä¸€ä¸ªåˆ†ç±»å™¨fcå±‚ï¼‰ï¼š

* **NaÃ¯ve Faster R-CNN.**ï¼š[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)æ‰€æœ‰çš„å·ç§¯å±‚éƒ½è¢«ç”¨æ¥è®¡ç®—å…±äº«çš„feature mapï¼ŒæŠŠRoI poolingæ”¾åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚ä¹‹åï¼ˆå³conv5ä¹‹åï¼‰ï¼Œå¯¹æ¯ä¸ªRoIåº”ç”¨ä¸€ä¸ª21ç±»åˆ«çš„fcå±‚ã€‚ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œä½¿ç”¨äº†ç©ºæ´å·ç§¯ã€‚
* **Class-specific RPN.**ï¼šRPNçš„è®­ç»ƒéµå¾ª[Faster R-CNNè®ºæ–‡](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äºå°†åˆ†ç±»å±‚çš„2ç±»ï¼ˆå‰æ™¯æˆ–èƒŒæ™¯ï¼‰æ”¹ä¸ºäº†21ç±»ã€‚ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œclass-specific RPNåœ¨[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)çš„conv5ä½¿ç”¨äº†ç©ºæ´å·ç§¯ã€‚
* **R-FCN without position-sensitivity.**ï¼šé€šè¿‡è®¾ç½®$k=1$å¯å°†R-FCNä¸­çš„position-sensitivityç§»é™¤ã€‚è¿™ç›¸å½“äºå¯¹æ¯ä¸ªRoIè¿›è¡Œglobal poolingã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/7.png)

[ResNetåŸæ–‡](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä¸­ç”¨ResNet-101å®ç°çš„standard Faster R-CNNè¾¾åˆ°äº†76.4%çš„mAPï¼ˆè§è¡¨3ï¼‰ï¼Œå…¶RoI poolingå±‚åœ¨conv4å’Œconv5ä¹‹é—´ã€‚è€ŒnaÃ¯ve Faster R-CNNï¼ˆå°†RoI poolingæ”¾åœ¨conv5ä¹‹åï¼‰çš„mAPæ‰åˆ°äº†68.9%ï¼ˆè§è¡¨2ï¼‰ã€‚è¿™ä¸ªæ¯”è¾ƒç»“æœè¯´æ˜äº†ï¼Œå¯¹äºFaster R-CNNï¼Œåœ¨å±‚ä¹‹é—´æ’å…¥RoI poolingä»¥å¼ºè°ƒç©ºé—´ä¿¡æ¯æ˜¯éå¸¸é‡è¦çš„ã€‚

R-FCN without position-sensitivityå› æ¨¡å‹æ— æ³•æ”¶æ•›å¯¼è‡´failã€‚

ğŸ‘‰**Comparisons with Faster R-CNN Using ResNet-101**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/8.png)

å¯¹äºè¡¨3ï¼Œæˆ‘ä»¬éƒ½ä½¿ç”¨$k \times k = 7 \times 7$ã€‚æ›´å¤šçš„æ¯”è¾ƒè§è¡¨4ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/9.png)

å¯¹äºè¡¨4ï¼Œåœ¨multi-scaleè®­ç»ƒä¸­ï¼Œåœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­ï¼Œæˆ‘ä»¬éšæœºå°†å›¾åƒçš„çŸ­è¾¹resizeåˆ°$\\{ 400,500,600,700,800 \\}$ä¸ªåƒç´ ã€‚åœ¨single-scaleè®­ç»ƒä¸­ï¼Œå›¾åƒçš„çŸ­è¾¹å›ºå®šä¸º600ä¸ªåƒç´ ã€‚å¯è§†åŒ–ç»“æœè§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/14.png)

åœ¨PASCAL VOC 2012ä¸Šçš„æ¯”è¾ƒè§è¡¨5ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/10.png)

æ›´ç»†èŠ‚çš„æ£€æµ‹ç»“æœè§è¡¨7å’Œè¡¨8ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/16.png)

ğŸ‘‰**On the Impact of Depth**

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/11.png)

ğŸ‘‰**On the Impact of Region Proposals**

éƒ½ä½¿ç”¨[ResNet-101](https://shichaoxin.com/2022/01/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Deep-Residual-Learning-for-Image-Recognition/)ä½œä¸ºbackboneï¼Œæµ‹è¯•ä½¿ç”¨ä¸åŒçš„proposalç”Ÿæˆæ–¹æ³•ï¼š[Selective Searchï¼ˆSSï¼‰](https://shichaoxin.com/2021/10/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Selective-Search-for-Object-Recognition/)ã€Edge Boxesï¼ˆEBï¼‰ã€[RPN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/12.png)

## 4.2.Experiments on MS COCO

æˆ‘ä»¬è¿˜åœ¨æœ‰80ä¸ªç±»åˆ«çš„MS COCOæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„å®éªŒåŒ…æ‹¬80kå¼ å›¾åƒçš„train setã€40kå¼ å›¾åƒçš„val setå’Œ20kå¼ å›¾åƒçš„test-dev setã€‚å‰90kæ¬¡è¿­ä»£çš„å­¦ä¹ ç‡ä¸º0.001ï¼Œå30kæ¬¡è¿­ä»£çš„å­¦ä¹ ç‡ä¸º0.0001ï¼Œmini-batch size=8ã€‚æˆ‘ä»¬è¿˜æŠŠ[Faster R-CNN](https://shichaoxin.com/2022/04/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks/)ä¸­çš„4æ­¥è®­ç»ƒæ³•æ‰©å±•åˆ°äº†5æ­¥ï¼ˆå³åœ¨æœ€åå¤šåŠ äº†ä¸€æ­¥ç”¨äºè®­ç»ƒRPNï¼‰ï¼Œè¿™æ ·åšç•¥å¾®æé«˜äº†åœ¨è¯¥æ•°æ®é›†ä¸Šçš„ç²¾åº¦ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œåªä½¿ç”¨å‰ä¸¤æ­¥è®­ç»ƒä¹Ÿå¯ä»¥è·å¾—ç›¸å¯¹è¾ƒå¥½çš„ç²¾åº¦ï¼Œä½†æ²¡æœ‰ç‰¹å¾å…±äº«ã€‚

è€ƒè™‘åˆ°COCOæ•°æ®é›†çš„ç›®æ ‡å°ºåº¦è·¨åº¦æ›´å¹¿ï¼Œæµ‹è¯•é˜¶æ®µçš„multi-scaleä½¿ç”¨äº†$\\{ 200,400,600,800,1000 \\}$ï¼ˆè§è¡¨6æœ€åä¸€è¡Œï¼‰ã€‚

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/13.png)

å¯è§†åŒ–ç»“æœè§ä¸‹ï¼š

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/AIPapers/RFCN/15.png)

# 5.Conclusion and Future Work

R-FCNæ˜¯ä¸€ä¸ªç®€å•ä¸”é«˜æ•ˆçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ã€‚

# 6.åŸæ–‡é“¾æ¥

ğŸ‘½[R-FCNï¼šObject Detection via Region-based Fully Convolutional Networks](https://github.com/x-jeff/AI_Papers/blob/master/2024/R-FCNï¼šObject%20Detection%20via%20Region-based%20Fully%20Convolutional%20Networks.pdf)