---
layout:     post
title:      【深度学习基础】第四十三课：BRNN
subtitle:   双向循环神经网络
date:       2020-12-12
author:     x-jeff
header-img: blogimg/20201212.jpg
catalog: true
tags:
    - Deep Learning Series
---
>【深度学习基础】系列博客为学习Coursera上吴恩达深度学习课程所做的课程笔记。  
>本文为原创文章，未经本人允许，禁止转载。转载请注明出处。

# 1.双向循环神经网络

假设我们有如下命名体识别模型用于识别句子中的人名：

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/DeepLearningSeries/Lesson43/43x1.png)

此时有两个句子：

1. He said,"Teddy bears are on sale!".
2. He said,"Teddy Roosevelt was a great President!".

模型在判断第三个单词“Teddy”是否为人名的一部分时，只能接收到在“Teddy”之前的单词传过来的信息，但很显然，下一个单词对“Teddy”的判断才是最重要的，如果下一个单词是“bear”，则“Teddy”不是人名的一部分；如果下一个单词是“Roosevelt”，则“Teddy”是人名的一部分。因此，我们希望在RNN中，信息不但可以向前流动，同时也可以反向流动。而本文所要介绍的BRNN便可解决这个问题。

**BRNN：Bidirectional RCNN，即双向循环神经网络**。BRNN可以让我们在序列的某点处不仅可以获取之前的信息，还可以获取未来的信息。BRNN的工作原理见下图：

![](https://xjeffblogimg.oss-cn-beijing.aliyuncs.com/BLOGIMG/BlogImage/DeepLearningSeries/Lesson43/43x2.png)

$a$上方的箭头表示信息流的方向。其中的基本单元（即上图中的紫色和绿色方框）可以是标准RNN单元，也可以是[GRU单元和LSTM单元](http://shichaoxin.com/2020/12/09/深度学习基础-第四十二课-GRU和LSTM/)。BRNN+LSTM是NLP问题中很常见的一种网络结构。但是BRNN的缺点也是显而易见的，即我们需要输入一个完整的句子。例如在语音识别应用中，BRNN需要我们等待整个语音结束后，将完整的语音输入模型才能够处理。